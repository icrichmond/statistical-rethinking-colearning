[
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Statistical Rethinking colearning 2023 - Bella",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\n\n\n\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n\n\n\n\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\n\n\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to Alec (robit.alec@gmail.com), or Isabella. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\n\n\n\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community.\n\n\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Rethinking colearning 2023 - Bella",
    "section": "",
    "text": "NOTE: website format taken from Alec Robitaille\n\nSchedule\n\nLectures\nHomework\n\nParticipant notes and homework solutions\nResources\nInstallation\nCode of Conduct\n\n\n\nSecond round of Statistical Rethinking colearning, this time with 2023 lectures and homework.\nThe first round of Statistical Rethinking colearning (2022) is available here.\n\n\n\n\n\n\n\nMeeting date\nReading\nLectures\n\n\n\n\n26 January\nChapters 1, 2 and 3\n[1] <Science Before Statistics> <Slides>  [2] <Garden of Forking Data> <Slides>\n\n\n09 February\nChapter 4\n[3] <Geocentric Models> <Slides>  [4] <Categories and Curves> <Slides>\n\n\n23 February\nChapters 5 and 6\n[5] <Elemental Confounds> <Slides>  [6] <Good and Bad Controls> <Slides>\n\n\n09 March\nChapters 7 and 8\n[7] <Overfitting> <Slides>  [8] <MCMC> <Slides>\n\n\n23 March\nChapters 9, 10 and 11\n[9] <Modeling Events> <Slides>  [10] <Counts and Confounds> <Slides>\n\n\n06 April\nChapters 11 and 12\n[11] <Ordered Categories> <Slides>  [12] <Multilevel Models> <Slides>\n\n\n20 April\nChapter 13\n[13] <Multilevel Adventures> <Slides>  [14] <Correlated Features> <Slides>\n\n\n04 May\nChapter 14\n[15] <Social Networks> <Slides>  [16] <Gaussian Processes> <Slides>\n\n\n18 May\nChapter 15\n[17] Measurement Error  [18] Missing Data\n\n\n01 June\nChapters 16 and 17\n[19] Beyond GLMs: State-space Models, ODEs  [20] Horoscopes\n\n\n\n\n\n\n\n\n\nMeeting date\nHomework\nSolutions\n\n\n\n\n2 February\nHomework 1\nSolutions\n\n\n16 February\nHomework 2\nSolutions\n\n\n2 March\nHomework 3\nSolutions\n\n\n16 March\nHomework 4\nSolutions\n\n\n30 March\nHomework 5\nSolutions\n\n\n13 April\nHomework 6\nSolutions\n\n\n27 April\nHomework 7\nSolutions\n\n\n11 May\nHomework 8\nSolutions\n\n\n25 May\nHomework 9\nSolutions\n\n\n01 June\nHomework 10\nSolutions\n\n\n\n\n\n\n\n\nAlec\nBella (this repo)\n\n\n\n\n\nAdditional material using other packages or languages\n\nOriginal R: https://github.com/rmcelreath/rethinking/\nR + Tidyverse + ggplot2 + brms: https://bookdown.org/content/4857/\nPython and PyMC3: Python/PyMC3\nJulia and Turing: https://github.com/StatisticalRethinkingJulia and https://github.com/StatisticalRethinkingJulia/TuringModels.jl\n\nSee Richard’s comments about these here: https://github.com/rmcelreath/stat_rethinking_2023#coding\n2022 colearning:\n\nLectures: https://github.com/rmcelreath/stat_rethinking_2022#calendar--topical-outline\nHomework: https://github.com/rmcelreath/stat_rethinking_2022/tree/main/homework\n\nAlso, Alec’s notes and solutions of the 2019 material: https://github.com/robitalec/statistical-rethinking and https://www.statistical-rethinking.robitalec.ca/\n\n\n\nPackage specific install directions. We’ll update these as we go!\nRethinking\n\nrethinking\n\nStan\n\ncmdstanr\nRStan\nbrms\n\nTargets\n\ntargets\nstantargets\n\nV8, needed for the dagitty package\n\nV8\n\n\n\n\nPlease note that this project is released with a Code of Conduct. By participating in this project you agree to abide by its terms."
  },
  {
    "objectID": "homework/homework-04.html",
    "href": "homework/homework-04.html",
    "title": "Homework - Week 04",
    "section": "",
    "text": "d <- sim_happiness(seed = 1977, N_years = 1000)\nd2 <- d[d$age > 17, ]\nd2$A <- (d2$age - 18) / (65 - 18)\nd2$mid <- d2$married + 1\n\n# model with marital status and age\ntar_load(h04_q1a)\nmMA <- h04_q1a\n\nmMA %>% \n  gather_draws(b_Intercept, b_mid, b_A, sigma) %>% \n  median_qi() %>%\n  ggplot(aes(y = .variable, x = .value, xmin = .lower, xmax = .upper)) + \n  geom_pointinterval() + \n  theme_classic() +\n  labs(y = \"\", x = \"mean value +/- 95% CIs\")\n\n\n\n# model with age\ntar_load(h04_q1b)\nmA <- h04_q1b\n\nmA %>% \n  gather_draws(b_Intercept, b_A, sigma) %>% \n  median_qi() %>%\n  ggplot(aes(y = .variable, x = .value, xmin = .lower, xmax = .upper)) + \n  geom_pointinterval() + \n  theme_classic() +\n  labs(y = \"\", x = \"mean value +/- 95% CIs\")\n\n\n\n# compare with PSIS & WAIC\ncMA <- add_criterion(mMA, c(\"loo\", \"waic\"))\ncA <- add_criterion(mA, c(\"loo\", \"waic\"))\nloo_compare(cMA, cA, criterion = \"loo\")\n\n    elpd_diff se_diff\ncMA    0.0       0.0 \ncA  -147.7      15.4 \n\nloo_compare(cMA, cA, criterion = \"waic\")\n\n    elpd_diff se_diff\ncMA    0.0       0.0 \ncA  -147.7      15.4 \n\n\nThe correct predictive model includes both marriage status and age. However, marriage status is a collider and the correct causal model includes only age. Thus, the correct causal model and the best predictive model are different in this case (because predictive models favour colliders)."
  },
  {
    "objectID": "homework/homework-04.html#question-2-reconsider-the-urban-fox-analysis-from-last-weeks-homework.-on-the-basis-of-psis-and-waic-scores-which-combination-of-variables-best-predicts-body-weight-w-weight-what-causal-interpretation-can-you-assign-each-coefficient-parameter-from-the-best-scoring-model",
    "href": "homework/homework-04.html#question-2-reconsider-the-urban-fox-analysis-from-last-weeks-homework.-on-the-basis-of-psis-and-waic-scores-which-combination-of-variables-best-predicts-body-weight-w-weight-what-causal-interpretation-can-you-assign-each-coefficient-parameter-from-the-best-scoring-model",
    "title": "Homework - Week 04",
    "section": "Question 2: Reconsider the urban fox analysis from last week’s homework. On the basis of PSIS and WAIC scores, which combination of variables best predicts body weight (W, weight)? What causal interpretation can you assign each coefficient (parameter) from the best scoring model?",
    "text": "Question 2: Reconsider the urban fox analysis from last week’s homework. On the basis of PSIS and WAIC scores, which combination of variables best predicts body weight (W, weight)? What causal interpretation can you assign each coefficient (parameter) from the best scoring model?\n\n# get data\ndata(foxes)\nd <- foxes %>% \n    select(c(weight, avgfood, area, groupsize)) %>%\n    mutate(avgfood = standardize(avgfood), \n           area = standardize(area),\n           weight = standardize(weight),\n           groupsize = standardize(groupsize))\n\n# load models\ntar_load(h03_q2)\ntar_load(h03_q3)\ntar_load(h04_q2)\nm_food <- h03_q2\nm_foodgroupsize <- h03_q3\nm_areafoodgroupsize <- h04_q2\n\ncrit_food <- add_criterion(m_food, c(\"loo\", \"waic\"))\ncrit_foodgroupsize <- add_criterion(m_foodgroupsize, c(\"loo\", \"waic\"))\n\nWarning: \n1 (0.9%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\ncrit_areafoodgroupsize <- add_criterion(m_areafoodgroupsize, c(\"loo\", \"waic\"))\n\nWarning: \n1 (0.9%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\nloo_compare(crit_food, crit_foodgroupsize, crit_areafoodgroupsize, criterion = \"loo\")\n\n                       elpd_diff se_diff\ncrit_areafoodgroupsize  0.0       0.0   \ncrit_foodgroupsize     -0.4       1.7   \ncrit_food              -5.3       3.4   \n\n\nThe model with area, average food, and group size is the best predictive model. In this model, we are assessing the direct effect of group size on weight. So the coefficient for G can be read as the direct effect. The coefficients for F and A do not have causal meaning (discuss with group). If we hadn’t stratified by group size, we would be assessing the direct effect of area on weight but stratifying by both average food and group size means that we opened a backdoor path."
  },
  {
    "objectID": "homework/homework-04.html#question-3-build-a-predictive-model-of-the-relationship-show-on-the-cover-of-the-book-the-relationship-between-the-timing-of-cherry-blossoms-and-march-temperature-in-the-same-year.-the-data-are-found-in-datacherry_blossoms.-consider-at-least-two-different-models-functional-relationships-to-predict-doy-with-temp.-you-could-for-example-compare-a-linear-model-with-a-quadratic-model.-compare-them-with-psis-or-waic.",
    "href": "homework/homework-04.html#question-3-build-a-predictive-model-of-the-relationship-show-on-the-cover-of-the-book-the-relationship-between-the-timing-of-cherry-blossoms-and-march-temperature-in-the-same-year.-the-data-are-found-in-datacherry_blossoms.-consider-at-least-two-different-models-functional-relationships-to-predict-doy-with-temp.-you-could-for-example-compare-a-linear-model-with-a-quadratic-model.-compare-them-with-psis-or-waic.",
    "title": "Homework - Week 04",
    "section": "Question 3: Build a predictive model of the relationship show on the cover of the book, the relationship between the timing of cherry blossoms and March temperature in the same year. The data are found in data(cherry_blossoms). Consider at least two different models (functional relationships) to predict doy with temp. You could for example compare a linear model with a quadratic model. Compare them with PSIS or WAIC.",
    "text": "Question 3: Build a predictive model of the relationship show on the cover of the book, the relationship between the timing of cherry blossoms and March temperature in the same year. The data are found in data(cherry_blossoms). Consider at least two different models (functional relationships) to predict doy with temp. You could for example compare a linear model with a quadratic model. Compare them with PSIS or WAIC.\n\n# data\ndata(\"cherry_blossoms\")\n\ncherry <- cherry_blossoms %>% \n  select(temp, doy) %>%\n  drop_na() %>%\n  mutate(temp_s = standardize(temp),\n         doy_s = standardize(doy))\n\n# models\ntar_load(h04_q3a)\ntar_load(h04_q3b)\ntar_load(h04_q3c)\nm_priors <- h04_q3a\nm_linear <- h04_q3b\nm_gam <- h04_q3c\n\n# compare\ncrit_priors <- add_criterion(m_priors, c(\"loo\"))\n\nWarning: Found 787 observations with a pareto_k > 0.7 in model 'm_priors'. It\nis recommended to set 'moment_match = TRUE' in order to perform moment matching\nfor problematic observations.\n\ncrit_linear <- add_criterion(m_linear, c(\"loo\"))\ncrit_gam <- add_criterion(m_gam, c(\"loo\"))\n\nloo_compare(crit_priors, crit_linear, crit_gam, criterion = \"loo\")\n\n            elpd_diff     se_diff      \ncrit_linear  0.000000e+00  0.000000e+00\ncrit_gam    -1.900000e+00  1.000000e+00\ncrit_priors -1.188291e+11  5.619104e+09\n\n\nThe linear model performed best, but the GAM and linear model performed much more similarly than the prior only model (which makes sense)."
  },
  {
    "objectID": "homework/homework-04.html#suppose-march-temperatures-reach-9-degrees-by-the-year-2050.-what-does-your-best-model-predict-for-the-predictive-distribution-of-the-day-in-year-that-the-cherry-trees-will-blossom",
    "href": "homework/homework-04.html#suppose-march-temperatures-reach-9-degrees-by-the-year-2050.-what-does-your-best-model-predict-for-the-predictive-distribution-of-the-day-in-year-that-the-cherry-trees-will-blossom",
    "title": "Homework - Week 04",
    "section": "Suppose March temperatures reach 9 degrees by the year 2050. What does your best model predict for the predictive distribution of the day-in-year that the cherry trees will blossom?",
    "text": "Suppose March temperatures reach 9 degrees by the year 2050. What does your best model predict for the predictive distribution of the day-in-year that the cherry trees will blossom?\n\n# posterior summary\nposterior_summary(m_linear)\n\n                 Estimate  Est.Error          Q2.5         Q97.5\nb_Intercept  4.343635e-05 0.03468038 -7.035872e-02  6.782152e-02\nb_temp_s    -3.247333e-01 0.03339855 -3.908559e-01 -2.599676e-01\nsigma        9.465189e-01 0.02359388  9.021125e-01  9.927066e-01\nlprior      -1.613640e+00 0.04994275 -1.718661e+00 -1.524033e+00\nlp__        -1.074888e+03 1.24161065 -1.078241e+03 -1.073480e+03\n\n# create dataset that simulates 9 degree days in March (also need to standardize as that is how model is currently set up)\npred_val <- cherry %>%\n  summarize(temp_s = (9-mean(temp))/sd(temp))\n\n# simulate from model for when March is 9 degrees\npost_pred <- predicted_draws(m_linear, pred_val) \npost_pred <- post_pred %>%\n  # convert back to real values from standardized ones\n  mutate(doy = .prediction*sd(cherry$doy) + mean(cherry$doy))\n\n# plot  \nggplot() + \n  geom_density(aes(x = doy), col = \"red\", data = post_pred) + \n  geom_density(aes(x = doy), data = cherry) + \n  xlab(\"day of year in 1st bloom\") + \n  theme_classic()\n\n\n\n\nAverage first day in bloom seems to be much earlier when warming occurs (red line) according to our predictive model."
  },
  {
    "objectID": "homework/homework-04.html#question-4-the-data-in-datadinosaurs-are-body-mass-estimates-at-different-estimated-ages-for-six-different-dinosaur-species.-see-dinosaurs-for-more-details.-choose-one-or-more-of-these-species-at-least-one-but-as-many-as-you-like-and-model-its-growth.-to-be-precise-make-a-predictive-model-of-body-mass-using-age-as-a-predictor.-consider-two-or-more-model-types-for-the-function-relating-age-to-body-mass-and-score-each-using-psis-and-waic.",
    "href": "homework/homework-04.html#question-4-the-data-in-datadinosaurs-are-body-mass-estimates-at-different-estimated-ages-for-six-different-dinosaur-species.-see-dinosaurs-for-more-details.-choose-one-or-more-of-these-species-at-least-one-but-as-many-as-you-like-and-model-its-growth.-to-be-precise-make-a-predictive-model-of-body-mass-using-age-as-a-predictor.-consider-two-or-more-model-types-for-the-function-relating-age-to-body-mass-and-score-each-using-psis-and-waic.",
    "title": "Homework - Week 04",
    "section": "Question 4: The data in data(Dinosaurs) are body mass estimates at different estimated ages for six different dinosaur species. See ?Dinosaurs for more details. Choose one or more of these species (at least one, but as many as you like) and model its growth. To be precise: Make a predictive model of body mass using age as a predictor. Consider two or more model types for the function relating age to body mass and score each using PSIS and WAIC.",
    "text": "Question 4: The data in data(Dinosaurs) are body mass estimates at different estimated ages for six different dinosaur species. See ?Dinosaurs for more details. Choose one or more of these species (at least one, but as many as you like) and model its growth. To be precise: Make a predictive model of body mass using age as a predictor. Consider two or more model types for the function relating age to body mass and score each using PSIS and WAIC."
  },
  {
    "objectID": "homework/homework-04.html#which-model-do-you-think-is-best-on-predictive-grounds-on-scientific-grounds-if-your-answers-to-these-questions-differ-why",
    "href": "homework/homework-04.html#which-model-do-you-think-is-best-on-predictive-grounds-on-scientific-grounds-if-your-answers-to-these-questions-differ-why",
    "title": "Homework - Week 04",
    "section": "Which model do you think is best, on predictive grounds? On scientific grounds? If your answers to these questions differ, why?",
    "text": "Which model do you think is best, on predictive grounds? On scientific grounds? If your answers to these questions differ, why?"
  },
  {
    "objectID": "homework/homework-04.html#this-is-a-challenging-exercise-because-the-data-are-so-scarce.-but-it-is-also-a-realistic-example-because-people-publish-nature-papers-with-even-less-data.-so-do-your-best-and-i-look-forward-to-seeing-your-growth-curves.",
    "href": "homework/homework-04.html#this-is-a-challenging-exercise-because-the-data-are-so-scarce.-but-it-is-also-a-realistic-example-because-people-publish-nature-papers-with-even-less-data.-so-do-your-best-and-i-look-forward-to-seeing-your-growth-curves.",
    "title": "Homework - Week 04",
    "section": "This is a challenging exercise, because the data are so scarce. But it is also a realistic example, because people publish Nature papers with even less data. So do your best, and I look forward to seeing your growth curves.",
    "text": "This is a challenging exercise, because the data are so scarce. But it is also a realistic example, because people publish Nature papers with even less data. So do your best, and I look forward to seeing your growth curves."
  },
  {
    "objectID": "homework/homework-03.html#where-f-is-avgfood-g-is-groupsize-a-is-area-and-w-is-weight.-use-the-backdoor-criterion-and-estimate-the-total-causa-influence-of-a-on-f.-what-effect-would-increasing-the-territory-have-on-the-amount-of-food-inside-of-it",
    "href": "homework/homework-03.html#where-f-is-avgfood-g-is-groupsize-a-is-area-and-w-is-weight.-use-the-backdoor-criterion-and-estimate-the-total-causa-influence-of-a-on-f.-what-effect-would-increasing-the-territory-have-on-the-amount-of-food-inside-of-it",
    "title": "Homework - Week 03",
    "section": "where F is avgfood, G is groupsize, A is area, and W is weight. Use the backdoor criterion and estimate the total causa influence of A on F. What effect would increasing the territory have on the amount of food inside of it?",
    "text": "where F is avgfood, G is groupsize, A is area, and W is weight. Use the backdoor criterion and estimate the total causa influence of A on F. What effect would increasing the territory have on the amount of food inside of it?\nTotal causal effect of A on F is just F ~ A.\n\n# get data\ndata(foxes)\nd <- foxes %>% \n  select(c(avgfood, area)) %>%\n  mutate(avgfood = standardize(avgfood), \n         area = standardize(area))\n\n# get a list of priors present in the model\ndefault_prior <- get_prior(avgfood ~ area, data = d, family = gaussian())\n\n# load model\ntar_load(h03_q1)\nm1<- h03_q1\n\n# model formula\nm1$formula\n\navgfood ~ area \n\n# priors\nm1$prior\n\n          prior     class coef group resp dpar nlpar lb ub       source\n normal(0, 0.5)         b                                          user\n normal(0, 0.5)         b area                             (vectorized)\n normal(0, 0.5) Intercept                                          user\n exponential(1)     sigma                             0            user\n\n# check diagnostics\nplot(m1)\n\n\n\n# get a summary of posterior distribution\nposterior_summary(m1)\n\n                Estimate  Est.Error         Q2.5        Q97.5\nb_Intercept   0.00180027 0.04424605  -0.08699153   0.08779513\nb_area        0.87508681 0.04532430   0.78381207   0.96385458\nsigma         0.47642964 0.03193351   0.41960619   0.54381478\nlprior       -2.46759468 0.15979059  -2.79675921  -2.15820677\nlp__        -81.07429865 1.29904575 -84.42465769 -79.65751830\n\n# plot the effect\nm1 %>% \n  gather_draws(b_Intercept, b_area, sigma) %>% \n  median_qi() %>%\n  ggplot(aes(y = .variable, x = .value, xmin = .lower, xmax = .upper)) + \n  geom_pointinterval() + \n  theme_classic() +\n  labs(y = \"\", x = \"mean value +/- 95% CIs\")\n\n\n\n\nIt looks like the effect of territory size on food availability is a strong positive relationship (remember to interpret this as standardized variables - so effect is stronger than it seems)."
  },
  {
    "objectID": "homework/homework-03.html#question-2-infer-the-total-causal-effect-of-adding-food-f-to-a-territory-on-the-weight-w-of-foxes.-can-you-calculate-the-causal-effect-by-simulating-an-intervention-on-food",
    "href": "homework/homework-03.html#question-2-infer-the-total-causal-effect-of-adding-food-f-to-a-territory-on-the-weight-w-of-foxes.-can-you-calculate-the-causal-effect-by-simulating-an-intervention-on-food",
    "title": "Homework - Week 03",
    "section": "Question 2: Infer the total causal effect of adding food, F, to a territory on the weight W of foxes. Can you calculate the causal effect by simulating an intervention on food?",
    "text": "Question 2: Infer the total causal effect of adding food, F, to a territory on the weight W of foxes. Can you calculate the causal effect by simulating an intervention on food?\n\n# get data\ndata(foxes)\nd <- foxes %>% \n  select(c(avgfood, weight)) %>%\n  mutate(avgfood = standardize(avgfood), \n         weight = standardize(weight))\n\n# get a list of priors present in the model\ndefault_prior <- get_prior(weight ~ avgfood, data = d, family = gaussian())\n\n# load model\ntar_load(h03_q2)\nm2<- h03_q2\n\n# model formula\nm2$formula\n\nweight ~ avgfood \n\n# priors\nm2$prior\n\n          prior     class    coef group resp dpar nlpar lb ub       source\n normal(0, 0.5)         b                                             user\n normal(0, 0.5)         b avgfood                             (vectorized)\n normal(0, 0.5) Intercept                                             user\n exponential(1)     sigma                                0            user\n\n# check diagnostics\nplot(m2)\n\n\n\n# get a summary of posterior distribution\nposterior_summary(m2)\n\n                 Estimate  Est.Error         Q2.5        Q97.5\nb_Intercept  6.834984e-04 0.09026490   -0.1761782    0.1706892\nb_avgfood   -2.153602e-02 0.09414535   -0.2049801    0.1656456\nsigma        1.010654e+00 0.06928777    0.8865267    1.1533827\nlprior      -1.497178e+00 0.08130099   -1.6705898   -1.3623127\nlp__        -1.670499e+02 1.25890208 -170.3416937 -165.6393421\n\n# simulate an intervention on food\n# make empty df \nsimdf <- tibble(weight = double(), \n                    avgfood = double(), \n                    condition = character())\n# sample W from data\nn <- 1e3\nsampW <- sample(d$weight, size = n, replace = T)\n# make df where avgfood = 0\nsimdf_nofood <- simdf %>%\n  add_row(weight = sampW, avgfood = rep(0, n), condition = rep('no food', n))\n\n# make df where avgfood = 1\nsimdf_food <- simdf %>%\n  add_row(weight = sampW, avgfood = rep(1, n), condition = rep('food', n))\n\n# simulate model output when F = 0\nepred_nofood <- simdf_nofood %>% \n  add_epred_draws(m2)\n\n# simulate model output when F = 1\nepred_food <- simdf_food %>%\n  add_epred_draws(m2)\n\n# visualize contrast of intervention on food\nepred <- as.data.frame(rbind(epred_nofood, epred_food))\n\nggplot(data = epred, aes(x = .epred, y = condition)) +\n  stat_pointinterval(.width = c(.66, .95)) + \n  theme_classic() + \n  labs(y = \"\", x = \"mean value +/- 66% and 95% CIs\")\n\n\n\n\nWe see that the total effect of food on weight is very slightly negative. Adding food would result in a small decrease in average weight. However, there is almost equal plausibility that it could be a positive effect as well and the effect is very small."
  },
  {
    "objectID": "homework/homework-03.html#question-3-infer-the-direct-causal-effect-of-adding-food-f-to-a-territory-on-the-weight-w-of-foxes.-in-light-of-your-estimates-from-this-problem-and-the-previous-one-what-do-you-think-is-going-on-with-these-foxes",
    "href": "homework/homework-03.html#question-3-infer-the-direct-causal-effect-of-adding-food-f-to-a-territory-on-the-weight-w-of-foxes.-in-light-of-your-estimates-from-this-problem-and-the-previous-one-what-do-you-think-is-going-on-with-these-foxes",
    "title": "Homework - Week 03",
    "section": "Question 3: Infer the direct causal effect of adding food F to a territory on the weight W of foxes. In light of your estimates from this problem and the previous one, what do you think is going on with these foxes?",
    "text": "Question 3: Infer the direct causal effect of adding food F to a territory on the weight W of foxes. In light of your estimates from this problem and the previous one, what do you think is going on with these foxes?\nTo assess the direct causal effect of adding food on fox weight, we need to stratify by group size. This means simply adding group size to the model.\n\n# get data\ndata(foxes)\nd <- foxes %>% \n  select(c(avgfood, weight, groupsize)) %>%\n  mutate(avgfood = standardize(avgfood), \n         weight = standardize(weight),\n         groupsize = standardize(groupsize))\n\n# get a list of priors present in the model\ndefault_prior <- get_prior(weight ~ avgfood + groupsize, data = d, family = gaussian())\n\n# load model\ntar_load(h03_q3)\nm3<- h03_q3\n\n# model formula\nm3$formula\n\nweight ~ avgfood + groupsize \n\n# priors\nm3$prior\n\n          prior     class      coef group resp dpar nlpar lb ub       source\n normal(0, 0.5)         b                                               user\n normal(0, 0.5)         b   avgfood                             (vectorized)\n normal(0, 0.5)         b groupsize                             (vectorized)\n normal(0, 0.5) Intercept                                               user\n exponential(1)     sigma                                  0            user\n\n# check diagnostics\nplot(m3)\n\n\n\n# get a summary of posterior distribution\nposterior_summary(m3)\n\n                 Estimate  Est.Error          Q2.5        Q97.5\nb_Intercept -1.290813e-03 0.08931639   -0.17236064    0.1769677\nb_avgfood    4.729671e-01 0.18599490    0.09371001    0.8265943\nb_groupsize -5.707044e-01 0.18681170   -0.93313280   -0.1968301\nsigma        9.646206e-01 0.06488804    0.84658064    1.1065583\nlprior      -2.895702e+00 0.75889644   -4.70678173   -1.7899017\nlp__        -1.629948e+02 1.44232128 -166.61982834 -161.1684968\n\n# plot\nm3 %>% \n  gather_draws(b_Intercept, b_avgfood, b_groupsize, sigma) %>% \n  median_qi() %>%\n  ggplot(aes(y = .variable, x = .value, xmin = .lower, xmax = .upper)) + \n  geom_pointinterval() + \n  theme_classic() +\n  labs(y = \"\", x = \"mean value +/- 95% CIs\")\n\n\n\n\nOnce we stratify for group size, we see that the effect of food availability on weight is stronger, and positive. We also see that group size has a moderate negative effect on weight. The effect sizes are almost the same size, but in opposite directions. When calculating the total effect, the effect of group size may be masking the effect of food on fox weight.\nBiological explanation: increases in territory size increase food availability (Q1) - but increases in food don’t affect fox weight. Is this effect being cancelled out by subsequent increases in group size? Can test causal model\n\n# load model\ntar_load(h03_q3b)\nm3b <- h03_q3b\n\n# model formula\nm3b$formula\n\ngroupsize ~ avgfood \n\n# check diagnostics\nplot(m3b)\n\n\n\n# get a summary of posterior distribution\nposterior_summary(m3b)\n\n                 Estimate  Est.Error         Q2.5        Q97.5\nb_Intercept -1.491733e-04 0.04127697  -0.08049194   0.07950636\nb_avgfood    8.959363e-01 0.04117644   0.81502122   0.97602255\nsigma        4.386855e-01 0.02912356   0.38752297   0.50095616\nlprior      -2.502469e+00 0.14990467  -2.82347812  -2.22383426\nlp__        -7.181795e+01 1.24592339 -75.01707671 -70.41421943\n\n# plot\nm3b %>% \n  gather_draws(b_Intercept, b_avgfood, sigma) %>% \n  median_qi() %>%\n  ggplot(aes(y = .variable, x = .value, xmin = .lower, xmax = .upper)) + \n  geom_pointinterval() + \n  theme_classic() +\n  labs(y = \"\", x = \"mean value +/- 95% CIs\")\n\n\n\n\nAverage food has a strong positive effect on group size. More food = larger groups = negative/minimal effect on weight."
  },
  {
    "objectID": "homework/homework-03.html#question-4-suppose-there-is-an-unovserved-confound-that-influences-f-and-g-like-this",
    "href": "homework/homework-03.html#question-4-suppose-there-is-an-unovserved-confound-that-influences-f-and-g-like-this",
    "title": "Homework - Week 03",
    "section": "Question 4: Suppose there is an unovserved confound that influences F and G, like this:",
    "text": "Question 4: Suppose there is an unovserved confound that influences F and G, like this:\n\n\n\n\n\n\nAssuming the DAG above is correct, again estimate both the total and direct causal effects of F on W. What impact does the unobserved confound have?\nTotal effect: Impossible because to close backdoor path you need to stratify on G - then you are estimating the direct effect.\nDirect effect: Stratify by G."
  },
  {
    "objectID": "homework/homework-02.html",
    "href": "homework/homework-02.html",
    "title": "Homework - Week 02",
    "section": "",
    "text": "Draw the DAG that represents these causal relationships. And then write a generative simulation that takes age as an input and simulates height and weight, obeying the relationships in the DAG.\nDAG:\n\n# DAG\ndag <- dagify(\n    weight ~ age + height,\n    height ~ age,\n    exposure = 'age',\n    outcome = 'weight'\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\nGenerative Simulation:\n\n# A = age, H = height, W = weight\nbAH <- 5 # as age increases, height increases by a lot\nbHW <- 0.5 # as height increases, weight proportionally increases cm/kg\nbAW <- 0.1 # as age increases, there is a small direct increase in weight\n\nsim_AW <- function(A, bAH, bHW, bAW){\n  N <- length(A)\n  H <- rnorm(N, bAH*A, 2)\n  W <- rnorm(N, bHW*H + bAW*A, 2)\n  data.frame(A, H, W)\n}\n\n# randomly generated individuals \nA <- runif(n=20, min=1, max=13)\n\ntest_sim <- sim_AW(A, bAH, bHW, bAW)\n\n# view relationship\nggplot(data = test_sim, aes(x=A, y=W)) + \n  geom_point() + \n  theme_classic()\n\n\n\n\nHave some weird things happening here (decreases in weight with age) but overall a positive-ish relationship between age-weight that is partially dependent on height."
  },
  {
    "objectID": "homework/homework-02.html#question-2-use-a-linear-regression-to-estimate-the-total-causal-effect-of-each-year-of-growth-on-weight.",
    "href": "homework/homework-02.html#question-2-use-a-linear-regression-to-estimate-the-total-causal-effect-of-each-year-of-growth-on-weight.",
    "title": "Homework - Week 02",
    "section": "Question 2: Use a linear regression to estimate the total causal effect of each year of growth on weight.",
    "text": "Question 2: Use a linear regression to estimate the total causal effect of each year of growth on weight.\nTotal causal effect means that we do not account for the effect of height. It is a linear regression of weight ~ age (where age is a proxy for year of growth).\n\ndata(Howell1)\nd <- Howell1 %>% \n  filter(age <= 13) %>%\n  select(c(weight, age))\n\n# get a list of priors present in the model\ndefault_prior <- get_prior(weight ~ age, data = d, family = gaussian())\n\n# get model\ntar_load(h02_mAW)\nmAW <- h02_mAW\n\n# model formula\nmAW$formula\n\nweight ~ age \n\n# priors\nmAW$prior\n\n          prior     class coef group resp dpar nlpar lb ub       source\n uniform(0, 10)         b                                          user\n uniform(0, 10)         b  age                             (vectorized)\n   normal(5, 1) Intercept                                          user\n exponential(1)     sigma                             0            user\n\n# check diagnostics\nplot(mAW)\n\n\n\n# get a summary of posterior distribution\nposterior_summary(mAW)\n\n               Estimate  Est.Error        Q2.5       Q97.5\nb_Intercept    7.036794 0.36425544    6.327332    7.753923\nb_age          1.335759 0.05138795    1.235176    1.442238\nsigma          2.596536 0.15143607    2.320393    2.903958\nlprior       -55.469858 2.07865655  -59.474311  -51.354272\nlp__        -427.576650 1.31101667 -431.020299 -426.121602"
  },
  {
    "objectID": "homework/homework-02.html#question-3-now-suppose-the-causal-association-between-age-and-weight-might-be-different-for-boys-and-girls.-use-a-single-linear-regression-with-a-categorical-variable-for-sex-to-estimate-the-total-causal-effect-of-age-on-weight-separately-for-boys-and-girls.-how-do-girls-and-boys-differ-provide-one-or-more-posterior-contrasts-as-a-summary.",
    "href": "homework/homework-02.html#question-3-now-suppose-the-causal-association-between-age-and-weight-might-be-different-for-boys-and-girls.-use-a-single-linear-regression-with-a-categorical-variable-for-sex-to-estimate-the-total-causal-effect-of-age-on-weight-separately-for-boys-and-girls.-how-do-girls-and-boys-differ-provide-one-or-more-posterior-contrasts-as-a-summary.",
    "title": "Homework - Week 02",
    "section": "Question 3: Now suppose the causal association between age and weight might be different for boys and girls. Use a single linear regression, with a categorical variable for sex, to estimate the total causal effect of age on weight separately for boys and girls. How do girls and boys differ? Provide one or more posterior contrasts as a summary.",
    "text": "Question 3: Now suppose the causal association between age and weight might be different for boys and girls. Use a single linear regression, with a categorical variable for sex, to estimate the total causal effect of age on weight separately for boys and girls. How do girls and boys differ? Provide one or more posterior contrasts as a summary.\nUpdated DAG:\n\n# DAG\ndag <- dagify(\n    weight ~ height + age + sex,\n    height ~ age + sex,\n    exposure = 'age',\n    outcome = 'weight'\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\nModel, stratified by sex:\n\ndata(Howell1)\nd2 <- Howell1 %>% \n  filter(age <= 13) %>%\n  mutate(sex = as.factor(case_when(male == 0 ~ 1, \n                         male == 1 ~ 2))) %>%\n  select(c(weight, age, sex))\n\n# get a list of priors present in the model\ndefault_prior2 <- get_prior(weight ~ age + sex, data = d2, family = gaussian())\n\n# load model\ntar_load(h02_mAWS)\nmAWS <- h02_mAWS\n\n# model formula\nmAWS$formula\n\nweight ~ age + sex \n\n# priors\nmAWS$prior\n\n          prior     class coef group resp dpar nlpar lb ub       source\n uniform(0, 10)         b                                          user\n uniform(0, 10)         b  age                             (vectorized)\n uniform(0, 10)         b sex2                             (vectorized)\n   normal(5, 1) Intercept                                          user\n exponential(1)     sigma                             0            user\n\n# check diagnostics\nplot(mAWS)\n\n\n\n# get a summary of posterior distribution\nposterior_summary(mAWS)\n\n               Estimate  Est.Error         Q2.5       Q97.5\nb_Intercept    6.421874 0.39163836    5.6340126    7.180696\nb_age          1.328347 0.04822519    1.2345120    1.425671\nb_sex2         1.406962 0.39901129    0.6507742    2.223799\nsigma          2.499072 0.13997303    2.2404017    2.788606\nlprior       -57.983164 1.96677528  -61.9331028  -54.196221\nlp__        -424.165388 1.42733997 -427.9576483 -422.453753\n\n# get prediction options \npred_vals <- data.frame(age = seq(0, 13, 0.5))\n\n# simulate from model where sex = 1 and sex = 2 \npost_pred_female <- predicted_draws(mAWS, pred_vals %>% mutate(sex = 1)) \npost_pred_male <- predicted_draws(mAWS, pred_vals %>% mutate(sex = 2))\n\n# prediction table \npost_differences <- data.frame(\n  predict_sex_female = post_pred_female$.prediction,\n  predict_sex_male = post_pred_male$.prediction,\n  age = post_pred_female$age\n) %>%\n  mutate(diff = predict_sex_male - predict_sex_female)\n\n\n\nggplot(post_differences, aes(age, diff)) +\n    stat_lineribbon() +\n  scale_fill_manual(values = met.brewer(\"VanGogh3\", 3)) +\n    labs(\n      x = 'age',\n        y = 'predicted difference in weight (males-females)') +\n  theme_classic()"
  },
  {
    "objectID": "homework/homework-02.html#question-4-the-data-in-dataoxboys-rethinking-package-are-growth-records-for-26-boys-measured-over-9-periods.-i-want-you-to-model-their-growth.-specifically-model-the-increments-in-growth-from-one-period-occasion-in-the-data-table-to-the-next.-each-increment-is-simply-the-difference-between-height-in-one-occasion-and-height-in-the-previous-occasion.-since-none-of-these-boys-shrunk-during-the-study-all-of-the-growth-increments-are-greater-than-zero.-estimate-the-posterior-distribution-of-these-increments.-constrain-the-distribution-so-it-is-always-positive-it-should-not-be-possible-for-the-model-to-think-that-boys-can-shrink-from-year-to-year.-finally-compute-the-posterior-distribution-of-the-total-growth-over-all-9-occasions.",
    "href": "homework/homework-02.html#question-4-the-data-in-dataoxboys-rethinking-package-are-growth-records-for-26-boys-measured-over-9-periods.-i-want-you-to-model-their-growth.-specifically-model-the-increments-in-growth-from-one-period-occasion-in-the-data-table-to-the-next.-each-increment-is-simply-the-difference-between-height-in-one-occasion-and-height-in-the-previous-occasion.-since-none-of-these-boys-shrunk-during-the-study-all-of-the-growth-increments-are-greater-than-zero.-estimate-the-posterior-distribution-of-these-increments.-constrain-the-distribution-so-it-is-always-positive-it-should-not-be-possible-for-the-model-to-think-that-boys-can-shrink-from-year-to-year.-finally-compute-the-posterior-distribution-of-the-total-growth-over-all-9-occasions.",
    "title": "Homework - Week 02",
    "section": "Question 4: The data in data(Oxboys) (rethinking package) are growth records for 26 boys measured over 9 periods. I want you to model their growth. Specifically, model the increments in growth from one period (Occasion in the data table) to the next. Each increment is simply the difference between height in one occasion and height in the previous occasion. Since none of these boys shrunk during the study, all of the growth increments are greater than zero. Estimate the posterior distribution of these increments. Constrain the distribution so it is always positive-it should not be possible for the model to think that boys can shrink from year to year. Finally compute the posterior distribution of the total growth over all 9 occasions.",
    "text": "Question 4: The data in data(Oxboys) (rethinking package) are growth records for 26 boys measured over 9 periods. I want you to model their growth. Specifically, model the increments in growth from one period (Occasion in the data table) to the next. Each increment is simply the difference between height in one occasion and height in the previous occasion. Since none of these boys shrunk during the study, all of the growth increments are greater than zero. Estimate the posterior distribution of these increments. Constrain the distribution so it is always positive-it should not be possible for the model to think that boys can shrink from year to year. Finally compute the posterior distribution of the total growth over all 9 occasions."
  },
  {
    "objectID": "homework/homework-06.html",
    "href": "homework/homework-06.html",
    "title": "Homework - Week 06",
    "section": "",
    "text": "\\[\n\\alpha_j \\sim Normal(\\overline{\\alpha}, \\sigma)\n\\\\\n\\overline{\\alpha} \\sim Normal(0, 1)\n\\\\\n\\sigma \\sim Exponential(1)\n\\] To make a prior predictive simulation in brms, I can build the model and then sample only from the priors. This just requires me to build the model as I normally would:\n\ndata(\"reedfrogs\")\ndf <- reedfrogs %>%\n  mutate(tank = row_number())\n\np1_draws <- prior_draws(tar_read(prior_1)) %>%\n  mutate(prior = \"1\",\n         sd_p = inv_logit_scaled(sd_tank))\np01_draws <- prior_draws(tar_read(prior_0.1)) %>%\n  mutate(prior = \"0.1\",\n         sd_p = inv_logit_scaled(sd_tank))\np10_draws <- prior_draws(tar_read(prior_10)) %>%\n  mutate(prior = \"10\",\n         sd_p = inv_logit_scaled(sd_tank))\np100_draws <- prior_draws(tar_read(prior_100)) %>%\n  mutate(prior = \"100\",\n         sd_p = inv_logit_scaled(sd_tank))\n\ndraws <- rbind(p01_draws, p1_draws, p10_draws, p100_draws)\n\nggplot(draws, aes(x = sd_p)) +\n  geom_density() + \n  theme_classic() + \n  facet_wrap(~ prior, scales = \"free_y\")\n\nOkay getting closer to Richard’s solution hear after some troubleshooting - but we are missing all negative values (probability < 0.5 on logit scale). Not sure why this is…"
  },
  {
    "objectID": "homework/homework-06.html#question-2-revisit-the-reedfrog-survival-data-datareedfrogs.-start-with-the-varying-effects-model-from-the-book-and-lecture.-then-modify-it-to-estimate-the-causal-effects-of-the-treatment-variables-pred-and-size-including-how-size-might-modify-the-effect-of-predation.-an-easy-approach-is-to-estimate-an-effect-for-each-combination-of-pred-and-size.-justify-your-model-with-a-dag-of-this-experiment.",
    "href": "homework/homework-06.html#question-2-revisit-the-reedfrog-survival-data-datareedfrogs.-start-with-the-varying-effects-model-from-the-book-and-lecture.-then-modify-it-to-estimate-the-causal-effects-of-the-treatment-variables-pred-and-size-including-how-size-might-modify-the-effect-of-predation.-an-easy-approach-is-to-estimate-an-effect-for-each-combination-of-pred-and-size.-justify-your-model-with-a-dag-of-this-experiment.",
    "title": "Homework - Week 06",
    "section": "Question 2: Revisit the Reedfrog survival data, data(reedfrogs). Start with the varying effects model from the book and lecture. Then modify it to estimate the causal effects of the treatment variables pred and size, including how size might modify the effect of predation. An easy approach is to estimate an effect for each combination of pred and size. Justify your model with a DAG of this experiment.",
    "text": "Question 2: Revisit the Reedfrog survival data, data(reedfrogs). Start with the varying effects model from the book and lecture. Then modify it to estimate the causal effects of the treatment variables pred and size, including how size might modify the effect of predation. An easy approach is to estimate an effect for each combination of pred and size. Justify your model with a DAG of this experiment.\n\ndata(reedfrogs)"
  },
  {
    "objectID": "homework/homework-06.html#question-3-now-estimate-the-causal-effect-of-density-on-survival.-consider-whether-pred-modifies-the-effect-of-density.-there-are-several-good-ways-to-include-density-in-your-binomial-glm.-you-could-treat-it-as-a-continuous-regression-variable-possibly-standardized.-or-you-could-convert-it-to-an-ordered-category-with-three-levels.-compare-the-σ-tank-standard-deviation-posterior-distribution-to-σ-from-your-model-in-problem-2.-how-are-they-different-why",
    "href": "homework/homework-06.html#question-3-now-estimate-the-causal-effect-of-density-on-survival.-consider-whether-pred-modifies-the-effect-of-density.-there-are-several-good-ways-to-include-density-in-your-binomial-glm.-you-could-treat-it-as-a-continuous-regression-variable-possibly-standardized.-or-you-could-convert-it-to-an-ordered-category-with-three-levels.-compare-the-σ-tank-standard-deviation-posterior-distribution-to-σ-from-your-model-in-problem-2.-how-are-they-different-why",
    "title": "Homework - Week 06",
    "section": "Question 3: Now estimate the causal effect of density on survival. Consider whether pred modifies the effect of density. There are several good ways to include density in your Binomial GLM. You could treat it as a continuous regression variable (possibly standardized). Or you could convert it to an ordered category (with three levels). Compare the σ (tank standard deviation) posterior distribution to σ from your model in Problem 2. How are they different? Why?",
    "text": "Question 3: Now estimate the causal effect of density on survival. Consider whether pred modifies the effect of density. There are several good ways to include density in your Binomial GLM. You could treat it as a continuous regression variable (possibly standardized). Or you could convert it to an ordered category (with three levels). Compare the σ (tank standard deviation) posterior distribution to σ from your model in Problem 2. How are they different? Why?"
  },
  {
    "objectID": "homework/homework-06.html#question-4-return-to-the-trolley-data-datatrolley-from-chapter-12.-define-and-fit-a-varying-intercepts-model-for-these-data.-by-this-i-mean-to-add-an-intercept-parameter-for-the-individual-participants-to-the-linear-model.-cluster-the-varying-intercepts-on-individual-participants-as-indicated-by-the-unique-values-in-the-id-variable.-include-action-intention-and-contact-as-treatment-effects-of-interest.-compare-the-varying-intercepts-model-and-a-model-that-ignores-individuals.-what-is-the-impact-of-individual-variation-in-these-data",
    "href": "homework/homework-06.html#question-4-return-to-the-trolley-data-datatrolley-from-chapter-12.-define-and-fit-a-varying-intercepts-model-for-these-data.-by-this-i-mean-to-add-an-intercept-parameter-for-the-individual-participants-to-the-linear-model.-cluster-the-varying-intercepts-on-individual-participants-as-indicated-by-the-unique-values-in-the-id-variable.-include-action-intention-and-contact-as-treatment-effects-of-interest.-compare-the-varying-intercepts-model-and-a-model-that-ignores-individuals.-what-is-the-impact-of-individual-variation-in-these-data",
    "title": "Homework - Week 06",
    "section": "Question 4: Return to the Trolley data, data(Trolley), from Chapter 12. Define and fit a varying intercepts model for these data. By this I mean to add an intercept parameter for the individual participants to the linear model. Cluster the varying intercepts on individual participants, as indicated by the unique values in the id variable. Include action, intention, and contact as treatment effects of interest. Compare the varying intercepts model and a model that ignores individuals. What is the impact of individual variation in these data?",
    "text": "Question 4: Return to the Trolley data, data(Trolley), from Chapter 12. Define and fit a varying intercepts model for these data. By this I mean to add an intercept parameter for the individual participants to the linear model. Cluster the varying intercepts on individual participants, as indicated by the unique values in the id variable. Include action, intention, and contact as treatment effects of interest. Compare the varying intercepts model and a model that ignores individuals. What is the impact of individual variation in these data?"
  },
  {
    "objectID": "homework/homework-01.html#question-1-suppose-the-globe-tossing-data-lecture-2-chapter-2-had-turned-out-to-be-4-water-and-11-land.-construct-the-posterior-distribution.",
    "href": "homework/homework-01.html#question-1-suppose-the-globe-tossing-data-lecture-2-chapter-2-had-turned-out-to-be-4-water-and-11-land.-construct-the-posterior-distribution.",
    "title": "Homework - Week 01",
    "section": "Question 1: Suppose the globe tossing data (Lecture 2, Chapter 2) had turned out to be 4 water and 11 land. Construct the posterior distribution.",
    "text": "Question 1: Suppose the globe tossing data (Lecture 2, Chapter 2) had turned out to be 4 water and 11 land. Construct the posterior distribution.\n\n# define how many tosses were W & L\nw <- 4\nl <- 11\n\n# define p, every 0.01 between 0,1 \np <- seq(0, 1, by = 0.01)\n\n# function to compute posterior by every p\ncompute_posterior <- function(W, L, poss){\n  ways <- sapply(poss, function(q) (q*4)^W * ((1-q)*4)^L)\n  post <- ways/sum(ways)\n  data.frame(poss, ways, post = round(post,3))\n}\n\n# compute posterior for our data\nposterior <- compute_posterior(w, l, p)\n\n# visualize posterior \nggplot(data = posterior) + \n  geom_line(aes(poss, post)) + \n  theme_classic() + \n  xlab(\"proportion water\") + \n  ylab(\"probability\")\n\n\n\n\nNOTE: Bonus answer in solutions is somewhat key to understanding next answer. This specific problem, where you have a continuous value bounded by 0,1 with an infinite number of p, follows a beta distribution. Because the beta distribution is defined, you can instead just use that mathematical equation to come to the same conclusion as above.\n\nggplot() +\n  stat_function(fun = function(x) dbeta(x, 4+1, 11+1), color = \"black\",\n                size = 1) +\n  theme_classic() + \n  xlab(\"p\") + \n  ylab(\"\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "homework/homework-01.html#question-2-using-the-posterior-distribution-from-1-compute-the-posterior-predictive-distribution-for-the-next-5-tosses-of-the-same-globe.-i-recommend-you-use-the-sampling-method.",
    "href": "homework/homework-01.html#question-2-using-the-posterior-distribution-from-1-compute-the-posterior-predictive-distribution-for-the-next-5-tosses-of-the-same-globe.-i-recommend-you-use-the-sampling-method.",
    "title": "Homework - Week 01",
    "section": "Question 2: Using the posterior distribution from 1, compute the posterior predictive distribution for the next 5 tosses of the same globe. I recommend you use the sampling method.",
    "text": "Question 2: Using the posterior distribution from 1, compute the posterior predictive distribution for the next 5 tosses of the same globe. I recommend you use the sampling method.\n\n# sample our posterior (beta distribution with 4 W, 11 L)\nn <- 1e4\npost_samples <- rbeta(n, 4+1, 11+1)\n\n# sim globe function\nsim_globe <- function(p, N){\n  \n  sample(c(\"W\", \"L\"), size = N, prob=c(p, 1-p), replace = T)\n\n}\n\n# simulate posterior predictive distribution for next 5 tosses of the globe\n# how many of the 5 tosses will = W? Tested 1e4 times\npred_post <- sapply(post_samples, function(p) sum(sim_globe(p, 5)==\"W\"))\n\n# create table that counts number of incidences of each option (i.e., how many times will 0 W appear, 1 W, 2 W, 3 W, 4 W, 5 W?)\ntab_post <- table(pred_post)\npred_post_df <- as.data.frame(tab_post)\n\nggplot(pred_post_df, aes(as.factor(pred_post), Freq)) + \n  geom_col() + \n  theme_classic() + \n  xlab(\"number of W\") + \n  ylab(\"count\")\n\n\n\n\nNOTE: Can also use rbinom() function instead of sim_globe() since there are only two possible outcomes."
  },
  {
    "objectID": "homework/homework-01.html#question-3-use-the-posterior-predictive-distribution-from-2-to-calculate-the-probability-of-3-or-more-water-samples-in-the-next-5-tosses.",
    "href": "homework/homework-01.html#question-3-use-the-posterior-predictive-distribution-from-2-to-calculate-the-probability-of-3-or-more-water-samples-in-the-next-5-tosses.",
    "title": "Homework - Week 01",
    "section": "Question 3: Use the posterior predictive distribution from 2 to calculate the probability of 3 or more water samples in the next 5 tosses.",
    "text": "Question 3: Use the posterior predictive distribution from 2 to calculate the probability of 3 or more water samples in the next 5 tosses.\nWe know that \\[ p = \\frac{ways}{sum(ways)} \\] Therefore, count the incidences of 3, 4, 5 in posterior predictive distribution from 2 and divide by total number of ways (1e4)\n\np_threeplus <- (sum(pred_post_df[which(pred_post_df[,1]==3 | pred_post_df[,1]==4 | \n                                         pred_post_df[,1]==5),2]))/n\n\nprint(paste0(\"p = \", p_threeplus))\n\n[1] \"p = 0.1769\""
  },
  {
    "objectID": "homework/homework-01.html#question-4-suppose-you-observe-w-5-water-points-but-you-forgot-to-write-down-how-many-times-the-globe-was-tossed-so-you-dont-know-the-number-of-land-points-l.-assume-that-p-0.7-and-compute-the-posterior-distribution-of-the-number-of-tosses-n.-hint-use-the-binomial-distribution.",
    "href": "homework/homework-01.html#question-4-suppose-you-observe-w-5-water-points-but-you-forgot-to-write-down-how-many-times-the-globe-was-tossed-so-you-dont-know-the-number-of-land-points-l.-assume-that-p-0.7-and-compute-the-posterior-distribution-of-the-number-of-tosses-n.-hint-use-the-binomial-distribution.",
    "title": "Homework - Week 01",
    "section": "Question 4: Suppose you observe W = 5 water points, but you forgot to write down how many times the globe was tossed, so you don’t know the number of land points L. Assume that p = 0.7 and compute the posterior distribution of the number of tosses N. Hint: Use the binomial distribution.",
    "text": "Question 4: Suppose you observe W = 5 water points, but you forgot to write down how many times the globe was tossed, so you don’t know the number of land points L. Assume that p = 0.7 and compute the posterior distribution of the number of tosses N. Hint: Use the binomial distribution.\nBefore, we were solving for p using \\[ p^W(1-p)^L \\] Which was a beta distribution because p was a continuous variable bound between 0,1. Now we want to solve for N, with W and p. We have a success/fail dataset, with a probability of success, therefore we use the binomial distribution. We need to calculate the probability of 0-5 N’s resulting in 5 successes (W).\n\n# N & L = unknown\nW <- 5\np <- 0.7\nN_max <- 25\nlst <- seq(W, N_max, by = 1)\n\n# calculate binomial distribution for each N between lower bound (W) and upper bound (N_max) with p = 0.7\nx <- sapply(lst, function(x) dbinom(W, x, p))\n\nggplot(data.frame(data = x, N = W:N_max), aes(x = N, y = x)) +\n  geom_col() +\n  labs(y = \"Probability\", x = \"N\") + \n  theme_classic()"
  },
  {
    "objectID": "homework/homework-listing.html",
    "href": "homework/homework-listing.html",
    "title": "Homework",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nDate\n\n\nAuthor\n\n\n\n\n\n\nHomework - Week 01\n\n\n\n\nIsabella C. Richmond\n\n\n\n\nHomework - Week 02\n\n\n\n\nIsabella C. Richmond\n\n\n\n\nHomework - Week 03\n\n\n\n\nIsabella C. Richmond\n\n\n\n\nHomework - Week 04\n\n\n\n\nIsabella C. Richmond\n\n\n\n\nHomework - Week 05\n\n\n\n\nIsabella C. Richmond\n\n\n\n\nHomework - Week 06\n\n\n\n\nIsabella C. Richmond\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homework/homework-05.html",
    "href": "homework/homework-05.html",
    "title": "Homework - Week 05",
    "section": "",
    "text": "Where G = gender, D = discipline, and A = awards. We assume there are confounds between D and A. To get the total effect of gender, we model awards stratified by gender.\n\ndata(\"NWOGrants\")\n\ndf <- NWOGrants %>%\n      mutate(awards = as.integer(awards),\n             applications = as.integer(applications),\n             discipline = as.factor(as.integer(discipline)),\n             gender = as.factor(case_when(gender == 'f' ~ 1,\n                                gender == 'm' ~ 2)))\n\n# load prior only model to investigate priors \ntar_load(h05_q1_prior)\nm1p<- h05_q1_prior\nm1p$prior\n\n         prior     class    coef group resp dpar nlpar lb ub       source\n normal(-1, 1)         b                                             user\n normal(-1, 1)         b gender2                             (vectorized)\n normal(-1, 1) Intercept                                             user\n\nplot(m1p)\n\n\n\n# get posterior distribution\npost <- as_draws_df(m1p)\n\n# transform logit values back to probability\npost <- post %>% \n  mutate(p_int = inv_logit(b_Intercept),\n         p_gen = inv_logit(b_gender2))\n\n# look at prior for intercept\nggplot(post, aes(p_int)) +\n  geom_density() + \n  theme_classic()\n\n\n\n# look at prior for gender\nggplot(post, aes(p_gen)) +\n  geom_density() + \n  theme_classic()\n\n\n\n\nNow let’s investigate the model with the data:\n\ntar_load(h05_q1)\nm1<- h05_q1\n\n# diagnostics\nplot(m1)\n\n\n\nconditional_effects(m1)\n\nSetting all 'trials' variables to 1 by default if not specified otherwise.\n\n\n\n\n# summary table (logit)\nposterior_summary(m1)\n\n               Estimate  Est.Error          Q2.5       Q97.5\nb_Intercept  -1.7345009 0.07944147  -1.890443412  -1.5814405\nb_gender2     0.1944565 0.10186431  -0.005163647   0.3958046\nlprior       -2.7608262 0.13255535  -3.039364044  -2.5183436\nlp__        -64.8764670 1.01267220 -67.582082077 -63.9086047\n\n# use model to predict values for each gender individually\n# adds draws from (possibly transformed) posterior linear predictors (or \"link-level\" predictors) to the data.\nt <- df %>%\n  data_grid(gender, applications) %>%\n  add_linpred_draws(m1) %>%\n  ungroup() %>%\n  select(-.row) %>%\n  spread(gender, .linpred) %>%\n  rename(female = '1', \n         male = '2') %>%\n  mutate(contrast = inv_logit_scaled(female) - inv_logit_scaled(male))\n\nggplot(t, aes(contrast)) + \n  geom_density() + \n  theme_classic() +\n  labs(x = \"Contrast (F-M) total\")\n\n\n\n\nThis shows approximately 2.5-3% disadvantage against women."
  },
  {
    "objectID": "homework/homework-05.html#question-2-now-estimate-the-direct-causal-effect-of-gender-on-grant-awards.-use-the-same-dag-as-above-to-justify-one-or-more-binomial-models.-compute-the-average-direct-causal-effect-of-gender-weighting-each-discipline-in-proportion-to-the-number-of",
    "href": "homework/homework-05.html#question-2-now-estimate-the-direct-causal-effect-of-gender-on-grant-awards.-use-the-same-dag-as-above-to-justify-one-or-more-binomial-models.-compute-the-average-direct-causal-effect-of-gender-weighting-each-discipline-in-proportion-to-the-number-of",
    "title": "Homework - Week 05",
    "section": "Question 2: Now estimate the DIRECT causal effect of gender on grant awards. Use the same DAG as above to justify one or more binomial models. Compute the average direct causal effect of gender, weighting each discipline in proportion to the number of",
    "text": "Question 2: Now estimate the DIRECT causal effect of gender on grant awards. Use the same DAG as above to justify one or more binomial models. Compute the average direct causal effect of gender, weighting each discipline in proportion to the number of\napplications in the sample. Refer to the marginal effect example in Lecture 9 for help.\nThe direct causal effect of gender requires us to stratify by discipline as well:\n\ntar_load(h05_q2)\nm2 <- h05_q2\n\n# diagnostics\nplot(m2)\n\n\n\n\n\n\n\n\n\n\n\n\n# summary table (logit)\nposterior_summary(m2)\n\n                           Estimate Est.Error        Q2.5        Q97.5\nb_Intercept            -1.078234368 0.2303899  -1.5270658  -0.62815719\nb_gender2               0.297936445 0.2591385  -0.2003820   0.81048652\nb_discipline2          -0.666748193 0.3209575  -1.3003351  -0.03227239\nb_discipline3          -0.375089214 0.2897252  -0.9552153   0.19399449\nb_discipline4          -0.274910029 0.3345760  -0.9210288   0.38600334\nb_discipline5          -0.961229877 0.2911846  -1.5475964  -0.40154520\nb_discipline6          -0.200060482 0.3911083  -0.9715377   0.54594059\nb_discipline7          -0.195413842 0.5491084  -1.3098731   0.87716185\nb_discipline8          -0.947580663 0.2666272  -1.4818832  -0.41445625\nb_discipline9          -0.302035417 0.3559906  -1.0141290   0.38917720\nb_gender2:discipline2   0.254861761 0.3796901  -0.4868367   1.00741128\nb_gender2:discipline3  -0.653401020 0.3503448  -1.3308737   0.01839890\nb_gender2:discipline4  -1.022363405 0.4372698  -1.8882461  -0.18258542\nb_gender2:discipline5   0.237108469 0.3422994  -0.4125911   0.91480098\nb_gender2:discipline6  -0.491384144 0.4384877  -1.3664876   0.37809831\nb_gender2:discipline7  -0.111617948 0.5808920  -1.2189097   1.01587319\nb_gender2:discipline8  -0.008933715 0.3154888  -0.6104390   0.61421303\nb_gender2:discipline9  -0.609878395 0.4066560  -1.3954512   0.20700928\nlprior                -22.853028835 1.2696461 -25.6885815 -20.71012537\nlp__                  -73.349787741 3.0145406 -80.0337146 -68.51065115\n\n# plot effects\nconditional_effects(m2)\n\nSetting all 'trials' variables to 1 by default if not specified otherwise.\n\n\n\n\n\n\n\n\n\n\n## Model each department independently and contrast\ndmod <- lapply(1:9, function(x) {\n  \n  tf <- tibble(discipline = x,\n         applications = 1, \n         gender = 1) %>%\n    select(discipline, applications, gender)\n  \n  tm <- tibble(discipline = x,\n         applications = 1, \n         gender = 2) %>%\n    select(discipline, applications, gender)\n  \n  pred_dept_female <- linpred_draws(m2, tf) %>%\n  mutate(ppred = inv_logit(.linpred))\n  \n  pred_dept_male <- linpred_draws(m2, tm) %>%\n  mutate(ppred = inv_logit(.linpred))\n  \n  c <- tibble(discipline = x, \n               ppred = pred_dept_female$ppred - pred_dept_male$ppred)\n  \n  return(c)\n  \n  })\n\ndmod_df <- as.data.frame(do.call(rbind, dmod))\n\nggplot(dmod_df, aes(x = ppred, colour = as.factor(discipline))) +\n  geom_density() + \n  theme_classic() + \n  labs(x = \"Gender contrast (F-M) by department\", colour = \"Discipline\")\n\n\n\n### Simulate \napps_per_dept <- df %>% \n  group_by(discipline) %>% \n  summarize(applications = sum(applications))\n\n# simulate as if all applications are from males\ndff <- apps_per_dept %>% \n  mutate(gender = 1) %>%\n  uncount(applications) %>%\n  mutate(applications = 1L)\n\n# simulate as if all applications are from females\ndfm <- apps_per_dept %>% \n  mutate(gender = 2) %>%\n  uncount(applications) %>%\n  mutate(applications = 1L)\n\nmarg_eff <- bind_rows(add_epred_draws(dff, m2),\n                      add_epred_draws(dfm, m2)) %>% \n  pivot_wider(names_from = \"gender\", values_from = \".epred\") %>%\n  rename(female = \"1\",\n         male = \"2\") %>% \n  mutate(contrast = female - male)\n\nggplot(marg_eff, aes(contrast)) + \n  geom_density() + \n  theme_classic() + \n  labs(x = \"Contrast F-M (marginal)\")\n\n\n\n\nEffect size and direction varies widely across departments - leading to a direct effect of gender having a very wide spread, with most of the density showing a disadvantage towards women but some notable exceptions."
  },
  {
    "objectID": "homework/homework-05.html#question-3-considering-the-total-effect-problem-1-and-direct-effect-problem-2-of-gender-what-causes-contribute-to-the-average-difference-between-women-and-men-in-award-rate-in-this-sample-it-is-not-necessary-to-say-whether-or-not-there-is-evidence-of-discrimination-or-the-presence-or-absence-of-unobserved-confounds-which-are-likely.-simply-explain-how-the-direct-effects-you-have-estimated-make-sense-or-not-of-the-total-effect.",
    "href": "homework/homework-05.html#question-3-considering-the-total-effect-problem-1-and-direct-effect-problem-2-of-gender-what-causes-contribute-to-the-average-difference-between-women-and-men-in-award-rate-in-this-sample-it-is-not-necessary-to-say-whether-or-not-there-is-evidence-of-discrimination-or-the-presence-or-absence-of-unobserved-confounds-which-are-likely.-simply-explain-how-the-direct-effects-you-have-estimated-make-sense-or-not-of-the-total-effect.",
    "title": "Homework - Week 05",
    "section": "Question 3: Considering the total effect (problem 1) and direct effect (problem 2) of gender, what causes contribute to the average difference between women and men in award rate in this sample? It is not necessary to say whether or not there is evidence of discrimination or the presence or absence of unobserved confounds (which are likely!). Simply explain how the direct effects you have estimated make sense (or not) of the total effect.",
    "text": "Question 3: Considering the total effect (problem 1) and direct effect (problem 2) of gender, what causes contribute to the average difference between women and men in award rate in this sample? It is not necessary to say whether or not there is evidence of discrimination or the presence or absence of unobserved confounds (which are likely!). Simply explain how the direct effects you have estimated make sense (or not) of the total effect.\nWe see that gender has a total effect of ~ 3% discrimination, and the model also shows that there is an effect of department - so the effect of gender acting through department is also important. We can plot this:\n\n# calculate percent of each discipline that is male/female \n\nt <- df %>%\n  mutate(total_f = sum(applications[gender == 1]),\n         total_m = sum(applications[gender == 2])) %>%\n  group_by(discipline) %>%\n  summarize(pDF = sum(applications[gender == 1])/total_f,\n         pDM = sum(applications[gender == 2])/total_m,\n         nApp = sum(applications),\n         nAwa = sum(awards),\n         pAwa = nAwa/nApp) %>%\n  unique()\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'discipline'. You can override using the\n`.groups` argument.\n\npost <- df %>%\n  data_grid(gender, discipline, applications) %>%\n  add_linpred_draws(m2) %>%\n  ungroup() %>%\n  select(-.row) %>%\n  spread(gender, .linpred) %>%\n  rename(female = '1', \n         male = '2') %>%\n  group_by(discipline) %>%\n  summarize(mean_pFA = mean(inv_logit_scaled(female)), \n            mean_pMA = mean(inv_logit_scaled(male))) %>%\n  mutate(award_dominant = if_else(mean_pMA > mean_pFA, \"male\", \"female\")) %>%\n  select(-discipline)\n\nfull <- cbind(t, post)\n\nggplot(full) + \n  geom_point(aes(x = pDF, y = pDM, colour = award_dominant)) + \n  geom_abline(intercept = 0, slope = 1) + \n  geom_text(aes(x = pDF, y = pDM, label = round(pAwa, 2)), check_overlap = T) + \n  theme_classic()\n\n\n\n\nBelow the line, there relatively larger proportion of women applied to the disciplines below the diagonal line. Numbers represent award success rates. Colours correspond to which gender receives more awards."
  },
  {
    "objectID": "homework/homework-05.html#question-4-the-data-in-dataufclefties-are-the-outcomes-of-205-ultimate-fighting-championship-ufc-matches-see-ufclefties-for-details.-it-is-widely-believed-that-left-handed-fighters-aka-southpaws-have-an-advantage-against-right-handed-fighters-and-left-handed-men-are-indeed-over-represented-among-fighters-and-fencers-and-tennis-players-compared-to-the-general-population.-estimate-the-average-advantage-if-any-that-a-left-handed-fighter-has-against-right-handed-fighters.-based-upon-your-estimate-why-do-you-think-left-handers-are-over-represented-among-ufc-fighters",
    "href": "homework/homework-05.html#question-4-the-data-in-dataufclefties-are-the-outcomes-of-205-ultimate-fighting-championship-ufc-matches-see-ufclefties-for-details.-it-is-widely-believed-that-left-handed-fighters-aka-southpaws-have-an-advantage-against-right-handed-fighters-and-left-handed-men-are-indeed-over-represented-among-fighters-and-fencers-and-tennis-players-compared-to-the-general-population.-estimate-the-average-advantage-if-any-that-a-left-handed-fighter-has-against-right-handed-fighters.-based-upon-your-estimate-why-do-you-think-left-handers-are-over-represented-among-ufc-fighters",
    "title": "Homework - Week 05",
    "section": "Question 4: The data in data(UFClefties) are the outcomes of 205 Ultimate Fighting Championship (UFC) matches (see ?UFClefties for details). It is widely believed that left-handed fighters (aka “Southpaws”) have an advantage against right-handed fighters, and left-handed men are indeed over-represented among fighters (and fencers and tennis players) compared to the general population. Estimate the average advantage, if any, that a left-handed fighter has against right-handed fighters. Based upon your estimate, why do you think left-handers are over-represented among UFC fighters?",
    "text": "Question 4: The data in data(UFClefties) are the outcomes of 205 Ultimate Fighting Championship (UFC) matches (see ?UFClefties for details). It is widely believed that left-handed fighters (aka “Southpaws”) have an advantage against right-handed fighters, and left-handed men are indeed over-represented among fighters (and fencers and tennis players) compared to the general population. Estimate the average advantage, if any, that a left-handed fighter has against right-handed fighters. Based upon your estimate, why do you think left-handers are over-represented among UFC fighters?"
  },
  {
    "objectID": "notes/notes-04.html",
    "href": "notes/notes-04.html",
    "title": "Lecture 04 - Categories & Curves",
    "section": "",
    "text": "Rose: learning what GAMs are , thinking of age/time as a cause\nThorn: I haven’t taken time to fix the plot code from the lectures"
  },
  {
    "objectID": "notes/notes-04.html#drawing-inferences",
    "href": "notes/notes-04.html#drawing-inferences",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Drawing Inferences",
    "text": "Drawing Inferences\n\nlinear model can accomodate anything, thus we need to think carefully about our scientific model\ngenerative model + multiple estimands = multiple estimators\nquite often the estimate we want is not in a summary table because it depends on multiple unknowns, so we often need to do post-processing"
  },
  {
    "objectID": "notes/notes-04.html#categories",
    "href": "notes/notes-04.html#categories",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Categories",
    "text": "Categories\n\ncategories are discrete and non-linear\ndiscrete, unordered types\nwe want to stratify by category, to fit a separate line for each"
  },
  {
    "objectID": "notes/notes-04.html#howell-data",
    "href": "notes/notes-04.html#howell-data",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Howell Data",
    "text": "Howell Data\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\nLoading required package: ggplot2\n\n\nrstan (Version 2.21.8, GitRev: 2e1f913d3ca3)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\n\n\nLoading required package: cmdstanr\n\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/icrichmond/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\n\n\nA newer version of CmdStan is available. See ?install_cmdstan() to install it.\nTo disable this check set option or environment variable CMDSTANR_NO_VER_CHECK=TRUE.\n\n\nLoading required package: parallel\n\n\nrethinking (Version 2.21)\n\n\n\nAttaching package: 'rethinking'\n\n\nThe following object is masked from 'package:rstan':\n\n    stan\n\n\nThe following object is masked from 'package:stats':\n\n    rstudent\n\n\n\nhow are height, weight, and sex causally related?\n\n\nd <- dagitty(\"dag {\n                H -> W\n                S -> W\n                S -> H\n             }\")\n\ndrawdag(d)\n\n\n\n\n\nheight influences weight\nsex influences weight and height\nweight is influenced by height and sex\ninfluence of sex is both direct and indirect on weight\n\\(H = f_{H}(S)\\)\n\\(W = f_{W}(H,S)\\)\nUnobserved causes are ignorable unless they are shared between variables (common cause) = confound\n\n\nsim_HW <- function(S, b, a){\n  N <- length(S)\n  H <- ifelse(S==1, 150, 160) + rnorm(N, 0, 5)\n  W <- a[S] + b[S]*H + rnorm(N, 0, 5)\n  data.frame(S, H, W)\n}\n\nS <- rbern(100)+1\ndat <- sim_HW(S, b=c(0.5, 0.6), a=c(0,0))\nhead(dat)\n\n  S        H         W\n1 1 148.8953  74.34442\n2 2 157.6056 100.51366\n3 2 156.8335  96.37301\n4 2 167.7319  94.88396\n5 1 146.9694  70.03269\n6 1 149.1277  69.26776\n\n\n\nscientific questions:\n\ncausal effect of H on W?\ncausal effect of S on W?\ndirect causal effect of S on W?\n\nwe need to stratify by S to answer qs 2 and 3\ncoding categorical variables\n\nindicator variables (0/1)\nindex variables (1,2,3,4)\nindex variables are generally preferable\n\nindex variables\n\noften we want to give each index the same prior\n\ntotal causal effect of sex\n\n\nS <- rep(1, 100)\nsimF <- sim_HW(S, b=c(0.5, 0.6), a=c(0,0))\n\nS <- rep(2, 100)\nsimM <- sim_HW(S, b=c(0.5, 0.6), a=c(0,0))\n\n# effect of sex (male-female)\nmean(simM$W - simF$W)\n\n[1] 21.91672\n\n\n\nestimating model and synthetic example\n\n\nS <- rbern(100)+1\ndat <- sim_HW(S, b = c(0.5,0.6), a = c(0,0))\n\nm_SW <- quap(alist(\n  W ~ dnorm(mu, sigma),\n  mu <- a[S],\n  a[S] ~ dnorm(60, 10),\n  sigma ~ dunif(0, 10)\n), data = dat)\n\nprecis(m_SW, depth = 2)\n\n           mean        sd     5.5%     94.5%\na[1]  74.465314 0.7411120 73.28087 75.649754\na[2]  96.098903 0.8361223 94.76262 97.435188\nsigma  5.560622 0.3935710  4.93162  6.189625\n\n\n\nanalyze the real sample\n\n\nd <- Howell1\nd <- d[ d$age >= 18,]\n\ndat <- list(\n  W = d$weight,\n  S = d$male + 1\n)\n\nm_SW <- quap(alist(\n  W ~ dnorm(mu, sigma), \n  mu <- a[S],\n  a[S] ~ dnorm(60, 10),\n  sigma ~ dunif(0, 10)\n), data = dat)\n\n\nposterior means and predictions\n\n\n# posterior mean W\npost <- extract.samples(m_SW)\ndens(post$a[,1])\n\n\n\n#dens(post$a[,2], add = T)\n\n# posterior W predictions\nW1 <- rnorm(1000, post$a[,1], post$sigma)\nW2 <- rnorm(1000, post$a[,2], post$sigma)\ndens(W1)\n\n\n\n#dens(W2, add = T)\n\n# contrast\nW_contrast <- W2 - W1\ndens(W_contrast)\n\n\n\n# proportion above zero\nsum(W_contrast > 0)/1000\n\n[1] 0.811\n\nsum(W_contrast < 0)/1000\n\n[1] 0.189\n\n\n\ncontrasting\n\nneed to compute the difference between the categories\nit is not legitimate to compare overlap in distributions\nwe must compute contrast distribution\n\n\n\nmu_contrast <- post$a[,2] - post$a[,1]\ndens(mu_contrast)\n\n\n\n\n\n“controlling” for the indirect effect of sex through height\n\n\nS <- rbern(100)+1\n# slopes are the same so there is no effect of height on weight through slope but men are on average 10 kg heavier (intercept 10)\nset.seed(12)\ndat <- sim_HW(S, b = c(0.5, 0.5), a = c(0, 10))\n\n\n\\(W_{i} \\sim Normal(\\mu _{i}, \\sigma)\\)\n\\(\\mu _{i} = \\alpha _{S[i]} + \\beta _{S[i]}(H_{i} - \\bar H)\\)\n\nThis equation centers the height \\((H_{i} - \\bar H)\\)\nCentering H means that alpha represents the average weight of a person with average height\n\\(\\alpha = [\\alpha _{1}, \\alpha _{2}]\\) , \\(\\beta = [\\beta _{1}, \\beta _{2}]\\)\n\nanalyze the sample\n\n\nd <- Howell1\nd <- d[d$age >= 18, ]\ndat <- list(W = d$weight, H = d$height, Hbar = mean(d$height), S = d$male + 1)\n\nm_SHW <- quap(alist(\n  W ~ dnorm(mu, sigma),\n  mu <- a[S] + b[S]*(H-Hbar),\n  a[S] ~ dnorm(60, 10),\n  b[S] ~ dunif(0, 1),\n  sigma ~ dunif(0, 10)\n), data = dat)\n\n\nwe need to compute the difference of expected weight at each height to get the actual estimate that we are looking for (for the direct effect of sex on weight)\n\n\nxseq <- seq(from=130, to=190, len=50)\n\nmuF <- link(m_SHW, data = list(S=rep(1,50), H=xseq, Hbar=mean(d$height)))\n#lines(xseq, apply(muF, 2, mean))\n\nmuM <- link(m_SHW, data = list(S=rep(2,50), H=xseq, Hbar = mean(d$height)))\n#lines(xseq, apply(muM, 2, mean))\n\nmu_contrast <- muF - muM\n\n#plot(NULL, xlim=range(xseq))\n#for (p in c(0.5, 0.6, 0.7, 0.8, 0.9, 0.99))\n#  shade(apply(mu_contrast, 2, PI, prob = p), xseq)\n#abline(h=0)\n\n\nnearly all of the causal effects of S acts through H\n\nwhen we block H, we see very little effect of sex on weight"
  },
  {
    "objectID": "notes/notes-04.html#categorical-variables",
    "href": "notes/notes-04.html#categorical-variables",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Categorical Variables",
    "text": "Categorical Variables\n\ncommon, easy to use with index coding\nuse samples to compute relevant contrasts\nalways summarize (mean, interval) as the last step\nwe want mean difference and not difference of means"
  },
  {
    "objectID": "notes/notes-04.html#curves-from-lines",
    "href": "notes/notes-04.html#curves-from-lines",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Curves from Lines",
    "text": "Curves from Lines\n\nmany non linear relationships\nlinear models can easily fit curves: 2 strategies\n\npolynomials (bad)\nsplines and GAMs (less bad)\n\npolynomial models\n\nstill linear because its an additive function of the parameters\ncreate strange symmetries and explosive uncertainty\nno local smoothing, only global smoothing\ndo not use\n\nsplines\n\ngreat for locally inferred function\nadd together a bunch of locally trained terms\ncan add as many locally trained terms as you want\neach term has a weight and slope and only affects its own region"
  },
  {
    "objectID": "notes/notes-04.html#full-luxury-bayes",
    "href": "notes/notes-04.html#full-luxury-bayes",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Full Luxury Bayes",
    "text": "Full Luxury Bayes\n\ninstead of two models for two estimands, use one model for full causal model\ncan simulate interventions with this approach\n\n\nm_SHW_full <- quap(alist(\n  \n  # weight\n  W ~ dnorm(mu, sigma),\n  mu <- a[S] + b[S]*(H-Hbar),\n  a[S] ~ dnorm(60, 10),\n  b[S] ~ dunif(0, 1),\n  sigma ~ dunif(0, 10),\n  \n  # height\n  H ~ dnorm(nu, tau),\n  nu <- h[S],\n  h[S] ~ dnorm(160, 10),\n  tau ~ dunif(0, 10)\n  \n), data = dat)\n\n\npost <- extract.samples(m_SHW_full)\nHbar <- dat$Hbar\nn <- 1e4\n\nwith(post, {\n  \n  H_S1 <- rnorm(n, h[,1], tau)\n  W_S1 <- rnorm(n, a[,2] + b[,1]*(H_S2-Hbar), sigma)\n  \n  W_do_S <<- W_S2 - W_S1\n  \n})\n\n# automate\nHWsim <- sim(m_SHW_full, data = list(S=c(1,2)), vars = c(\"H\", \"W\"))\nW_do_S_auto <- HWsim$W[,2] - HWsim$W[,1]\n\n\nyou can either do one statistical model for each estimand OR one simulation for each estimand (full luxury Bayes)"
  },
  {
    "objectID": "notes/notes-04.html#todo",
    "href": "notes/notes-04.html#todo",
    "title": "Lecture 04 - Categories & Curves",
    "section": "TODO:",
    "text": "TODO:\n\nfix weird plot erroring"
  },
  {
    "objectID": "notes/notes-02.html",
    "href": "notes/notes-02.html",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "",
    "text": "Rose: remembering that posterior distributions are relative probabilities is a great foundation to move forward on\nThorn: equations are harddd + baseR + installing rstan + misclassification ahh"
  },
  {
    "objectID": "notes/notes-02.html#globe-example",
    "href": "notes/notes-02.html#globe-example",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Globe Example",
    "text": "Globe Example\nestimand: proportion of the globe covered in water - do people know what an estimand is?"
  },
  {
    "objectID": "notes/notes-02.html#generative-model-globe",
    "href": "notes/notes-02.html#generative-model-globe",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Generative Model (globe)",
    "text": "Generative Model (globe)\n\nstart with how the variables influence each other, i.e., causal model\n\n\nlibrary(dagitty)\nlibrary(rethinking)\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\nLoading required package: ggplot2\n\n\nrstan (Version 2.21.8, GitRev: 2e1f913d3ca3)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\n\n\nLoading required package: cmdstanr\n\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/icrichmond/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\n\n\nA newer version of CmdStan is available. See ?install_cmdstan() to install it.\nTo disable this check set option or environment variable CMDSTANR_NO_VER_CHECK=TRUE.\n\n\nLoading required package: parallel\n\n\nrethinking (Version 2.21)\n\n\n\nAttaching package: 'rethinking'\n\n\nThe following object is masked from 'package:rstan':\n\n    stan\n\n\nThe following object is masked from 'package:stats':\n\n    rstudent\n\nd <- dagitty(\"dag {\n                p -> W\n                p -> L\n                N -> W \n                N -> L }\")\n\ndrawdag(d)\n\n\n\n\n\\[\nW,L = f(p,N)\n\\]\n\nW and L are functions of p and N"
  },
  {
    "objectID": "notes/notes-02.html#bayesian-data-analysis",
    "href": "notes/notes-02.html#bayesian-data-analysis",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Bayesian Data Analysis",
    "text": "Bayesian Data Analysis\nFor each possible explanation of the sample,\n\ncount all the ways the sample could happen\nexplanations with more ways to produce the sample are more plausible"
  },
  {
    "objectID": "notes/notes-02.html#garden-of-forking-data",
    "href": "notes/notes-02.html#garden-of-forking-data",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Garden of Forking Data",
    "text": "Garden of Forking Data\n\nrelies on samples being independent\nrelative differences between probabilities are dependent on sample size (differences will be smaller with smaller sample sizes because there is less evidence)\nnormalizing to probability allows for interpretability and easier math\ncollection of probabilities is a posterior distribution\n\nADD CODE (minute 35):\n\nsample <- c(\"W\", \"L\", \"W\", \"W\", \"W\", \"L\", \"W\", \"L\", \"W\")\n\nW <- sum(sample==\"W\")\nL <- sum(sample==\"L\")\np <- c(0, 0.25, 0.5, 0.75, 1)\nways <- sapply(p, function(q) (q*4)^W * ((1-q)*4)^L)\nprob <- ways/sum(ways)\ncbind(p, ways, prob)\n\n        p ways       prob\n[1,] 0.00    0 0.00000000\n[2,] 0.25   27 0.02129338\n[3,] 0.50  512 0.40378549\n[4,] 0.75  729 0.57492114\n[5,] 1.00    0 0.00000000"
  },
  {
    "objectID": "notes/notes-02.html#testing",
    "href": "notes/notes-02.html#testing",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Testing",
    "text": "Testing\n\nhave to test\ntest using extreme values where you intuitively know the right answer\n\n\nsim_globe <- function(p = 0.7, N = 9){\n  \n  sample(c(\"W\", \"L\"), size = N, prob=c(p, 1-p), replace = T)\n}\n\nsim_globe()\n\n[1] \"W\" \"L\" \"W\" \"W\" \"W\" \"L\" \"L\" \"W\" \"L\"\n\nsim_globe(p=1, N=11) \n\n [1] \"W\" \"W\" \"W\" \"W\" \"W\" \"W\" \"W\" \"W\" \"W\" \"W\" \"W\"\n\nsum(sim_globe(p=0.5, N=1e4) == \"W\")/1e4\n\n[1] 0.4917\n\n\nFunction:\n\nlibrary(crayon)\n\n\nAttaching package: 'crayon'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    %+%\n\nmake_bar <- function(q,size=20) {\n    n <- round(q*size)\n    s1 <- concat( rep(\"#\",n) )\n    s2 <- concat( rep(\" \",size-n) )\n    concat(s1,s2)\n}\n\ncompute_posterior <- function(the_sample, poss = c(0,0.25,0.5,0.75,1)){\n  W <- sum(the_sample==\"W\")\n  L <- sum(the_sample==\"L\")\n  ways <- sapply(poss, function(q) (q*4)^W * ((1-q)*4)^L)\n  post <- ways/sum(ways)\n  bars <- sapply(post, function(q) make_bar(q))\n  data.frame(poss, ways, post = round(post,3), bars)\n}\n\ncompute_posterior(sim_globe())\n\n  poss ways  post                 bars\n1 0.00    0 0.000                     \n2 0.25   27 0.021                     \n3 0.50  512 0.404 ########            \n4 0.75  729 0.575 ###########         \n5 1.00    0 0.000"
  },
  {
    "objectID": "notes/notes-02.html#real-number-sampling",
    "href": "notes/notes-02.html#real-number-sampling",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Real Number Sampling",
    "text": "Real Number Sampling\n\nmore possibilities = less probability in each option/outcome\n\nprobability is spread out across many options\n\nnormalizing to probability allows our equation to calculate infinite number of “sides”/outcomes\n\n\\[\np^W(1-p)^L\n\\]\np = probability\ndensity = probability when we are assessing infinite number of possibilities\n\nshape of the posterior embodies sample size\n\nno min sample size -> just more uncertain posterior\nposterior distribution embodies sample size\n\nno point estimates! estimate is entire posterior distribution\n\ncan use summary points from post dist for communication purposes\n\nintervals are merely indicators of the shape of the posterior distribution\n\nno “true interval” i.e., 95% CI doesn’t exist\ninterval is just distribution lower/upper bounds"
  },
  {
    "objectID": "notes/notes-02.html#analyze-sample-summarize",
    "href": "notes/notes-02.html#analyze-sample-summarize",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Analyze Sample + Summarize",
    "text": "Analyze Sample + Summarize\n\npost_samples <- rbeta(1e3, 6+1, 3+1)\n\ndens(post_samples, lwd = 4, col = 2, xlab = \"prop water\", adj = 0.1)\n\ncurve(dbeta(x, 6+1, 3+1), add = T, lty = 2, lwd = 3)\n\n\n\n\n\nposterior prediction = “what would we bet?”\n\nhow many W’s do we expect to see in the next 10 tosses\n\nfor each sample of post dist, we can create a predictive distribution, then posterior predictive\n\nincorporates uncertainty from posterior distribution\n\n\n\npost_samples <- rbeta(1e4, 6+1, 3+1)\n\npred_post <- sapply(post_samples, function(p) \nsum(sim_globe(p, 10)==\"W\"))\n\ntab_post <- table(pred_post)\n\n#for (i in 0:10) lines(c(i,i),c(0,tab_post[i+1]), lwd = 4, col = 4)"
  },
  {
    "objectID": "notes/notes-02.html#misclassification-bonus-round",
    "href": "notes/notes-02.html#misclassification-bonus-round",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Misclassification (Bonus Round)",
    "text": "Misclassification (Bonus Round)\n\nW* is misclassified due to sampling error and measurement process\n\ntrue W is unknown\n\n\n\nlibrary(dagitty)\nlibrary(rethinking)\n\nd <- dagitty(\"dag {\n                p -> W\n                N -> W\n                W -> Wm\n                M -> Wm\n             }\")\n\ndrawdag(d)\n\n\n\n\n\nincorporate measurement error with x (error rate of 10%)\n\n\nsim_globe2 <- function(p = 0.7, N = 9, x = 0.1){\n  \n  true_sample <- sample(c(\"W\", \"L\"), size = N, prob = c(p, 1-p), replace = T)\n  \n  obs_sample <- ifelse(runif(N) < x,\n                       ifelse(true_sample == \"W\", \"L\", \"W\"),\n                       true_sample)\n  \n  return(obs_sample)\n  \n}\n\n\nhow do you know the error rate?\ndon’t understand mechanism behind incorporating x but understand why x needs to be incorporated + consequences of not"
  },
  {
    "objectID": "notes/notes-02.html#todo",
    "href": "notes/notes-02.html#todo",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "TODO",
    "text": "TODO\n\nDAG coords\nRead misclassification in 3rd ed."
  },
  {
    "objectID": "notes/notes-10.html#rose-thorn",
    "href": "notes/notes-10.html#rose-thorn",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Rose / Thorn",
    "text": "Rose / Thorn\nRose:\nThorn:"
  },
  {
    "objectID": "notes/notes-10.html#generalized-linear-models",
    "href": "notes/notes-10.html#generalized-linear-models",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Generalized Linear Models",
    "text": "Generalized Linear Models\n\nExpected value is some function of an additive combination of parameters\nuniform changes in predictor not uniform changes in prediction\nall predictor variables interact and moderate one another\ninlfuences predictions and uncertainty of predictions"
  },
  {
    "objectID": "notes/notes-10.html#confounded-admissions",
    "href": "notes/notes-10.html#confounded-admissions",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Confounded Admissions",
    "text": "Confounded Admissions\n\nability is a confound for admissions\n\n\n\n\n\ninclude confound in the model:\n\n\n# continuing from UCBadmit example\n# what happens when there is a confound?\n\nset.seed(17)\nN <- 2000 # number of applicants\n# even gender distribution\nG <- sample( 1:2 , size=N , replace=TRUE )\n# sample ability, high (1) to average (0)\nu <- rbern(N,0.1)\n# gender 1 tends to apply to department 1, 2 to 2\n# and G=1 with greater ability tend to apply to 2 as well\nD <- rbern( N , ifelse( G==1 , u*0.5 , 0.8 ) ) + 1\n# matrix of acceptance rates [dept,gender]\naccept_rate_u0 <- matrix( c(0.1,0.1,0.1,0.3) , nrow=2 )\naccept_rate_u1 <- matrix( c(0.2,0.3,0.2,0.5) , nrow=2 )\n# simulate acceptance\np <- sapply( 1:N , function(i) \n    ifelse( u[i]==0 , accept_rate_u0[D[i],G[i]] , accept_rate_u1[D[i],G[i]] ) )\nA <- rbern( N , p )\n\ntable(G,D)\ntable(G,A)\n\ndat_sim <- list( A=A , D=D , G=G )\n\n# total effect gender\nm1 <- ulam(\n    alist(\n        A ~ bernoulli(p),\n        logit(p) <- a[G],\n        a[G] ~ normal(0,1)\n    ), data=dat_sim , chains=4 , cores=4 )\n\npost1 <- extract.samples(m1)\npost1$fm_contrast <- post1$a[,1] - post1$a[,2]\nprecis(post1)\n\n# direct effects - now confounded!\nm2 <- ulam(\n    alist(\n        A ~ bernoulli(p),\n        logit(p) <- a[G,D],\n        matrix[G,D]:a ~ normal(0,1)\n    ), data=dat_sim , chains=4 , cores=4 )\n\nprecis(m2,3)\n\n# contrast\npost2 <- extract.samples(m2)\npost2$fm_contrast_D1 <- post2$a[,1,1] - post2$a[,2,1]\npost2$fm_contrast_D2 <- post2$a[,1,2] - post2$a[,2,2]\nprecis(post2)\n\ndens( post2$fm_contrast_D1 , lwd=4 , col=4 , xlab=\"F-M contrast in each department\" )\ndens( post2$fm_contrast_D2 , lwd=4 , col=2 , add=TRUE )\nabline(v=0,lty=3)\n\ndens( post2$a[,1,1] , lwd=4 , col=2 , xlim=c(-3,1) )\ndens( post2$a[,2,1] , lwd=4 , col=4 , add=TRUE )\ndens( post2$fm_contrast_D1 , lwd=4 , add=TRUE )\n\ndens( post2$a[,1,2] , lwd=4 , col=2 , add=TRUE , lty=4 )\ndens( post2$a[,2,2] , lwd=4 , col=4 , add=TRUE , lty=4)\ndens( post2$fm_contrast_D2 , lwd=4 , add=TRUE , lty=4)\n\n\nsorting can mask a lot of things through collider bias"
  },
  {
    "objectID": "notes/notes-10.html#citation-networks",
    "href": "notes/notes-10.html#citation-networks",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Citation Networks",
    "text": "Citation Networks\n\n\n\n\n\n\nin the absence of strong causal assumptions, we can’t conclude anything\nproxies for quality are often poor proxies (e.g., citations)\nif you want causal inference, you must make causal assumptions"
  },
  {
    "objectID": "notes/notes-10.html#sensitivity-analysis",
    "href": "notes/notes-10.html#sensitivity-analysis",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Sensitivity Analysis",
    "text": "Sensitivity Analysis\n\nwhat are the implications of what we don’t know?\nassume confound exists, model its consequences for different strengths/kinds of influence\nhow strong must the confound be to change conclusions?\ninclude quality as an unobserved variable\n\nchange parameter size/strength to test the effect of unobserved confound\n\n\n\n# sensitivity\n\ndat_sim$D2 <- ifelse( D==2 , 1 , 0 )\ndat_sim$b <- c(1,1)\ndat_sim$g <- c(1,0)\ndat_sim$N <- length(dat_sim$D2)\n\nm3s <- ulam(\n    alist( \n        # A model\n        A ~ bernoulli(p),\n        logit(p) <- a[G,D] + b[G]*u[i],\n        matrix[G,D]:a ~ normal(0,1),\n\n        # D model\n        D2 ~ bernoulli(q),\n        logit(q) <- delta[G] + g[G]*u[i],\n        delta[G] ~ normal(0,1),\n\n        # declare unobserved u\n        vector[N]:u ~ normal(0,1)\n    ), data=dat_sim , chains=4 , cores=4 )\n\nprecis(m3s,3,pars=c(\"a\",\"delta\"))\n\npost3s <- extract.samples(m3s)\npost3s$fm_contrast_D1 <- post3s$a[,1,1] - post3s$a[,2,1]\npost3s$fm_contrast_D2 <- post3s$a[,1,2] - post3s$a[,2,2]\n\ndens( post2$fm_contrast_D1 , lwd=1 , col=4 , xlab=\"F-M contrast in each department\" , xlim=c(-2,1) )\ndens( post2$fm_contrast_D2 , lwd=1 , col=2 , add=TRUE )\nabline(v=0,lty=3)\ndens( post3s$fm_contrast_D1 , lwd=4 , col=4 , add=TRUE )\ndens( post3s$fm_contrast_D2 , lwd=4 , col=2 , add=TRUE )\n\nplot( jitter(u) , apply(post3s$u,2,mean) , col=ifelse(G==1,2,4) , lwd=3 )\n\n\nyou can say the strength of the confound needed to undo the results you found\n\nimportant thing to report - don’t pretend confounds don’t exist\ncan’t eliminate possibility of confounding\n\na lot of the most important science cannot be done experimentally so we need to be able to do these things"
  },
  {
    "objectID": "notes/notes-10.html#poisson-counts",
    "href": "notes/notes-10.html#poisson-counts",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Poisson Counts",
    "text": "Poisson Counts\n\n\n\n\n\n\ntotal count is not binomial: no maximum\n\nPoisson distribution: very high maximum and very low probability of each success\n\nPoisson distribution uses the log link - must be positive\n\nexponential scaling can be surprising\nlarge priors makes extremely long tails with very large values\nwant higher mean, lower variance\n\n\n\n# model\n\nlibrary(rethinking)\ndata(Kline)\nd <- Kline\nd$P <- scale( log(d$population) )\nd$contact_id <- ifelse( d$contact==\"high\" , 2 , 1 )\n\ndat <- list(\n    T = d$total_tools ,\n    P = d$P ,\n    C = d$contact_id )\n\n# intercept only\nm11.9 <- ulam(\n    alist(\n        T ~ dpois( lambda ),\n        log(lambda) <- a,\n        a ~ dnorm( 3 , 0.5 )\n    ), data=dat , chains=4 , log_lik=TRUE )\n\n# interaction model\nm11.10 <- ulam(\n    alist(\n        T ~ dpois( lambda ),\n        log(lambda) <- a[C] + b[C]*P,\n        a[C] ~ dnorm( 3 , 0.5 ),\n        b[C] ~ dnorm( 0 , 0.2 )\n    ), data=dat , chains=4 , log_lik=TRUE )\n\ncompare( m11.9 , m11.10 , func=PSIS )\n\nk <- PSIS( m11.10 , pointwise=TRUE )$k\nplot( dat$P , dat$T , xlab=\"log population (std)\" , ylab=\"total tools\" ,\n    col=ifelse( dat$C==1 , 4 , 2 ) , lwd=4+4*normalize(k) ,\n    ylim=c(0,75) , cex=1+normalize(k) )\n# set up the horizontal axis values to compute predictions at\nP_seq <- seq( from=-1.4 , to=3 , len=100 )\n\n# predictions for C=1 (low contact)\nlambda <- link( m11.10 , data=data.frame( P=P_seq , C=1 ) )\nlmu <- apply( lambda , 2 , mean )\nlci <- apply( lambda , 2 , PI )\nlines( P_seq , lmu , lty=2 , lwd=1.5 )\nshade( lci , P_seq , xpd=TRUE , col=col.alpha(4,0.3) )\n\n# predictions for C=2 (high contact)\nlambda <- link( m11.10 , data=data.frame( P=P_seq , C=2 ) )\nlmu <- apply( lambda , 2 , mean )\nlci <- apply( lambda , 2 , PI )\nlines( P_seq , lmu , lty=1 , lwd=1.5 )\nshade( lci , P_seq , xpd=TRUE , col=col.alpha(2,0.3))\n\nidentify( dat$P , dat$T , d$culture )\n\n# natural scale now\n\nplot( d$population , d$total_tools , xlab=\"population\" , ylab=\"total tools\" ,\n    col=ifelse( dat$C==1 , 4 , 2 ) , lwd=4+4*normalize(k) ,\n    ylim=c(0,75) , cex=1+normalize(k) )\nP_seq <- seq( from=-5 , to=3 , length.out=100 )\n# 1.53 is sd of log(population)\n# 9 is mean of log(population)\npop_seq <- exp( P_seq*1.53 + 9 )\nlambda <- link( m11.10 , data=data.frame( P=P_seq , C=1 ) )\nlmu <- apply( lambda , 2 , mean )\nlci <- apply( lambda , 2 , PI )\nlines( pop_seq , lmu , lty=2 , lwd=1.5 )\nshade( lci , pop_seq , xpd=TRUE , col=col.alpha(4,0.3))\n\nlambda <- link( m11.10 , data=data.frame( P=P_seq , C=2 ) )\nlmu <- apply( lambda , 2 , mean )\nlci <- apply( lambda , 2 , PI )\nlines( pop_seq , lmu , lty=1 , lwd=1.5 )\nshade( lci , pop_seq , xpd=TRUE , col=col.alpha(2,0.3) )\n\nidentify( d$population , d$total_tools , d$culture )\n\n\nnumber of effective parameters penalty shows how well the model performs after you drop individual data points\n\ntherefore models with more parameters often have lower effective parameters\n\ngamma-Poisson is the appropriate analog to a student t-test - wider tails\n\n\n# innovation/loss model\n\ndat2 <- list( T=d$total_tools, P=d$population, C=d$contact_id )\nm11.11 <- ulam(\n    alist(\n        T ~ dpois( lambda ),\n        lambda <- exp(a[C])*P^b[C]/g,\n        a[C] ~ dnorm(1,1),\n        b[C] ~ dexp(1),\n        g ~ dexp(1)\n    ), data=dat2 , chains=4 , cores=4 , log_lik=TRUE )\n\nprecis(m11.11,2)\n\nplot( d$population , d$total_tools , xlab=\"population\" , ylab=\"total tools\" ,\n    col=ifelse( dat$C==1 , 4 , 2 ) , lwd=4+4*normalize(k) ,\n    ylim=c(0,75) , cex=1+normalize(k) )\nP_seq <- seq( from=-5 , to=3 , length.out=100 )"
  },
  {
    "objectID": "notes/notes-10.html#count-glms",
    "href": "notes/notes-10.html#count-glms",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Count GLMs",
    "text": "Count GLMs\n\ndistributions from constraints\nmaximum entropy priors: binomial, Poisson, and extensions\nrobust regressions: beta-binomial, gamma-Poisson"
  },
  {
    "objectID": "notes/notes-13.html#rose-thorn",
    "href": "notes/notes-13.html#rose-thorn",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "Rose / Thorn",
    "text": "Rose / Thorn\nRose:\nThorn:"
  },
  {
    "objectID": "notes/notes-13.html#multilevel-adventures",
    "href": "notes/notes-13.html#multilevel-adventures",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "Multilevel Adventures",
    "text": "Multilevel Adventures\n\ncluster: kinds of groups in the data\nfeatures: aspets of the model (parameters) that vary by cluster\ncluster (tanks) -> features (survival)\nadd clusters = more index (categorical) variables, more population priors\nadd features = more parameters, more dimensions in each population prior"
  },
  {
    "objectID": "notes/notes-13.html#varying-effects",
    "href": "notes/notes-13.html#varying-effects",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "Varying Effects",
    "text": "Varying Effects\n\na way for us to try and estimate unmeasured confounds\nvarying effect strategy: unmeasured features of clusters leave an imprint on the data that can be measured by 1) repeat observations of each cluster and 2) partial pooling among clusters\npredictive perspective: important source of cluster-level variation, regularize\ncausal perspective: competing causes or unobserved confounds\ninterested in varying effects from a predictive and a causal perspective\nfixed effects: varying effects with variance fixed at infinity, no pooling"
  },
  {
    "objectID": "notes/notes-13.html#practical-difficulties",
    "href": "notes/notes-13.html#practical-difficulties",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "Practical Difficulties",
    "text": "Practical Difficulties\n\nvarying effects are a good default but come with difficulties\n\nhow to use more than one cluster type at the same time?\nhow to calculate predictions\nhow to sample chains efficiently\ngroup-level confounding"
  },
  {
    "objectID": "notes/notes-13.html#varying-districts",
    "href": "notes/notes-13.html#varying-districts",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "Varying Districts",
    "text": "Varying Districts\n\ncluster by district\nestimand: C in each district, partially pooled\nvarying intercept on each district\n\\(C_i \\sim Bernoulli(p_i)\\)\n\\(logit(p_i) = \\alpha_{D[i]}\\)\n\\(\\alpha_j \\sim Normal(\\bar{\\alpha}, \\sigma)\\)\n\\(\\bar{\\alpha} \\sim Normal(0,1)\\)\n\\(\\sigma \\sim Exponential(1)\\)\n\n\n# simple varying intercepts model\nlibrary(rethinking)\ndata(bangladesh)\nd <- bangladesh\n\ndat <- list(\n    C = d$use.contraception,\n    D = as.integer(d$district) )\n\nmCD <- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) <- a[D],\n        vector[61]:a ~ normal(abar,sigma),\n        abar ~ normal(0,1),\n        sigma ~ exponential(1)\n    ) , data=dat , chains=4 , cores=4 )\n\n\n# plot estimates\np <- link( mCD , data=list(D=1:61) )\n# blank2(w=2)\nplot( NULL , xlab=\"district\" , lwd=3 , col=2 , xlim=c(1,61), ylim=c(0,1) , ylab=\"prob use contraception\" )\n\npoints( 1:61 , apply(p,2,mean) , xlab=\"district\" , lwd=3 , col=2 , ylim=c(0,1) , ylab=\"prob use contraception\" )\n\n for ( i in 1:61 ) lines( c(i,i) , PI(p[,i]) , lwd=8 , col=col.alpha(2,0.5) )\n\n# show raw proportions - have to skip 54\nn <- table(dat$D)\nCn <- xtabs(dat$C ~ dat$D)\npC <- as.numeric( Cn/n )\npC <- c( pC[1:53] , NA , pC[54:60] )\npoints( pC , lwd=2 )\n\n# only some labels via locator\nn <- table(dat$D)\nn <- as.numeric(n)\nn <- c( n[1:53] , 0 , n[54:60] )\nidentify( 1:61 , pC , labels=n , cex=1 )\n\n\npartial pooling shrinks districts with low sampling towards mean\n\nbetter predictions\n\nwhat is the effect of urban living? District features are potential group-level confounds\neach district\n\\(C_i \\sim Bernoulli(p_i)\\)\n\\(logit(p_i) = \\alpha_{D[i]} + \\beta_{D[i]}U_i\\)\n\\(\\alpha_j \\sim Normal(\\bar{\\alpha}, \\sigma)\\) = regularizing prior for rural\n\\(\\beta_j \\sim Normal(\\bar{\\beta}, \\tau)\\) = regularizing prior for urban effect\n\\(\\bar{\\alpha}, \\bar{\\beta} \\sim Normal(0,1)\\) = averages\n\\(\\sigma, \\tau \\sim Exponential(1)\\) = standard deviations\n\n\ndat <- list(\n    C = d$use.contraception,\n    D = as.integer(d$district),\n    U = ifelse(d$urban==1,1,0) )\n\n# total U\nmCDU <- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) <- a[D] + b[D]*U,\n        vector[61]:a ~ normal(abar,sigma),\n        vector[61]:b ~ normal(bbar,tau),\n        c(abar,bbar) ~ normal(0,1),\n        c(sigma,tau) ~ exponential(1)\n    ) , data=dat , chains=4 , cores=4 )\n\ntraceplot(mCDU,pars=\"tau\",lwd=2,n_cols=1)\ntrankplot(mCDU,pars=\"tau\",lwd=3,n_cols=1)\n\n# non-centered version\nmCDUnc <- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) <- a[D] + b[D]*U,\n        # define effects using other parameters\n        save> vector[61]:a <<- abar + za*sigma,\n        save> vector[61]:b <<- bbar + zb*tau,\n        # z-scored effects\n        vector[61]:za ~ normal(0,1),\n        vector[61]:zb ~ normal(0,1),\n        # ye olde hyper-priors\n        c(abar,bbar) ~ normal(0,1),\n        c(sigma,tau) ~ exponential(1)\n    ) , data=dat , chains=4 , cores=4 )\n\n# plot estimates\n\nUval <- 0\nxcol <- ifelse(Uval==0,2,4)\np <- link( mCDUnc , data=list(D=1:61,U=rep(Uval,61)) )\n# blank2(w=2,h=0.8)\nplot( NULL , xlab=\"district\" , lwd=3 , col=2 , xlim=c(1,61), ylim=c(0,1) , ylab=\"prob use contraception\" )\nabline(h=0.5,lty=2,lwd=0.5)\n\npoints( 1:61 , apply(p,2,mean) , xlab=\"district\" , lwd=3 , col=xcol , ylim=c(0,1) , ylab=\"prob use contraception\" )\n\n for ( i in 1:61 ) lines( c(i,i) , PI(p[,i]) , lwd=8 , col=col.alpha(xcol,0.5) )\n\n# show raw proportions - have to skip 54\nn <- table(dat$D,dat$U)\nCn <- xtabs(dat$C ~ dat$D + dat$U)\npC <- as.numeric( Cn[,Uval+1]/n[,Uval+1] )\npC <- c( pC[1:53] , NA , pC[54:60] )\npoints( pC , lwd=2 )\n\n# only some labels via locator\nnn <- as.numeric(n[,Uval+1])\nnn <- c( nn[1:53] , 0 , nn[54:60] )\nidentify( 1:61 , pC , labels=nn , cex=1 )\n\n# show standard deviations\npost <- extract.samples(mCDUnc)\ndens(post$sigma,xlab=\"posterior standard deviation\",lwd=3,col=2,xlim=c(0,1.2))\ndens(post$tau,lwd=3,col=4,add=TRUE,adj=0.2)\ncurve(dexp(x,1),from=0,to=1.3,add=TRUE,lwd=2,lty=2)\n\n\npriors inside of priors is good for models but can create ill-fitting models\nthe more you cut up the data because of different varying effects, the sample sizes will inevitably get smaller -> partial pooling helps"
  },
  {
    "objectID": "notes/notes-01.html",
    "href": "notes/notes-01.html",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "",
    "text": "Rose: excited for fewer examples + sensitivity analyses\nBONUS: I LOVE DAGS\nThorn: i am having a hard time imagining/extending my thinking re: causal imputation + unique null hypotheses (focus on causation)"
  },
  {
    "objectID": "notes/notes-01.html#third-edition",
    "href": "notes/notes-01.html#third-edition",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "Third Edition",
    "text": "Third Edition\n\npeach boxes instead of blue boxes"
  },
  {
    "objectID": "notes/notes-01.html#causal-inference",
    "href": "notes/notes-01.html#causal-inference",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "Causal Inference",
    "text": "Causal Inference\n\nstatistical models require scientific (causal) models\ncorrelation is a very limited measure of association\n\nassociation can occur without correlation\n\ncausal prediction = prediction of the consequences of an intervention (implications of changing one variable on another variable)\n\nknowing the cause of an action allows you to create predictions\n\ncausal imputation = knowing the cause of an action allows you to reconstruct possible outcomes (i.e., what if I had done something else?)"
  },
  {
    "objectID": "notes/notes-01.html#dags",
    "href": "notes/notes-01.html#dags",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "DAGs",
    "text": "DAGs\n\nabstract causal models: includes names of variables and their causal relationships\ntells you the consequences of an intervention\nfacilitates you asking scientific questions"
  },
  {
    "objectID": "notes/notes-01.html#golems",
    "href": "notes/notes-01.html#golems",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "Golems",
    "text": "Golems\n\nstatistical models = golems\noften not possible to design and outline a null hypothesis that is meaningful to reject in observational science\n\nwhat is a null ecological community?\n\nthink of good example/explanation for no null ecology/previous two slides\n\nread textbook section\nfocus on third example?\ntakeaway is that null hypothesis does not give you cause/process behind outcome\n\nwhat is your null? is it unique?"
  },
  {
    "objectID": "notes/notes-01.html#todo",
    "href": "notes/notes-01.html#todo",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "TODO",
    "text": "TODO\n\nread textbook section on null ecology\nagenda\ndiscuss code options"
  },
  {
    "objectID": "notes/notes-08.html#rose-thorn",
    "href": "notes/notes-08.html#rose-thorn",
    "title": "Lecture 08 - Markov chain Monte Carlo",
    "section": "Rose / Thorn",
    "text": "Rose / Thorn\nRose: skateboarding metaphor\nThorn: not understanding parameters in model specification"
  },
  {
    "objectID": "notes/notes-08.html#modelling-approaches",
    "href": "notes/notes-08.html#modelling-approaches",
    "title": "Lecture 08 - Markov chain Monte Carlo",
    "section": "Modelling Approaches",
    "text": "Modelling Approaches\n\nquadratic approximation makes strong assumptions about what the model looks like - approximately Gaussian\nMCMC is intensive but with less assumptions and more flexible"
  },
  {
    "objectID": "notes/notes-08.html#markov-chain-monte-carlo",
    "href": "notes/notes-08.html#markov-chain-monte-carlo",
    "title": "Lecture 08 - Markov chain Monte Carlo",
    "section": "Markov chain Monte Carlo",
    "text": "Markov chain Monte Carlo\n\nchain: sequence of draws from distribution\nMarkov chain: history doesn’t matter, just where you are now\nMonte Carlo: random simulation"
  },
  {
    "objectID": "notes/notes-08.html#hamiltonian-monte-carlo",
    "href": "notes/notes-08.html#hamiltonian-monte-carlo",
    "title": "Lecture 08 - Markov chain Monte Carlo",
    "section": "Hamiltonian Monte Carlo",
    "text": "Hamiltonian Monte Carlo\n\nuses random pathways that follow the distribution of the variables\n\n\ndag <- dagify(\n  S ~ Q + J + X,\n  Q ~ X,\n  J ~ Z,\n  outcome = 'S',\n  latent = 'Q',\n    coords = list(x = c(Q = 0, X = 0, S = 1, J = 1, Z = 2),\n                y = c(X = 0, J = 0, Z = 0, Q = 1, S = 1))\n)\n\nggdag(dag) + theme_dag()\n\n\n\n\n\nEstimand: association between wine quality and wine origin. Stratify by judge for efficiency.\n\n\ndata(Wines2012)\nd <- Wines2012\n\ndat <- list(\n  S = standardize(d$score),\n  J = as.numeric(d$judge), \n  W = as.numeric(d$wine),\n  X = ifelse(d$wine.amer == 1,1,2),\n  Z = ifelse(d$judge.amer == 1,1,2)\n)\n\nmQ <- ulam(alist(\n  S ~ dnorm(mu, sigma), \n  mu <- Q[W],\n  Q[W] ~ dnorm(0, 1), \n  sigma ~ dexp(1)),\n  data = dat, chains = 4, cores = 4)\n\nprecis(mQ, 2)\n\n\ntrace plots: visualization of the Markov chain\nwant more than one chain in order to check convergence\n\nconvergence: each chain explores the right distribution and every chain explores the same distribution\n\nR-hat is chain convergence diagnostic\n\nvariance ratio\nif chains do converge, beginning of the chain and end of chain should be exploring the same place and therefore the chain is stationary\nas total variance (among chains) approaches average variance within chains, R-hat approaches 1\ndoes not guarantee convergence but gives an idea that the chains are working when ~ 1\n\nn_eff = effective samples\n\napproximation of how long the chain would be if each sample was completely independent of the one before it\nwhen samples are autocorrelated, you have fewer effective samples\ntypically n_eff is smaller than number of samples you actually took\n\n\n\nmQO <- ulam(alist(\n  S ~ dnorm(mu, sigma), \n  mu <- Q[W] + O[X],\n  Q[W] ~ dnorm(0, 1),\n  O[X] ~ dnorm(0, 1),\n  sigma ~ dexp(1)),\n  data = dat, chains = 4, cores = 4)\n\nplot(precis(mQO, 2))\n\nmQOJ <- ulam(alist(\n  S ~ dnorm(mu, sigma), \n  mu <- (Q[W] + O[X] - H[J])*D[J],\n  Q[W] ~ dnorm(0, 1),\n  O[X] ~ dnorm(0, 1),\n  H[J] ~ dnorm(0, 1),\n  D[J] ~ dexp(1),\n  sigma ~ dexp(1)),\n  data = dat, chains = 4, cores = 4)\n\nplot(precis(mQOJ, 2))\n\n\noften if there is an issue, it is with your model\n\nloop back to basic scientific questions and assumptions\ndivergent transitions are one of the signs of this - “rejected proposal”"
  },
  {
    "objectID": "notes/notes-listing.html",
    "href": "notes/notes-listing.html",
    "title": "Notes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nDate\n\n\nAuthor\n\n\n\n\n\n\nLecture 01 - The Golem of Prague\n\n\nJan 23, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 02 - The Garden of Forking Data\n\n\nJan 23, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 03 - Geocentric Models\n\n\nFeb 8, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 04 - Categories & Curves\n\n\nFeb 8, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 05 - Elemental Confounds\n\n\nFeb 22, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 06 - Good & Bad Controls\n\n\nFeb 22, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 07 - Fitting Over & Under\n\n\nMar 8, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 08 - Markov chain Monte Carlo\n\n\nMar 8, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 09 - Modeling Events\n\n\nMar 22, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 10 - Counts & Hidden Confounds\n\n\nMar 22, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 11 - Ordered Categories\n\n\nApr 5, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 12 - Multilevel Models\n\n\nApr 5, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 13 - Multilevel Adventures\n\n\nApr 18, 2023\n\n\nIsabella C. Richmond\n\n\n\n\nLecture 14 - Correlated Features\n\n\nApr 19, 2023\n\n\nIsabella C. Richmond\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/notes-03.html",
    "href": "notes/notes-03.html",
    "title": "Lecture 03 - Geocentric Models",
    "section": "",
    "text": "Rose: flow reminder! Retrograde explanation\nThorn: installing rethinking on windows"
  },
  {
    "objectID": "notes/notes-03.html#linear-regressions",
    "href": "notes/notes-03.html#linear-regressions",
    "title": "Lecture 03 - Geocentric Models",
    "section": "Linear Regressions",
    "text": "Linear Regressions\n\nessentially a geocentric model - overly simplified\nseparate from a causal model\nassociations are from the causal model, not the statistical model"
  },
  {
    "objectID": "notes/notes-03.html#gaussian-distributions",
    "href": "notes/notes-03.html#gaussian-distributions",
    "title": "Lecture 03 - Geocentric Models",
    "section": "Gaussian Distributions",
    "text": "Gaussian Distributions\n\nthere are many more ways to end up in the center than to end up on the periphery\nwhy the Gaussian distribution spontaneously occurs in natural systems\ngenerative: if we add fluctuations, we tend towards normal distribution (lots of summed fluctuations in nature)\ninferential: estimating mean and variance, normal distribution is best one to use because it is least informative (no other information present)\nnormal distribution is just a tool for estimating mean/variance because it has widest distribution\n\ndata doesn’t have to be normal to be able to leverage the tool to estimate mean/variance"
  },
  {
    "objectID": "notes/notes-03.html#workflow",
    "href": "notes/notes-03.html#workflow",
    "title": "Lecture 03 - Geocentric Models",
    "section": "Workflow",
    "text": "Workflow\n\nState a clear question\nSketch causal assumptions\nDefine generative model from sketch\nUse generative model to build estimator\nProfit\n\n\nlibrary(rethinking)\nlibrary(dagitty)\ndata(Howell1)"
  },
  {
    "objectID": "notes/notes-03.html#describing-models",
    "href": "notes/notes-03.html#describing-models",
    "title": "Lecture 03 - Geocentric Models",
    "section": "Describing Models",
    "text": "Describing Models\n\\[\nW_{i}= \\beta H_{i} + U_{i}\n\\]\n\\[\nU_{i} \\sim Normal(0, \\sigma)\n\\]\n\\[\nH_{i} \\sim Uniform(130, 170)\n\\]\n\n= is deterministic\n~ is distributional"
  },
  {
    "objectID": "notes/notes-03.html#howell-example",
    "href": "notes/notes-03.html#howell-example",
    "title": "Lecture 03 - Geocentric Models",
    "section": "Howell Example",
    "text": "Howell Example\n\nQuestion: Describe association between adult weight and height\n\n\nd2 <- Howell1[Howell1$age>=18,]\n\n\nScientific model: weight is some function of height and unobserved influences\n\n\nd <- dagitty(\"dag {\n                H -> W\n                U -> W\n             }\")\n\ndrawdag(d)\n\n\n\n\n\\[\nW = f(H, U)\n\\]\n\nGenerative/Statistical model\n\n\nTwo options: dynamic (complex and ongoing) and static\n\nStatic model allows us to imagine changes at specific times and still use a Gaussian distribution\n\nFor adults, weight is a proportion of height plus the influence of unobserved causes\n\n\\[\nW = \\beta H+U\n\\]\n\nsim_weight <- function(H, b, sd){\n  U <- rnorm(length(H), 0, sd)\n  W <- b*H + U\n  return(W)\n}\n\nH <- runif(200, min = 130, max = 170)\nW <- sim_weight(H, b = 0.5, sd = 5)\nplot(W ~ H, col = 2, lwd = 3)\n\n\n\n\n\nwe want to estimate how the average weight changes with height\n\\[\nE(W_{i}|H_{i}) = \\alpha + \\beta H_{i}\n\\]\n\\(E(W_{i}|H_{i})\\) = average weight conditional on height\n\\(\\alpha\\) = intercept (when height is 0, what is weight? Scientifically should be zero but putting it in model to make sure our model is scientifically sound)\n\\(\\beta\\) = slope\nPosterior distribution:\n\n\\[\nPr(\\alpha,\\beta,\\sigma| H_{i}, W_{i}) = \\frac{Pr(W_{i}|H_{i}, \\alpha,\\beta,\\sigma)Pr(\\alpha,\\beta,\\sigma)}{Z}\n\\]\n\\(W_{i} \\sim Normal(\\mu _{i}), \\sigma)\\)\n\\(\\mu _{i} = \\alpha + \\beta H_{i}\\)\nalpha, sigma, beta are unknown so we need a posterior distribution for them (and they are dependent on the data)\n\\(Pr(\\alpha,\\beta,\\sigma| H_{i}, W_{i})\\) = posterior probability of specific line\n\\(Pr(W_{i}|H_{i}, \\alpha,\\beta,\\sigma)\\) = probability of each weight dependent on height value, alpha, beta, sigma\n\\(Pr(\\alpha,\\beta,\\sigma)\\) = prior\n\n\nStatistical Model\n\nQuadratic approximation\n\n\\(W_{i} \\sim Normal(\\mu _{i}), \\sigma)\\)\n\\(\\mu _{i} = \\alpha + \\beta H_{i}\\)\n\\(\\alpha \\sim Normal(0,10)\\)\n\\(\\beta \\sim Uniform(0,1)\\)\n\\(\\sigma \\sim Uniform(0, 10)\\)\n\n\n\nm3.1 <- quap(alist(\n  W ~ dnorm(mu, sigma),\n  mu <- a + b*H,\n  a ~ dnorm(0, 10),\n  b ~ dunif(0, 1),\n  sigma ~ dunif(0, 10)\n), data = list(W=W, H=H))\n\n\nPriors\n\nwe want to constrain to scientifically plausible values\njustify with information outside the data - like the rest of model\n\n\n\nn <- 1e3\na <- rnorm(n, 0, 10)\nb <- runif(n, 0, 1)\nplot(NULL, xlim = c(130, 170), ylim = c(50, 90))\n\n\n\n#for (j in 1:50) abline(a=a[j], b=b[j])\n\n\nValidate model\n\n\ntest statistical model with simulated observations from scientific model - need to test if your model is working\nuse many values and make sure your model responds appropriately\n\n\n# model summary\nprecis(m3.1)\n\n           mean         sd       5.5%     94.5%\na     1.4181497 4.24320273 -5.3633078 8.1996072\nb     0.4878943 0.02833964  0.4426021 0.5331865\nsigma 5.1958589 0.25979738  4.7806525 5.6110653\n\n\n\nAnalyze data\n\n\ndat <- list(W = d2$weight, H = d2$height)\nm3.2 <- quap(alist(\n  W ~ dnorm(mu, sigma),\n  mu <- a + b*H,\n  a ~ dnorm(0, 10), \n  b ~ dunif(0, 1),\n  sigma ~ dunif(0, 10)\n), data = dat)\n\nprecis(m3.2)\n\n             mean         sd        5.5%       94.5%\na     -43.3904022 4.17051013 -50.0556829 -36.7251215\nb       0.5718282 0.02694916   0.5287583   0.6148982\nsigma   4.2524435 0.16171244   3.9939958   4.5108912\n\n\n\nparameters are not independent of one another, they cannot be independently interpreted\n\nuse posterior predictions and describe/interpret those by sampling the posterior distribution\n\n\n\npost <- extract.samples(m3.2)\nplot(d2$height, d2$weight)\n#for (j in 1:20)\n#  abline(a=post$a[j], b=post$b[j])\n\nheight_seq <- seq(130, 190, len = 20)\nW_postpred <- sim(m3.2, data = list(H=height_seq))\nW_PI <- apply(W_postpred, 2, PI)\nlines(height_seq, W_PI[1,])\nlines(height_seq, W_PI[2,])"
  },
  {
    "objectID": "notes/notes-03.html#todo",
    "href": "notes/notes-03.html#todo",
    "title": "Lecture 03 - Geocentric Models",
    "section": "TODO:",
    "text": "TODO:\n\nfigure out plot erroring"
  },
  {
    "objectID": "notes/notes-06.html#rose-thorn",
    "href": "notes/notes-06.html#rose-thorn",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Rose / Thorn",
    "text": "Rose / Thorn\nRose: identifying and working through bad controls\nThorn:"
  },
  {
    "objectID": "notes/notes-06.html#randomization",
    "href": "notes/notes-06.html#randomization",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Randomization",
    "text": "Randomization\n\nrandomizing the treatment can remove the confound (only available for experiments)"
  },
  {
    "objectID": "notes/notes-06.html#causal-thinking",
    "href": "notes/notes-06.html#causal-thinking",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Causal Thinking",
    "text": "Causal Thinking\n\nin an experiment, we cut causes of the treatment -> we randomize\nsimulating intervention mimics randomization\ndo(X) means intervene on X\nexample: simple confound\n\n\ndag <- dagify(\n\n    X ~ U,\n\n    Y ~ U + X\n\n)\n\nggdag(dag) +\n\n    theme_dag()\n\n\n\n\n\nstratifying by U removes causal relationship and allows to test effect of X -> Y\nmarginalize or average over control variables\n\nthe coefficient is not usually satisfactory, need to marginalize\n\n\n\ndag <- dagify(\n\n    Baboons ~ Cheetahs,\n\n    Gazelle ~ Baboons + Cheetahs\n\n)\n\nggdag(dag) +\n\n    theme_dag()\n\n\n\n\n\npopulations of each of these species influences the other\n\nwhen cheetahs are present, baboons are scared and do not influence gazelle population\nwhen cheetahs are absent, baboons eat and regulate gazelle population\nto assess causal effect of baboons, need to average over cheetah population"
  },
  {
    "objectID": "notes/notes-06.html#do-calculus",
    "href": "notes/notes-06.html#do-calculus",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Do-Calculus",
    "text": "Do-Calculus\n\nallows us to determine if it is possible to answer our question using a DAG\nbackdoor criterion\n\nshortcut to apply do-calculus to use your eyes\nrule to find a set of variables to stratify by to yield estimate of our estimand\n\n\nidentify all paths connecting treatment (X) to outcome (Y)\npaths with arrows entering X are backdoor paths (non-causal paths)\nfind adjustment set that closes/blocks all backdoor paths\n\n\n\n\n\n# simulate confounded Y\nN <- 200\nb_XY <- 0\nb_UY <- -1\nb_UZ <- -1\nb_ZX <- 1\n\nset.seed(10)\nU <- rbern(N)\nZ <- rnorm(N, b_UZ*U)\nX <- rnorm(N, b_ZX*Z)\nY <- rnorm(N, b_XY*X + b_UY*U)\nd <- list(Y=Y, X=X, Z=Z)\n\n# ignore U,Z \nm_YX <- quap(alist(\n  Y ~ dnorm(mu, sigma),\n  mu <- a + b_XY*X,\n  a ~ dnorm(0,1),\n  b_XY ~ dnorm(0, 1),\n  sigma ~ dexp(1)\n), data = d)\n\n# stratify by Z \nm_YXZ <- quap(alist(\n    Y ~ dnorm(mu, sigma),\n  mu <- a + b_XY*X + b_Z*Z,\n  a ~ dnorm(0,1),\n  c(b_XY, b_Z) ~ dnorm(0, 1),\n  sigma ~ dexp(1)\n), data = d)\n\npost <- extract.samples(m_YX)\npost2 <- extract.samples(m_YXZ)\ndens(post$b_XY)\n\n\n\n#dens(post2$b_XY, add = TRUE)\n\n\nany variable you add to a model as part of the adjustment set (ie to control for), its coefficients are usually not interpretable\nminimum adjustment set is not always the best set"
  },
  {
    "objectID": "notes/notes-06.html#good-bad-controls",
    "href": "notes/notes-06.html#good-bad-controls",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Good & Bad Controls",
    "text": "Good & Bad Controls\n\ncontrol variable: variable introduced to an analysis so that a causal estimate is possible\n\ngood and bad controls\n\nvariables not being collinear is not a good reason for including/excluding variables\n\ncollinearity can arise from many statistical processes\n\npost-treatment variables are often risky controls\nif there is no backdoor path to variable of interest, you don’t need to control for it\n\n\n# sim confounding by post-treatment variable\n\nf <- function(n=100,bXZ=1,bZY=1) {\n    X <- rnorm(n)\n    u <- rnorm(n)\n    Z <- rnorm(n, bXZ*X + u)\n    Y <- rnorm(n, bZY*Z + u )\n    bX <- coef( lm(Y ~ X) )['X']\n    bXZ <- coef( lm(Y ~ X + Z) )['X']\n    return( c(bX,bXZ) )\n}\n\nsim <- mcreplicate( 1e4 , f(bZY=0), mc.cores = 1)\n\n[ 1000 / 10000 ]\n[ 2000 / 10000 ]\n[ 3000 / 10000 ]\n[ 4000 / 10000 ]\n[ 5000 / 10000 ]\n[ 6000 / 10000 ]\n[ 7000 / 10000 ]\n[ 8000 / 10000 ]\n[ 9000 / 10000 ]\n[ 10000 / 10000 ]\n\ndens( sim[1,] , lwd=3 , xlab=\"posterior mean\" , xlim=c(-1,0.8) , ylim=c(0,2.7)  )\n\n\n\n#dens( sim[2,] , lwd=3 , col=2 , add=TRUE )\n\n\ncase control bias (selection on outcome)\n\nvery bad to add descendents of your outcome to your model\nweakly stratifying by the outcome (e.g., stratifying by Z)\n\n\n\ndag <- dagify(\n    Y ~ X,\n    Z ~ Y\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nf <- function(n=100,bXY=1,bYZ=1) {\n    X <- rnorm(n)\n    Y <- rnorm(n, bXY*X )\n    Z <- rnorm(n, bYZ*Y )\n    bX <- coef( lm(Y ~ X) )['X']\n    bXZ <- coef( lm(Y ~ X + Z) )['X']\n    return( c(bX,bXZ) )\n}\n\nsim <- mcreplicate( 1e4 , f(), mc.cores = 1 )\n\n[ 1000 / 10000 ]\n[ 2000 / 10000 ]\n[ 3000 / 10000 ]\n[ 4000 / 10000 ]\n[ 5000 / 10000 ]\n[ 6000 / 10000 ]\n[ 7000 / 10000 ]\n[ 8000 / 10000 ]\n[ 9000 / 10000 ]\n[ 10000 / 10000 ]\n\ndens( sim[1,] , lwd=3 , xlab=\"posterior mean\" , xlim=c(0,1.5) , ylim=c(0,5)  )\n\n\n\n#dens( sim[2,] , lwd=3 , col=2 , add=TRUE )\n\n\nprecision parasite\n\nno backdoors because Z is not connected to Y except through X\nnot good to stratify Z because you are explaining part of the effect of X with Z\n\n\n\ndag <- dagify(\n    Y ~ X,\n    X ~ Z\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nf <- function(n=100,bZX=1,bXY=1) {\n    Z <- rnorm(n)\n    X <- rnorm(n, bZX*Z )\n    Y <- rnorm(n, bXY*X )\n    bX <- coef( lm(Y ~ X) )['X']\n    bXZ <- coef( lm(Y ~ X + Z) )['X']\n    return( c(bX,bXZ) )\n}\n\nsim <- mcreplicate( 1e4 , f(n=50), mc.cores = 1 )\n\n[ 1000 / 10000 ]\n[ 2000 / 10000 ]\n[ 3000 / 10000 ]\n[ 4000 / 10000 ]\n[ 5000 / 10000 ]\n[ 6000 / 10000 ]\n[ 7000 / 10000 ]\n[ 8000 / 10000 ]\n[ 9000 / 10000 ]\n[ 10000 / 10000 ]\n\ndens( sim[1,] , lwd=3 , xlab=\"posterior mean\" , xlim=c(0.5,1.5) , ylim=c(0,4.5)  )\ndens( sim[2,] , lwd=3 , col=2 , add=TRUE )\n\n\n\n\n\nbias amplification\n\nX and Y confounded by u\nadding Z biases your answer because it “double” activates the confound\n\n\n\ndag <- dagify(\n    Y ~ X + u,\n    X ~ Z + u\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nf <- function(n=100,bZX=1,bXY=1) {\n    Z <- rnorm(n)\n    u <- rnorm(n)\n    X <- rnorm(n, bZX*Z + u )\n    Y <- rnorm(n, bXY*X + u )\n    bX <- coef( lm(Y ~ X) )['X']\n    bXZ <- coef( lm(Y ~ X + Z) )['X']\n    return( c(bX,bXZ) )\n}\n\nsim <- mcreplicate( 1e4 , f(bXY=0), mc.cores = 1)\n\n[ 1000 / 10000 ]\n[ 2000 / 10000 ]\n[ 3000 / 10000 ]\n[ 4000 / 10000 ]\n[ 5000 / 10000 ]\n[ 6000 / 10000 ]\n[ 7000 / 10000 ]\n[ 8000 / 10000 ]\n[ 9000 / 10000 ]\n[ 10000 / 10000 ]\n\ndens( sim[1,] , lwd=3 , xlab=\"posterior mean\" , xlim=c(-0.5,1) , ylim=c(0,5.5)  )\n\n\n\n#dens( sim[2,] , lwd=3 , col=2 , add=TRUE )\n\nabline_w <- function(...,col=1,lwd=1,dlwd=2) {\n    abline(...,col=\"white\",lwd=lwd+dlwd)\n    abline(...,col=col,lwd=lwd)\n}\n\nn <- 1000\nZ <- rbern(n)\nu <- rnorm(n)\nX <- rnorm(n, 7*Z + u )\nY <- rnorm(n, 0*X + u )\n\ncols <- c( col.alpha(2,0.5) , col.alpha(4,0.5) )\nplot( X , Y  , col=cols[Z+1] , lwd=2 )\n\n\n\n#abline_w( lm(Y~X) , lwd=3 )\n#\n#abline_w( lm(Y[Z==1]~X[Z==1]) , lwd=3 , col=4 )\n#\n#abline_w( lm(Y[Z==0]~X[Z==0]) , lwd=3 , col=2 )"
  },
  {
    "objectID": "notes/notes-06.html#summary",
    "href": "notes/notes-06.html#summary",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Summary",
    "text": "Summary\n\nadding control variables can be worse than omitting\nthere are good controls - backdoor criterion\nmake assumptions explicit"
  },
  {
    "objectID": "notes/notes-06.html#bonus---table-2-fallacy",
    "href": "notes/notes-06.html#bonus---table-2-fallacy",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Bonus - Table 2 Fallacy",
    "text": "Bonus - Table 2 Fallacy\n\nnot all coefficients are causal effects\nstatistical model designed to identify X -> Y will not also identify effects of control variables\n\\(Y_i \\sim Normal(\\mu_i, \\sigma)\\)\n\\(\\mu_i = \\alpha + \\beta_xX_i + \\beta_SS_i + \\beta_AA_i\\)\nthink through DAG for each control variable to see what the coefficient actually means\nno interpretation without causal representation"
  },
  {
    "objectID": "notes/notes-06.html#todo",
    "href": "notes/notes-06.html#todo",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "TODO",
    "text": "TODO\n\nread Table 2 Fallacy paper"
  },
  {
    "objectID": "notes/notes-07.html#rose-thorn",
    "href": "notes/notes-07.html#rose-thorn",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Rose / Thorn",
    "text": "Rose / Thorn\nRose: not trying to be perfect, just better\nThorn: thinking through prediction vs causality - when do I want prediction?"
  },
  {
    "objectID": "notes/notes-07.html#problems-of-prediction",
    "href": "notes/notes-07.html#problems-of-prediction",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Problems of Prediction",
    "text": "Problems of Prediction\n\nwhat function describes the data (fitting, compression)\nwhat functions explains these points (causal inference)\nwhat would happen if we changed the data (intervention)\nwhat is the next observation from the same process (prediction)\n\nprediction is the absence of intervention\nprediction does not require causal inference\n\nLeave-one-out cross-validation\n\n\n\ndrop one point\nfit line to remaining\npredict dropped point\nrepeat (1) with next point\nscore is error on dropped\n\n\ntask you use to assess the expected predictive accuracy of a statistical procedure\nscore in: fit to the sample / score out: fit to prediction\nLPPD (log posterior probability of observation) used for cross-validation because it includes the entire posterior\nmore flexible patterns generally perform better in sample and worse out of sample"
  },
  {
    "objectID": "notes/notes-07.html#cross-validation",
    "href": "notes/notes-07.html#cross-validation",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Cross-Validation",
    "text": "Cross-Validation\n\nfor simple models, more parameters improves fit to sample BUT may reduce accuracy of predictions out of sample\naccurate models trade off flexibility with overfitting"
  },
  {
    "objectID": "notes/notes-07.html#regularization",
    "href": "notes/notes-07.html#regularization",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Regularization",
    "text": "Regularization\n\noverfitting depends upon the priors\ndon’t be too excited about every point in the sample, because not every point in the sample is regular (not all points are representative)\nskeptical priors regularize models - have tighter variance that reduces flexibility\n\ndownweights improbable values\n\nskeptical priors improve model prediction - regularize so that models learn regular features and ignore irregular features\n\nthere is such a thing as too tight priors\n\nRegularizing priors -> for pure prediction uses, you can tune the prior using cross-validation\n\ncausal inference uses science to choose priors"
  },
  {
    "objectID": "notes/notes-07.html#prediction-penalty",
    "href": "notes/notes-07.html#prediction-penalty",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Prediction Penalty",
    "text": "Prediction Penalty\n\nFor N points, cross-validation requires fitting N models\n\nfeasible for few data points but for many data points gets unwieldy\n\nImportance sampling (PSIS) and information criteria (WAIC) allow you to assess prediction penalty from one model posterior distribution (for predictive models)\nWAIC, PSIS, cross-validation (CV) measure overfitting\n\nregularization manages overfiting\n\nCausal inference is not addressed by measuring or addressing overfitting\n\nthese tools are addressing the performance of a predictive model, not a causal model\nshould not select causal models based on these values because they are not associated with causality"
  },
  {
    "objectID": "notes/notes-07.html#model-mis-selection",
    "href": "notes/notes-07.html#model-mis-selection",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Model Mis-selection",
    "text": "Model Mis-selection\n\nDo not use predictive criteria (WAIC, PSIS, CV) to choose a causal estimate\nPredictive criteria prefer confounds and colliders\n\nimprove predictive accuracy"
  },
  {
    "objectID": "notes/notes-07.html#outliers-robust-regression",
    "href": "notes/notes-07.html#outliers-robust-regression",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Outliers & Robust Regression",
    "text": "Outliers & Robust Regression\n\nsome points are more influential than others - ‘outliers’\noutliers are information - don’t necessarily want to remove them\n\nbut they often have high leverage/weight because they are “surprising”\ndropping outliers ignores the problem - predictions will still be bad\nmodel is wrong, not the data\n\ncan quantify the influence of each point on the posterior distribution using cross-validation\ncan also use a mixture model/robust regression to address outliers\ndivorce rate example\n\nMaine and Idaho are outliers in divorce/age relationship\nquantify influence of outliers using PSIS k statistic or WAIC penalty term\nunmodelled sources of variation cause outliers -> error distributions are not constant across the sample\n\nassuming that the dataset has multiple error distributions, with the same mean but different variations indicates that you are using a student t-test\nGaussian distribution has extremely thin tails - very skeptical\nstudent t distribution is much less skeptical, wider tails, much less influenced by outliers + more robust\n\n\n\n\ndata(WaffleDivorce)\nd <- WaffleDivorce\n\n# model\ndat <- list(\n    D = standardize(d$Divorce),\n    M = standardize(d$Marriage),\n    A = standardize(d$MedianAgeMarriage)\n)\n\nm5.3 <- quap(alist(\n  D ~ dnorm(mu, sigma), \n  mu <- a + bM*M + bA*A,\n  a ~ dnorm(0, 0.2),\n  bM ~ dnorm(0, 0.5), \n  bA ~ dnorm(0, 0.5),\n  sigma ~ dexp(1)\n), data = dat)\n\nm5.3t <- quap(alist(\n  D ~ dstudent(2, mu, sigma), \n  mu <- a + bM*M + bA*A,\n  a ~ dnorm(0, 0.2),\n  bM ~ dnorm(0, 0.5), \n  bA ~ dnorm(0, 0.5),\n  sigma ~ dexp(1)\n), data = dat)"
  },
  {
    "objectID": "notes/notes-07.html#robust-regressions",
    "href": "notes/notes-07.html#robust-regressions",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Robust Regressions",
    "text": "Robust Regressions\n\nunobserved heterogeneity in sample -> mixture of Gaussian errors\n\nthicker tails means model is less surprised/more robust\n\nstudent-t regression can be a good default for undertheorized domains\n\nbecause Gaussian distribution is so skeptical"
  },
  {
    "objectID": "notes/notes-07.html#prediction",
    "href": "notes/notes-07.html#prediction",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Prediction",
    "text": "Prediction\n\npossible to make very good predictions without knowing causes\noptimizing prediction does not reliably reveal causes"
  },
  {
    "objectID": "notes/notes-09.html#rose-thorn",
    "href": "notes/notes-09.html#rose-thorn",
    "title": "Lecture 09 - Modeling Events",
    "section": "Rose / Thorn",
    "text": "Rose / Thorn\nRose: starting to understand what a generalized linear model actually is\nThorn: algebra and links"
  },
  {
    "objectID": "notes/notes-09.html#modeling-events",
    "href": "notes/notes-09.html#modeling-events",
    "title": "Lecture 09 - Modeling Events",
    "section": "Modeling Events",
    "text": "Modeling Events\nNOTE: read causal foundations of bias, fairness, and …\n\nobservations are counts\nunknowns are possibilities, odds\neverything is interacting\n\nWhat is the effect of gender on university admissions?\n\n\n\n\n\n\ntotal effect of discrimination is what people experience\nquite often, the thing we are able to estimate is what we want (total effects are easier to estimate but subpaths are interesting and important to understanding equity)\n\n\nN <- 1000 # number of applicants\nG <- sample(1:2, size = N, replace = T) # gender distribution\nD <- rbern(N, ifelse(G==1, 0.3, 0.8)) + 1 #gener 1 tends to apply to appartment 1, 2 to 2\naccept_rate <- matrix(c(0.1, 0.3, 0.1, 0.3), nrow = 2) # matrix of acceptance rates [dept, gender]\nA <- rbern(N, accept_rate[D,G]) # simulate acceptance\n\n\nwe observe: count of events\nwe estimate: probability (or log-odds) of events\n\nlike the globe tossing model, but need “proportion of water” stratified by other variables"
  },
  {
    "objectID": "notes/notes-09.html#generalized-linear-models",
    "href": "notes/notes-09.html#generalized-linear-models",
    "title": "Lecture 09 - Modeling Events",
    "section": "Generalized Linear Models",
    "text": "Generalized Linear Models\n\nlinear models: expected value is additive “linear” combination of parameters\ngeneralized linear models: expected value is some function of an additive combination of parameters\nf is the link function - links parameters of distribution to linear model\ndistributions: relative number of ways to observe data, given assumptions about rates, probabilities, slopes, etc.\ndistributions are matched to constraints on observed variables\nlink functions are matched to distributions\nexponential distribution - the time to an event that has a constant rate. Values you sample from exponential distribution are latencies/rates (continuous data above one)\n\nprocess that produces events and then you count those events = binomial distribution\ndon’t know maximum number of counts = poisson (special case of binomial)\nsum exponential processes = gamma\nlarge means of gamma distribution = normal distribution\n\ndistribution you want is governed by the constraints you assume about your variable\n\nyou cannot test if your data are normal\nneed to think about constraints and match to distributions"
  },
  {
    "objectID": "notes/notes-09.html#logit-link",
    "href": "notes/notes-09.html#logit-link",
    "title": "Lecture 09 - Modeling Events",
    "section": "Logit Link",
    "text": "Logit Link\n\nlog-odds = logit link\nBernoulli/binomial models most often use the logit link\nlinear model output is on the “log-odds scale”"
  },
  {
    "objectID": "notes/notes-09.html#logistic-priors",
    "href": "notes/notes-09.html#logistic-priors",
    "title": "Lecture 09 - Modeling Events",
    "section": "Logistic Priors",
    "text": "Logistic Priors\n\nlogit link compresses parameter distributions\non log-odds scale, above +4 = almost always, below -4 = almost never\n\ntherefore, tighter priors are better\n\n\n\n# generative model, basic mediator scenario\n\nN <- 1000 # number of applicants\n# even gender distribution\nG <- sample( 1:2 , size=N , replace=TRUE )\n# gender 1 tends to apply to department 1, 2 to 2\nD <- rbern( N , ifelse( G==1 , 0.3 , 0.8 ) ) + 1\n# matrix of acceptance rates [dept,gender]\naccept_rate <- matrix( c(0.1,0.3,0.1,0.3) , nrow=2 )\naccept_rate <- matrix( c(0.05,0.2,0.1,0.3) , nrow=2 )\n# simulate acceptance\np <- sapply( 1:N , function(i) accept_rate[D[i],G[i]] )\nA <- rbern( N , p )\n\n# total effect gender\ndat_sim <- list( A=A , D=D , G=G )\n\nm1 <- ulam(\n    alist(\n        A ~ bernoulli(p),\n        logit(p) <- a[G],\n        a[G] ~ normal(0,1)\n    ), data=dat_sim , chains=4 , cores=4 )\n\nprecis(m1,depth=2)\n\n# direct effects\nm2 <- ulam(\n    alist(\n        A ~ bernoulli(p),\n        logit(p) <- a[G,D],\n        matrix[G,D]:a ~ normal(0,1)\n    ), data=dat_sim , chains=4 , cores=4 )\n\nprecis(m2,depth=3)\n\n# aggregate the dat_sim for binomial instead of Bernoulli\n\nx <- as.data.frame(cbind( A=dat_sim$A , G=dat_sim$G , D=dat_sim$D  ))\nhead(x,20)\n\ndat_sim2 <- aggregate( A ~ G + D , dat_sim , sum )\ndat_sim2$N <- aggregate( A ~ G + D , dat_sim , length )$A\n\nm2_bin <- ulam(\n    alist(\n        A ~ binomial(N,p),\n        logit(p) <- a[G,D],\n        matrix[G,D]:a ~ normal(0,1)\n    ), data=dat_sim2 , chains=4 , cores=4 )\n\nprecis(m2_bin,3)\n\nModel real data:\n\ndata(UCBadmit)\nd <- UCBadmit\n\ndat <- list( \n    A = d$admit,\n    N = d$applications,\n    G = ifelse(d$applicant.gender==\"female\",1,2),\n    D = as.integer(d$dept)\n)\n\n# total effect gender\nmG <- ulam(\n    alist(\n        A ~ binomial(N,p),\n        logit(p) <- a[G],\n        a[G] ~ normal(0,1)\n    ), data=dat , chains=4 , cores=4 )\n\nprecis(mG,2)\n\n# direct effects\nmGD <- ulam(\n    alist(\n        A ~ binomial(N,p),\n        logit(p) <- a[G,D],\n        matrix[G,D]:a ~ normal(0,1)\n    ), data=dat , chains=4 , cores=4 )\n\nprecis(mGD,3)\n\n# check chains\n\ntraceplot(mGD)\ntrankplot(mGD)\n\n# contrasts\n# on probability scale\n\npost1 <- extract.samples(mG)\nPrA_G1 <- inv_logit( post1$a[,1] )\nPrA_G2 <- inv_logit( post1$a[,2] )\ndiff_prob <- PrA_G1 - PrA_G2\ndens(diff_prob,lwd=4,col=2,xlab=\"Gender contrast (probability)\")\n\npost2 <- extract.samples(mGD)\nPrA <- inv_logit( post2$a ) \ndiff_prob_D_ <- sapply( 1:6 , function(i) PrA[,1,i] - PrA[,2,i] )\nplot(NULL,xlim=c(-0.2,0.3),ylim=c(0,25),xlab=\"Gender contrast (probability)\",ylab=\"Density\")\nfor ( i in 1:6 ) dens( diff_prob_D_[,i] , lwd=4 , col=1+i , add=TRUE )\nabline(v=0,lty=3)\n\n# marginal effect of gender perception (direct effect)\n\n# compute department weights via simulation\n# we can just compute predictions as if all applications had been perceived as men\n# and then again as if all had been perceived as women\n# difference is marginal effect of perception, beause does not change department assignments (G -> A only, no G -> D)\n\n# OLD WRONG CODE!\n#p_G1 <- link( mGD , data=list(N=dat$N,D=dat$D,G=rep(1,12)) )\n#p_G2 <- link( mGD , data=list(N=dat$N,D=dat$D,G=rep(2,12)) )\n\n# NEW CORRECT CODE\n\n# number of applicatons to simulate\ntotal_apps <- sum(dat$N)\n\n# number of applications per department\napps_per_dept <- sapply( 1:6 , function(i) sum(dat$N[dat$D==i]) )\n\n# simulate as if all apps from women\np_G1 <- link(mGD,data=list(\n    D=rep(1:6,times=apps_per_dept),\n    N=rep(1,total_apps),\n    G=rep(1,total_apps)))\n\n# simulate as if all apps from men\np_G2 <- link(mGD,data=list(\n    D=rep(1:6,times=apps_per_dept),\n    N=rep(1,total_apps),\n    G=rep(2,total_apps)))\n\n# summarize\ndens( p_G1 - p_G2 , lwd=4 , col=2 , xlab=\"effect of gender perception\" )\nabline(v=0,lty=3)\n\n# show each dept density with weight as in population\nw <- xtabs( dat$N ~ dat$D ) / sum(dat$N)\nw <- w/max(w)\nplot(NULL,xlim=c(-0.2,0.3),ylim=c(0,25),xlab=\"Gender contrast (probability)\",ylab=\"Density\")\nfor ( i in 1:6 ) dens( diff_prob_D_[,i] , lwd=2+8*w[i]^3 , col=1+i , add=TRUE )\nabline(v=0,lty=3)"
  },
  {
    "objectID": "notes/notes-09.html#post-stratification",
    "href": "notes/notes-09.html#post-stratification",
    "title": "Lecture 09 - Modeling Events",
    "section": "Post-Stratification",
    "text": "Post-Stratification\n\ndescription, prediction, and causal inference often require post-stratification\nway to predict what the intervention will do to a specific population\npost-stratification = re-weighting estimates for target population"
  },
  {
    "objectID": "notes/notes-09.html#survival-analysis",
    "href": "notes/notes-09.html#survival-analysis",
    "title": "Lecture 09 - Modeling Events",
    "section": "Survival Analysis",
    "text": "Survival Analysis\n\nanother way of modelling events but we care about the time it took for an event to happen instead of number of times it happened\ncannot ignore censored cases (left-censored = don’t know when time started, right-censored = observation ended before event)\nexponential or gamma distribution"
  },
  {
    "objectID": "notes/notes-05.html",
    "href": "notes/notes-05.html",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "",
    "text": "Rose: so helpful and relevant\nThorn: is all my science wrong"
  },
  {
    "objectID": "notes/notes-05.html#correlation",
    "href": "notes/notes-05.html#correlation",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "Correlation",
    "text": "Correlation\n\ncorrelation is common in nature, causation is sparse\nscientific question/estimand -> recipe/estimator -> result/estimate"
  },
  {
    "objectID": "notes/notes-05.html#association-causation",
    "href": "notes/notes-05.html#association-causation",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "Association & Causation",
    "text": "Association & Causation\n\nwe must defend against confounding in our stats\nconfounds mislead us - feature of the sample + how we use it\nfour elemental confounds\n\ncauses of confounds can be extremely diverse but they are all at their core made up of relationships between 3 variables"
  },
  {
    "objectID": "notes/notes-05.html#the-fork",
    "href": "notes/notes-05.html#the-fork",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "The Fork",
    "text": "The Fork\n\nX and Y are associated \\(Y \\not\\!\\perp\\!\\!\\!\\perp X\\)\nShare a common cause Z\nOnce stratified by Z, no association \\(Y \\perp\\!\\!\\!\\perp X | Z\\)\n\n\ndag <- dagify(\n    X ~ Z,\n    Y ~ Z\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nsimulation:\n\n\nn <- 1000\nZ <- rbern(n, 0.5)\nX <- rbern(n, (1-Z)*0.01 + Z*0.9)\nY <- rbern(n, (1-Z)*0.01 + Z*0.9)\n\n\ncols <- c(4,2)\nn <- 300\nZ <- rbern(n, 0.5)\nX <- rnorm(n, (1-Z)*0.01 + Z*0.9)\nY <- rnorm(n, (1-Z)*0.01 + Z*0.9)\n\nplot(X, Y, col=cols[Z+1])\n\n\n\n# abline(lm(Y[Z==1]))\n#\n#\n\n\nexample:\n\nwhy do regions of the USA with higher rates of marriage also have higher rates of divorce?\nestimand: causal effect of marriage rate on divorce rate\n\n\n\ndag <- dagify(\n    D ~ A,\n    M ~ A,\n    D ~ M\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\ncauses are not in the data\nis effect of marriage rates on divorce rates just a symptom of common cause age?\nneed to break the fork to test direct effect – stratify by A\ncontinuous variable stratification means that we are adding to that variable essentially to the intercept\nstandardizing variables is almost always helpful in linear regression\n\nmake the mean zero and divide by sd\n\nto stratify by A, include as a term in the linear model:\n\n\\(D _i \\sim Normal(\\mu _i, \\sigma)\\)\n\\(\\mu _i = \\alpha + \\beta_MM_i + \\beta_AA_i\\)\n\\(\\alpha \\sim Normal(0, 0.2)\\)\n\\(\\beta_M \\sim Normal(0,0.5)\\)\n\\(\\beta_A \\sim Normal(0, 0.5)\\)\n\\(\\sigma \\sim Exponential(1)\\)\n\n\n\nlibrary(rethinking)\ndata(WaffleDivorce)\nd <- WaffleDivorce\n\n# model\ndat <- list(\n    D = standardize(d$Divorce),\n    M = standardize(d$Marriage),\n    A = standardize(d$MedianAgeMarriage)\n)\n\nm_DMA <- quap(\n    alist(\n        D ~ dnorm(mu,sigma),\n        mu <- a + bM*M + bA*A,\n        a ~ dnorm(0,0.2),\n        bM ~ dnorm(0,0.5),\n        bA ~ dnorm(0,0.5),\n        sigma ~ dexp(1)\n    ) , data=dat )\n\nplot(precis(m_DMA))\n\n\n\n\n\na causal effect is a manipulation of the generative model, an intervention\ndistribution of D when we intervene (“do”) M \\(p(D|do(M))\\)\n\nimplies deleting all arrows into M and simulating D\n\n\n\npost <- extract.samples(m_DMA)\n\n# sample A from data\nn <- 1e3\nAs <- sample(dat$A, size = n, replace = T)\n\n# simulate D for M=0 (sample mean)\nDM0 <- with(post, rnorm(n, a + bM*0 + bA*As, sigma))\n\n# simulate D for M = 1 (+1 standard deviation)\n# use the same A values \nDM1 <- with(post, rnorm(n, a + bM*1 + bA*As, sigma))\n\n# contrast\nM10_contrast <- DM1 - DM0\ndens(M10_contrast, lwd=4, col=2, xlab=\"effect of increase in M\")"
  },
  {
    "objectID": "notes/notes-05.html#the-pipe",
    "href": "notes/notes-05.html#the-pipe",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "The Pipe",
    "text": "The Pipe\n\nX and Y are associated \\(Y \\not\\!\\perp\\!\\!\\!\\perp X\\)\nInfluence of X on Y trasmitted through Z\nOnce stratified by Z, no association \\(Y \\perp\\!\\!\\!\\perp X | Z\\)\n\n\ndag <- dagify(\n    Y ~ Z,\n    Z ~ X\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nn <- 1000\nX <- rbern(n, 0.5)\nZ <- rbern(n, (1-X)*0.01 + X*0.9)\nY <- rbern(n, (1-Z)*0.01 + Z*0.9)\n\n\neverything that Y knows about X, is already known by Z\n\nonce you learn Z, there is nothing more to learn about the association\n\n\n\ncols <- c(4,2)\nn <- 300\nX <- rbern(n)\nZ <- rbern(n, inv_logit(X))\nY <- rbern(n, (2*Z-1))\n\nWarning in rbinom(n, size = 1, prob = prob): NAs produced\n\n# plot\n\n\nincluding the mediator at the wrong time can lead to incorrect inference\n\n\ndag <- dagify(\n   H1 ~ H0 + Treat,\n   H1 ~ Fungus,\n   Fungus ~ Treat\n   \n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nwhat is the total causal effect of treatment?\nTreat -> Fungus -> H1 is a pipe, should not stratify by F\npoost-treatment bias\n\nif you stratify by a consquence of the treatment, it can induce post-treatment bias - gives you a misleading estimate of what you’re after\nconsequences of treatment should not usually be included in the estimator"
  },
  {
    "objectID": "notes/notes-05.html#the-collider",
    "href": "notes/notes-05.html#the-collider",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "The Collider",
    "text": "The Collider\n\nX and Y are not associated (share no causes) \\(Y \\perp\\!\\!\\!\\perp X\\)\nX and Y both influence Z\nOnce stratified by Z, X and Y are associated \\(Y \\not\\!\\perp\\!\\!\\!\\perp X | Z\\)\n\n\ndag <- dagify(\n    Z ~ X + Y\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nn <- 1000\nX <- rbern(n, 0.5)\nY <- rbern(n, 0.5)\nZ <- rbern(n, ifelse(X+Y>0, 0.9, 0.2))\n\n\nstrong correlations caused by the collider could be read as correlation but causes are not in the data\n\n\ncols <- c(4,2)\nN <- 300\nX <- rnorm(N)\nY <- rnorm(N)\nZ <- rbern(N, inv_logit(2*X+2*Y-2))\n\nplot(X,Y, cols = cols[Z+1])\n\nWarning in plot.window(...): \"cols\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"cols\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"cols\" is not a\ngraphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"cols\" is not a\ngraphical parameter\n\n\nWarning in box(...): \"cols\" is not a graphical parameter\n\n\nWarning in title(...): \"cols\" is not a graphical parameter\n\n\n\n\n# lines\n\n\nsometimes samples come already stratified by collider\nassociations among the things you have measured post-selection is dangerous because the selection is often collider bias\nendogenous colliders\n\nif you include a collider in your estimator you can induce a spurious correlation\nhappens within your analysis\n\nexample: age and happiness\n\nestimand: influence of age on happiness\npossible confound: marital status\nsuppose age has zero influence on happiness, but that both age and happiness influence marital status\n\n\n\ndag <- dagify(\n   M ~ A + H\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nstratified by marital status, negative association between age and happiness even though they are not related -> age/happiness are unrelated"
  },
  {
    "objectID": "notes/notes-05.html#the-descendant",
    "href": "notes/notes-05.html#the-descendant",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "The Descendant",
    "text": "The Descendant\n\nhow it behaves depends on what it is attached to\nA is the descendant, contains information of its “parent”\nX and Y are causally associated through Z \\(Y \\not\\!\\perp\\!\\!\\!\\perp X\\)\nA holds information about Z\nOnce stratified by A, X and Y less associated (if strong enough) \\(Y \\perp\\!\\!\\!\\perp X | A\\)\n\n\ndag <- dagify(\n   Z ~ X,\n   Y ~ Z,\n   A ~ Z\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nn <- 1000\nx <- rbern(n, 0.5)\nz <- rbern(n, (1-x)*0.1 + x*0.9)\ny <- rbern(n, (1-z)*0.1 + z*0.9)\na <- rbern(n, (1-z)*0.1 + z*0.9)\n\n\ndescendants are everywhere - proxies"
  },
  {
    "objectID": "notes/notes-12.html#rose-thorn",
    "href": "notes/notes-12.html#rose-thorn",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Rose / Thorn",
    "text": "Rose / Thorn\nRose: helpful but confusing (because so far from what we are taught) way to discuss random effects\nThorn: how tf does this translate to “normal” R packages"
  },
  {
    "objectID": "notes/notes-12.html#repeat-observations",
    "href": "notes/notes-12.html#repeat-observations",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Repeat Observations",
    "text": "Repeat Observations\n\nfor any given estimand, there are multiple estimators we can use (but some are better than others)\ncan include categorical responses such as individuals as seen before\n\nbut the model is not learning"
  },
  {
    "objectID": "notes/notes-12.html#multilevel-models",
    "href": "notes/notes-12.html#multilevel-models",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Multilevel Models",
    "text": "Multilevel Models\n\nmodels within models\n\n\nmodel observed groups/individuals\nmodel of population of groups/individuals\n\n\nthe population model creates a kind of memory\nmultilevel models with memory learn faster, better AND models with memory resist overfitting\nmultilevel models use every observation to inform predictions about other cafes and the population of cafes"
  },
  {
    "objectID": "notes/notes-12.html#regularization",
    "href": "notes/notes-12.html#regularization",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Regularization",
    "text": "Regularization\n\nmultilevel models adaptively regularize\ncomplete pooling: treat all clusters as identical -> underfitting\nno pooling: treat all clusters as unrelated -> overfitting\npartial pooling: adaptive compromise that achieves regularization"
  },
  {
    "objectID": "notes/notes-12.html#reedfrogs",
    "href": "notes/notes-12.html#reedfrogs",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Reedfrogs",
    "text": "Reedfrogs\n\ntreatments: density, size, predation\noutcome: survival\n48 groups (“tanks”) of tadpoles\n\n\n\n\n\n\n\n\\(S_i \\sim Binomial(D_i, p_i)\\)\n\\(logit(p_i) = \\alpha_{T[i]}\\)\n\\(\\alpha_j \\sim Normal(\\overline{\\alpha}, \\sigma)\\)\n\\(\\overline{\\alpha} \\sim Normal(0, 1.5)\\)\nparameters are just unobserved variables\n\ndata is an observed parameter\n\nif we want to learn about differences in between groups, we can set the prior for the mean tank as we normally would and then leave the prior for the variation of the groups as an unobserved parameter to be learned\nfind optimal value of sigma through cross-validation\n\nalthough we are using the model to choose a prior, we are not basing it off of model fit of the sample, we are evaluating it on cross-validation (out-of-sample). So we we are just assessing whether the model is overfit - not seeing how well it fits the data/causal relationships"
  },
  {
    "objectID": "notes/notes-12.html#automatic-regularization",
    "href": "notes/notes-12.html#automatic-regularization",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Automatic Regularization",
    "text": "Automatic Regularization\n\ncan use automatic regularization instead of cross-validation to remove the need to run so many models\n\n\\(S_i \\sim Binomial(D_i, p_i)\\)\n\\(logit(p_i) = \\alpha_{T[i]}\\)\n\\(\\alpha_j \\sim Normal(\\overline{\\alpha}, \\sigma)\\)\n\\(\\overline{\\alpha} \\sim Normal(0, 1.5)\\)\n\\(\\sigma \\sim Exponential(1)\\)\n\n\n\nlibrary(rethinking) \ndata(reedfrogs)\nd <- reedfrogs \nd$tank <- 1:nrow(d)\ndat <- list(\n    S = d$surv,\n    D = d$density,\n    T = d$tank )\n\nmST <- ulam( \n    alist(\n        S ~ dbinom( D , p ) ,\n        logit(p) <- a[T] ,\n        a[T] ~ dnorm( a_bar , sigma ) , \n        a_bar ~ dnorm( 0 , 1.5 ) ,\n        sigma ~ dexp( 1 )\n    ), data=dat , chains=4 , log_lik=TRUE )\n\nmSTnomem <- ulam( \n    alist(\n        S ~ dbinom( D , p ) ,\n        logit(p) <- a[T] ,\n        a[T] ~ dnorm( a_bar , 1 ) , \n        a_bar ~ dnorm( 0 , 1.5 )\n    ), data=dat , chains=4 , log_lik=TRUE )\n\ncompare( mST , mSTnomem , func=WAIC )\n\n\nmultilevel models regularize “for free” - model mST is a multilevel model and having sigma as a prior means that it is regularized around the relevant values\nmSTnomem is not a multilevel model (sigma is not a prior - it is a fixed value)\nwhen you are working with multilevel models, when you add treatment variables, the variation among means is going to shrink because you are accounting for the variation with the different treatments\nstratify mean by predators:\n\n\\(S_i \\sim Binomial(D_i, p_i)\\)\n\\(logit(p_i) = \\alpha_{T[i]} + \\beta_PP_i\\)\n\\(\\beta_P \\sim Normal(0, 0.5)\\)\n\\(\\alpha_j \\sim Normal(\\overline{\\alpha}, \\sigma)\\)\n\\(\\overline{\\alpha_j} \\sim Normal(0, 1.5)\\)\n\\(\\sigma \\sim Exponential(1)\\)\n\n\n\n# pred model\n\ndat$P <- ifelse(d$pred==\"pred\",1,0)\nmSTP <- ulam( \n    alist(\n        S ~ dbinom( D , p ) ,\n        logit(p) <- a[T] + bP*P ,\n        bP ~ dnorm( 0 , 0.5 ),\n        a[T] ~ dnorm( a_bar , sigma ) , \n        a_bar ~ dnorm( 0 , 1.5 ) ,\n        sigma ~ dexp( 1 )\n    ), data=dat , chains=4 , log_lik=TRUE )\n\npost <- extract.samples(mSTP)\ndens( post$bP , lwd=4 , col=2 , xlab=\"bP (effect of predators)\" )\n\n\nextremely similar predictions between model with predators and model without\n\nbecause alphas can learn the behaviours of each tank without an explanation (ie predators)\n\nBUT the variation between tanks is very different between models\n\npredator model has much lower variation in sigma"
  },
  {
    "objectID": "notes/notes-12.html#multilevel-tadpoles",
    "href": "notes/notes-12.html#multilevel-tadpoles",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Multilevel Tadpoles",
    "text": "Multilevel Tadpoles\n\nmodel of unobserved population helps learn about observed units\nuse data efficiently, reduce overfitting\nvarying effects: unit-specific partially pooled estimates (also called random effects depending on discipline)"
  },
  {
    "objectID": "notes/notes-12.html#varying-effects-superstitions",
    "href": "notes/notes-12.html#varying-effects-superstitions",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Varying Effects Superstitions",
    "text": "Varying Effects Superstitions\n\nunits must be sampled at random (false - unrelated) - justification for partial pooling is that you learn faster\nnumber of units must be large (false - unrelated)\nassumes Gaussian variation (false) - misunderstanding of probability theory. Distributions in statistical models are not claims of frequency distributions of the variables in the real world, they are just priors. Posterior distribution does not have to be Gaussian. A Gaussian prior does not impose a Gaussian posterior distribution.\n\nprior is just a prior\nbut you can use non-random distributions in multilevel models"
  },
  {
    "objectID": "notes/notes-12.html#practical-difficulties",
    "href": "notes/notes-12.html#practical-difficulties",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Practical Difficulties",
    "text": "Practical Difficulties\n\nhow to use more than one cluster at the same time?\nhow to sample efficiently?\nwhat about slopes? confounds?"
  },
  {
    "objectID": "notes/notes-12.html#bonus-random-confounds",
    "href": "notes/notes-12.html#bonus-random-confounds",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Bonus: Random Confounds",
    "text": "Bonus: Random Confounds\n\nwhen unobserved group features influence individually-varying causes\n\ngroup level variables have direct and indirect influences\n\nvery confusing literature\n\n\n\n\n\n\n\nG (tank traits) have direct influences on Si (survival)\nZ (group trait) have direct influences on Si (survival)\nXi (individual trait) have direct influences on Si\nPROBLEM: G (tank traits) also indirectly influence Si through Xi\nmultilevel models that account for these confounds = Mundlak Machines\n\n\nset.seed(8672)\n\nN_groups <- 30\nN_id <- 200\na0 <- (-2)\nbZY <- (-0.5)\ng <- sample(1:N_groups,size=N_id,replace=TRUE) # sample into groups\nUg <- rnorm(N_groups,1.5) # group confounds\nX <- rnorm(N_id, Ug[g] ) # individual varying trait\nZ <- rnorm(N_groups) # group varying trait (observed)\nY <- rbern(N_id, p=inv_logit( a0 + X + Ug[g] + bZY*Z[g] ) )\n\ntable(g)\n\n\ncan use a fixed effects model (estimate a different average rate for each group, without pooling) which soaks up the confounding - but its inefficient and it cannot identify any group-level effects\n\n\n# fixed effects\n# X deconfounded, but Z unidentified now!\nprecis(glm(Y~X+Z[g]+as.factor(g),family=binomial),pars=c(\"X\",\"Z\"),2)\n\ndat <- list(Y=Y,X=X,g=g,Ng=N_groups,Z=Z)\n\n# fixed effects\nmf <- ulam(\n    alist(\n        Y ~ bernoulli(p),\n        logit(p) <- a[g] + bxy*X + bzy*Z[g],\n        a[g] ~ dnorm(0,10),\n        c(bxy,bzy) ~ dnorm(0,1)\n    ) , data=dat , chains=4 , cores=4 )\n\n# random effects\nmr <- ulam(\n    alist(\n        Y ~ bernoulli(p),\n        logit(p) <- a[g] + bxy*X + bzy*Z[g],\n        transpars> vector[Ng]:a <<- abar + z*tau,\n        z[g] ~ dnorm(0,1),\n        c(bxy,bzy) ~ dnorm(0,1),\n        abar ~ dnorm(0,1),\n        tau ~ dexp(1)\n    ) , data=dat , chains=4 , cores=4 , sample=TRUE )\n\n\nshould expect your model to have posterior high density regions over the true value\nfixed effects model cannot estimate the group level effects\nmultilevel model pulls intercepts towards each other and thus compromises on identifying the confound so that it can get better estimates for each group\n\nbetter estimates for G, worse estimate for X but you can include Z\n\nMundlak Machine\n\ncalculate group average X which is a descendant of the confound (G) SO if we condition on \\(\\overline{X}_G\\) and treat it like a group level variable, it will partly deconfound our model\nestimate a different average rate for each group via partial pooling via including group average X\nbetter X but improper respect for uncertainty in X-bar (ignoring quality of Xbar across groups)\n\n\n\n# The Mundlak Machine\nxbar <- sapply( 1:N_groups , function(j) mean(X[g==j]) )\ndat$Xbar <- xbar\nmrx <- ulam(\n    alist(\n        Y ~ bernoulli(p),\n        logit(p) <- a[g] + bxy*X + bzy*Z[g] + buy*Xbar[g],\n        transpars> vector[Ng]:a <<- abar + z*tau,\n        z[g] ~ dnorm(0,1),\n        c(bxy,buy,bzy) ~ dnorm(0,1),\n        abar ~ dnorm(0,1),\n        tau ~ dexp(1)\n    ) , data=dat , chains=4 , cores=4 , sample=TRUE )\n\n\ncan fix the problem of not respecting the uncertainty in X-bar\n\ntreat G as unknown and use Xi to estimate\nrespects uncertainty in G\nrun two simultaneous regressions\n\n\n\n# The Latent Mundlak Machine\nmru <- ulam(\n    alist(\n        # Y model\n        Y ~ bernoulli(p),\n        logit(p) <- a[g] + bxy*X + bzy*Z[g] + buy*u[g],\n        transpars> vector[Ng]:a <<- abar + z*tau,\n        # X model\n        X ~ normal(mu,sigma),\n        mu <- aX + bux*u[g],\n        vector[Ng]:u ~ normal(0,1),\n        # priors\n        z[g] ~ dnorm(0,1),\n        c(aX,bxy,buy,bzy) ~ dnorm(0,1),\n        bux ~ dexp(1),\n        abar ~ dnorm(0,1),\n        tau ~ dexp(1),\n        sigma ~ dexp(1)\n    ) , data=dat , chains=4 , cores=4 , sample=TRUE )\n\n\ncan use fixed effects if you are not interested in group-level predictors or prediction\ncan include average X but it is better to use the latent model\nconfounds vary a lot - there is no one answer"
  },
  {
    "objectID": "notes/notes-14.html#rose-thorn",
    "href": "notes/notes-14.html#rose-thorn",
    "title": "Lecture 14 - Correlated Features",
    "section": "Rose / Thorn",
    "text": "Rose / Thorn\nRose:\nThorn:"
  },
  {
    "objectID": "notes/notes-14.html#add-correlated-features",
    "href": "notes/notes-14.html#add-correlated-features",
    "title": "Lecture 14 - Correlated Features",
    "section": "Add Correlated Features",
    "text": "Add Correlated Features\n\nwhen you build models that can identify correlation between features you can use partial pooling between those correlated features\none prior distribution for each cluster\n\none feature: one dimensional distribution (varying intercepts)\ntwo features: two-D distribution (often use multivariate normal distribution - have mean and variation but also correlation between the parameters)\nN features: N-dimensional distribution\n\nhard part: learning associations\n\n\n###########\n# non-centered varying slopes with and without covariance\n\ndat <- list(\n    C = d$use.contraception,\n    D = as.integer(d$district),\n    U = d$urban,\n    A = standardize(d$age.centered),\n    K = d$living.children )\n\n# no covariance\nmCDUnc <- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) <- a[D] + b[D]*U,\n        # define effects using other parameters\n        save> vector[61]:a <<- abar + za*sigma,\n        save> vector[61]:b <<- bbar + zb*tau,\n        # z-scored effects\n        vector[61]:za ~ normal(0,1),\n        vector[61]:zb ~ normal(0,1),\n        # ye olde hyper-priors\n        c(abar,bbar) ~ normal(0,1),\n        c(sigma,tau) ~ exponential(1)\n    ) , data=dat , chains=4 , cores=4 )\n\n\nit is hard to learn the correlation from any finite sample\nLKJ correlation matrix priors - prior for correlation matrices\n\ntends to have shapes\ncan be skeptical of extreme correlations\n\n\n\n# covariance - centered\nmCDUcov <- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) <- a[D] + b[D]*U,\n        # define effects using other parameters\n        transpars> vector[61]:a <<- v[,1],\n        transpars> vector[61]:b <<- v[,2],\n        # priors - centered correlated varying effects\n        matrix[61,2]:v ~ multi_normal(abar,Rho,sigma),\n        vector[2]:abar ~ normal(0,1),\n        corr_matrix[2]:Rho ~ lkj_corr(4),\n        vector[2]:sigma ~ exponential(1)\n    ) , data=dat , chains=4 , cores=4 )\n\n\ncentering vs non-centering to increase efficiency of models\n\ncentered = priors of priors (parameters inside the priors)\nnon-centered = changing model to not have hyper-priors (but be mathematically equivalent) to have increased efficiencies\n\n\n\n# covariance - non-centered\nmCDUcov_nc <- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) <- a[D] + b[D]*U,\n        # define effects using other parameters\n        # this is the non-centered Cholesky machine\n        transpars> vector[61]:a <<- abar[1] + v[,1],\n        transpars> vector[61]:b <<- abar[2] + v[,2],\n        transpars> matrix[61,2]:v <-\n            compose_noncentered( sigma , L_Rho , Z ),\n        # priors - note that none have parameters inside them\n        # that is what makes them non-centered\n        matrix[2,61]:Z ~ normal( 0 , 1 ),\n        vector[2]:abar ~ normal(0,1),\n        cholesky_factor_corr[2]:L_Rho ~ lkj_corr_cholesky( 4 ),\n        vector[2]:sigma ~ exponential(1),\n        # convert Cholesky to Corr matrix\n        gq> matrix[2,2]:Rho <<- Chol_to_Corr(L_Rho)\n    ) , data=dat , chains=4 , cores=4 )\n\n\nnice to compare prior to posterior distribution to make sure the model learned something\ncorrelated varying effects models are easier to fit in Bayesian framework\npriors learn correlation structure\nvarying effects can be correlated even if the prior doesn’t learn the correlations"
  },
  {
    "objectID": "notes/notes-14.html#inconvenient-posteriors",
    "href": "notes/notes-14.html#inconvenient-posteriors",
    "title": "Lecture 14 - Correlated Features",
    "section": "Inconvenient Posteriors",
    "text": "Inconvenient Posteriors\n\ntransforming priors can help with divergent transitions because it changes the shape of the model\nbrms uses non-centered priors as default in multilevel models\n\nnot always better\n\ncentered and non-centered priors are better in different contexts\n\ncentered: lots of data in each cluster (data probability dominant)\nnon-centered: many clusters, sparse evidence (prior dominant)"
  },
  {
    "objectID": "notes/notes-11.html#rose-thorn",
    "href": "notes/notes-11.html#rose-thorn",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Rose / Thorn",
    "text": "Rose / Thorn\nRose: extremely relevant\nThorn: ahhhh how to actually do it"
  },
  {
    "objectID": "notes/notes-11.html#trolley-problems",
    "href": "notes/notes-11.html#trolley-problems",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Trolley Problems",
    "text": "Trolley Problems\n\nthere is a runaway trolley, you are next to a switch\nif you do not pull the switch, it will kill 5 people. If you pull the switch, one person dies\nwhat is the ethics of pulling the switch\ncan assess people’s reactions to trolley problems to assess ethics (can’t actually do trolley problems)\nthree variables that people try to analyze: action, intention, contact\n\ntaking an action is less morally permissible than not\nintention seems more monstrous\nintended access are even worse if they involve contact\n\ntrolley data: answering 30 trolley problems asking how appropriate is the action from 1-7?\noutcome data is ordered categorical data\nestimand: how do action, intention, and contact influence response to a trolley story?\n\nhow are influences of A/I/C associated with other variables?"
  },
  {
    "objectID": "notes/notes-11.html#ordered-categories",
    "href": "notes/notes-11.html#ordered-categories",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Ordered Categories",
    "text": "Ordered Categories\n\ncategories of discrete types with ordered relationships\ndistances between the categories doesn’t have to be the same (e.g., going from 4-5 is probably easier than going from 6-7 because reaching the max means more than shifting in the middle )\nanchor points are common (defaults when we are not sure/feeling meh)\n\nnot everyone shares the same anchor points\n\nneed to think of outcomes as cumulative distribution -> i.e., 5 is everything 5 and under added together\n\nbuild log-odds parameters that correspond to this (log(probability of thing / probability of thing not happening))\nlogit link models\ncumulative proportion -> cumulative log-odds to model these data\nparameters are on cumulative log-odds scale = cutpoints\nnumber of cutpoints you need is n-1 of outcomes (because last one is Infinity because we added the cumulative proportion of everything together to get to 1)\nto predict the data, we have to recalculate cumulative proportion\n\nHow to make it a function of variables (GLM)?\n\nstratify cutpoints\noffset each cutpoint by value of linear model\nRi ~ OrderedLogit(\\(\\phi_i , \\alpha\\))\n\\(\\phi_i\\) = \\(\\beta x_i\\)\n\\(\\alpha\\) = cutpoint\nthere is no intercept in phi because the intercept is already accounted for with cutpoints\nBigger phis give you smaller average responses and smaller phis give you larger average responses (if phi is subtracted - double check software)\n\nExample:\n\n\\(R_i \\sim OrderedLogit(\\phi_i , \\alpha)\\)\n\\(\\phi_i = \\beta_A A_i + \\beta_C C_i + \\beta_I I_i\\)\n\\(\\beta \\sim Normal(0, 0.5)\\)\n\\(\\alpha_j \\sim Normal(0, 1)\\)\n\n\n\ndata(Trolley)\nd <- Trolley\ndat <- list(\n    R = d$response,\n    A = d$action,\n    I = d$intention,\n    C = d$contact\n)\n\nmRX <- ulam(\n    alist(\n        R ~ dordlogit(phi,alpha),\n        phi <- bA*A + bI*I + bC*C,\n        c(bA,bI,bC) ~ normal(0,0.5),\n        alpha ~ normal(0,1)\n    ) , data=dat , chains=4 , cores=4 )\n\nprecis(mRX,2)\n\n\nafter modelling, simulate different outcomes\n\n\n# plot predictive distributions for each treatment\n\nvals <- c(0,1,1) # A,I,C\nRsim <- mcreplicate( 100 , sim(mRX,data=list(A=vals[1],I=vals[2],C=vals[3])) , mc.cores=6 )\nsimplehist(as.vector(Rsim),lwd=8,col=2,xlab=\"Response\")\nmtext(concat(\"A=\",vals[1],\", I=\",vals[2],\", C=\",vals[3]))"
  },
  {
    "objectID": "notes/notes-11.html#competing-causes",
    "href": "notes/notes-11.html#competing-causes",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Competing Causes",
    "text": "Competing Causes\n\nwe can stratify by competing causes - just stratify the model by the variable of interest\n\n\n# total effect of gender\ndat$G <- ifelse(d$male==1,2,1)\nmRXG <- ulam(\n    alist(\n        R ~ dordlogit(phi,alpha),\n        phi <- bA[G]*A + bI[G]*I + bC[G]*C,\n        bA[G] ~ normal(0,0.5),\n        bI[G] ~ normal(0,0.5),\n        bC[G] ~ normal(0,0.5),\n        alpha ~ normal(0,1)\n    ) , data=dat , chains=4 , cores=4 )\n\nprecis(mRXG,2)\n\nvals <- c(0,1,1,2) # A,I,C,G\nRsim <- mcreplicate( 100 , sim(mRXG,data=list(A=vals[1],I=vals[2],C=vals[3],G=vals[4])) , mc.cores=6 )\nsimplehist(as.vector(Rsim),lwd=8,col=2,xlab=\"Response\")\nmtext(concat(\"A=\",vals[1],\", I=\",vals[2],\", C=\",vals[3],\", G=\",vals[4]))\n\n\nis this the causal effect of gender?\n\nconfounded because this is a voluntary sample\neverything is causally associated with participation\nparticipation is implicitly conditioned on - it is a collider\nbecause all our covarying effects of interest are already stratified by the collider participation, it is impossible to get the causal effect of gender BUT we can get direct effect of gender (if we stratify appropriately)\n\n\n\n\n\n\nhow do we put these metric predictors into the model?"
  },
  {
    "objectID": "notes/notes-11.html#ordered-monotonic-predictors",
    "href": "notes/notes-11.html#ordered-monotonic-predictors",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Ordered Monotonic Predictors",
    "text": "Ordered Monotonic Predictors\n\neducation is an ordered category that is a predictor\n\nunlikely that each level has the same effect\nwant a parameter for each level\ntake top level as “maximum effect” and each level gets their own beta and multiply each education level by maximum effect\nindividual delta parameters form a simplex (vector that sums to 1)\nprobability distribution that sums to 1 = Dirichlet\n\nDirichlet\n\ndistribution for distributions\nvector that sums to 1\nneed the same number of input numbers as levels\nbigger the numbers get, the less variation there is in the distributions\nhaving the same number doesn’t mean they are all the same, it means there is no prior expectation of which ones are bigger than the others\n\n\n\n# distributions of education and age\n\nedu_levels <- c( 6 , 1 , 8 , 4 , 7 , 2 , 5 , 3 )\nedu_new <- edu_levels[ d$edu ]\n\ndat$E <- edu_new\ndat$a <- rep(2,7) # dirichlet prior\n\nmRXE <- ulam(\n    alist(\n        R ~ ordered_logistic( phi , alpha ),\n        phi <- bE*sum( delta_j[1:E] ) + bA*A + bI*I + bC*C,\n        alpha ~ normal( 0 , 1 ),\n        c(bA,bI,bC,bE) ~ normal( 0 , 0.5 ),\n        vector[8]: delta_j <<- append_row( 0 , delta ),\n        simplex[7]: delta ~ dirichlet( a )\n    ), data=dat , chains=4 , cores=4 )\n\nprecis(mRXE,2)\n\n# version with transpars\nmRXE2 <- ulam(\n    alist(\n        R ~ ordered_logistic( phi , alpha ),\n        phi <- bE*sum( delta_j[1:E] ) + bA*A + bI*I + bC*C,\n        alpha ~ normal( 0 , 1 ),\n        c(bA,bI,bC,bE) ~ normal( 0 , 0.5 ),\n        transpars> vector[8]: delta_j <<- append_row( 0 , delta ),\n        simplex[7]: delta ~ dirichlet( a )\n    ), data=dat , chains=4 , cores=4 )\n\nl <- link(mRXE2)\n\n\ndeltas from output show the proportion of the effect that is attributed to each education level\n\n\n# BIG MODEL\n\ndat$Y <- standardize(d$age)\n\n# single-threaded version\nmRXEYG <- ulam(\n    alist(\n        R ~ ordered_logistic( phi , alpha ),\n        phi <- bE[G]*sum( delta_j[1:E] ) + \n               bA[G]*A + bI[G]*I + bC[G]*C +\n               bY[G]*Y,\n        alpha ~ normal( 0 , 1 ),\n        bA[G] ~ normal( 0 , 0.5 ),\n        bI[G] ~ normal( 0 , 0.5 ),\n        bC[G] ~ normal( 0 , 0.5 ),\n        bE[G] ~ normal( 0 , 0.5 ),\n        bY[G] ~ normal( 0 , 0.5 ),\n        vector[8]: delta_j <<- append_row( 0 , delta ),\n        simplex[7]: delta ~ dirichlet( a )\n    ), data=dat , chains=4 , cores=4 )\n\n# multi-threaded version\nmRXEYGt <- ulam(\n    alist(\n        R ~ ordered_logistic( phi , alpha ),\n        phi <- bE[G]*sum( delta_j[1:E] ) + \n               bA[G]*A + bI[G]*I + bC[G]*C +\n               bY[G]*Y,\n        alpha ~ normal( 0 , 1 ),\n        bA[G] ~ normal( 0 , 0.5 ),\n        bI[G] ~ normal( 0 , 0.5 ),\n        bC[G] ~ normal( 0 , 0.5 ),\n        bE[G] ~ normal( 0 , 0.5 ),\n        bY[G] ~ normal( 0 , 0.5 ),\n        vector[8]: delta_j <<- append_row( 0 , delta ),\n        simplex[7]: delta ~ dirichlet( a )\n    ), data=dat , chains=4 , cores=4 , threads=2 )\n\nprecis(mRXEYGt,2)"
  },
  {
    "objectID": "notes/notes-11.html#complex-causal-effects",
    "href": "notes/notes-11.html#complex-causal-effects",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Complex Causal Effects",
    "text": "Complex Causal Effects\n\ncausal effects (predicted consequences of intervention) require marginalization\ncausal effect of education requires distribution of age and gender to average over\nsimulate causal effects after thinking carefully over the range of the population you’d like to estimate over\nproblem 1: should not marginalize over this sample because of selection bias (participation)! Post-stratify to new target\nproblem 2: should not set all ages to the same education\n\nwhat does a real population look like?\n\ncausal effect of age requires effect of age on education, which we cannot estimate (because of participation!)\nno matter how complex, its still just a generative simulation using posterior samples\n\nneed generative model to plan estimation\nneed generative model to compute causal estimates"
  },
  {
    "objectID": "notes/notes-11.html#repeat-observations",
    "href": "notes/notes-11.html#repeat-observations",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Repeat Observations",
    "text": "Repeat Observations\n\nrepeating stories and individuals\n\nnot confounds because the treatment is randomized"
  },
  {
    "objectID": "notes/notes-11.html#bonus-post-stratification",
    "href": "notes/notes-11.html#bonus-post-stratification",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Bonus: Post-Stratification",
    "text": "Bonus: Post-Stratification\n\nquality of data is more important than quantity\nbigger samples amplify biases\na non-representative sample can be better than a representative one\n\ndifferent aspects of data matter than representation\ncan correct for non-representativeness\n\nbasic problem: sample is not the target\n\npost-stratification is principled methods for extrapolating from sample to population\npost-stratification requires causal model of reasons sample differs from population\n\nselection nodes\n\n[S] indicates what the sample is being selected by (e.g., age -> different ages are less likely to respond to a survey)\nmany sources of data are already filtered by selection effects\nthe right thing to do depends upon causes of selection\n\nmany questions are really post-stratification questions\njustified descriptions require causal information and post stratification\ntime trends should account for changes in measurement/population\ncomparison is post-stratification from one population to another\nPAPER: a causal framework for cross-cultural generalizability\n4 step plan for honest digital scholarship\n\n\n\nwhat are we trying to describe?\nwhat is the ideal data for doing so?\nwhat data do we actually have?\nwhat causes the differences between (2) and (3)?\n[optional] is there a way to use (3) + (4) to do (1)?"
  }
]