[
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\n\n\n\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n\n\n\n\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\n\n\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to Alec (robit.alec@gmail.com), or Isabella. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\n\n\n\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community.\n\n\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-standards",
    "href": "CODE_OF_CONDUCT.html#our-standards",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Examples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "href": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to Alec (robit.alec@gmail.com), or Isabella. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Rethinking Colearning 2023",
    "section": "",
    "text": "NOTE: website format taken from Alec Robitaille\n\nSchedule\n\nLectures\nHomework\n\nParticipant notes and homework solutions\nResources\nInstallation\nCode of Conduct\n\n\n\nThird round of Statistical Rethinking colearning, this time with 2024 lectures and homework.\nThe first round of Statistical Rethinking colearning (2022) is available here.\nThe second round of Statistical Rethinking colearning (2023) is available here.\n\n\n\n\n\n\n\nMeeting date\nReading\nLectures\n\n\n\n\n25 January\nChapters 1, 2 and 3\n[1] &lt;Science Before Statistics&gt; &lt;Slides&gt;  [2] &lt;Garden of Forking Data&gt; &lt;Slides&gt;\n\n\n08 February\nChapter 4\n[3] &lt;Geocentric Models&gt; &lt;Slides&gt;  [4] &lt;Categories and Curves&gt; &lt;Slides&gt;\n\n\n22 February\nChapters 5 and 6\n[5] &lt;Elemental Confounds&gt; &lt;Slides&gt;  [6] &lt;Good and Bad Controls&gt; &lt;Slides&gt;\n\n\n07 March\nChapters 7 and 8\n[7] &lt;Overfitting&gt; &lt;Slides&gt;  [8] &lt;MCMC&gt; &lt;Slides&gt;\n\n\n21 March\nChapters 9, 10 and 11\n[9] &lt;Modeling Events&gt; &lt;Slides&gt;  [10] &lt;Counts and Confounds&gt; &lt;Slides&gt;\n\n\n04 April\nChapters 11 and 12\n[11] &lt;Ordered Categories&gt; &lt;Slides&gt;  [12] &lt;Multilevel Models&gt; &lt;Slides&gt;\n\n\n18 April\nChapter 13\n[13] &lt;Multilevel Adventures&gt; &lt;Slides&gt;  [14] &lt;Correlated Features&gt; &lt;Slides&gt;\n\n\n2 May\nChapter 14\n[15] &lt;Social Networks&gt; &lt;Slides&gt;  [16] &lt;Gaussian Processes&gt; &lt;Slides&gt;\n\n\n16 May\nChapter 15\n[17] Measurement Error  [18] Missing Data\n\n\n30 May\nChapters 16 and 17\n[19] Beyond GLMs: State-space Models, ODEs  [20] Horoscopes\n\n\n\n\n\n\n\n\n\nMeeting date\nHomework\nSolutions\n\n\n\n\n1 February\nHomework 1\nSolutions\n\n\n15 February\nHomework 2\nSolutions\n\n\n29 February\nHomework 3\nSolutions\n\n\n14 March\nHomework 4\nSolutions\n\n\n28 March\nHomework 5\nSolutions\n\n\n11 April\nHomework 6\nSolutions\n\n\n25 April\nHomework 7\nSolutions\n\n\n9 May\nHomework 8\nSolutions\n\n\n23 May\nHomework 9\nSolutions\n\n\n30 May\nHomework 10\nSolutions\n\n\n\n\n\n\n\n\nAlec\nBella (this repo)\n\n\n\n\n\nAdditional material using other packages or languages\n\nOriginal R: https://github.com/rmcelreath/rethinking/\nR + Tidyverse + ggplot2 + brms: https://bookdown.org/content/4857/\nPython and PyMC3: Python/PyMC3\nJulia and Turing: https://github.com/StatisticalRethinkingJulia and https://github.com/StatisticalRethinkingJulia/TuringModels.jl\n\nSee Richard’s comments about these here: https://github.com/rmcelreath/stat_rethinking_2023#coding\n2022 colearning:\n\nLectures: https://github.com/rmcelreath/stat_rethinking_2022#calendar--topical-outline\nHomework: https://github.com/rmcelreath/stat_rethinking_2022/tree/main/homework\n\nAlso, Alec’s notes and solutions of the 2019 material: https://github.com/robitalec/statistical-rethinking and https://www.statistical-rethinking.robitalec.ca/\n\n\n\nPackage specific install directions. We’ll update these as we go!\nRethinking\n\nrethinking\n\nStan\n\ncmdstanr\nRStan\nbrms\n\nTargets\n\ntargets\nstantargets\n\nV8, needed for the dagitty package\n\nV8\n\n\n\n\nPlease note that this project is released with a Code of Conduct. By participating in this project you agree to abide by its terms."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Statistical Rethinking Colearning 2023",
    "section": "",
    "text": "Meeting date\nReading\nLectures\n\n\n\n\n25 January\nChapters 1, 2 and 3\n[1] &lt;Science Before Statistics&gt; &lt;Slides&gt;  [2] &lt;Garden of Forking Data&gt; &lt;Slides&gt;\n\n\n08 February\nChapter 4\n[3] &lt;Geocentric Models&gt; &lt;Slides&gt;  [4] &lt;Categories and Curves&gt; &lt;Slides&gt;\n\n\n22 February\nChapters 5 and 6\n[5] &lt;Elemental Confounds&gt; &lt;Slides&gt;  [6] &lt;Good and Bad Controls&gt; &lt;Slides&gt;\n\n\n07 March\nChapters 7 and 8\n[7] &lt;Overfitting&gt; &lt;Slides&gt;  [8] &lt;MCMC&gt; &lt;Slides&gt;\n\n\n21 March\nChapters 9, 10 and 11\n[9] &lt;Modeling Events&gt; &lt;Slides&gt;  [10] &lt;Counts and Confounds&gt; &lt;Slides&gt;\n\n\n04 April\nChapters 11 and 12\n[11] &lt;Ordered Categories&gt; &lt;Slides&gt;  [12] &lt;Multilevel Models&gt; &lt;Slides&gt;\n\n\n18 April\nChapter 13\n[13] &lt;Multilevel Adventures&gt; &lt;Slides&gt;  [14] &lt;Correlated Features&gt; &lt;Slides&gt;\n\n\n2 May\nChapter 14\n[15] &lt;Social Networks&gt; &lt;Slides&gt;  [16] &lt;Gaussian Processes&gt; &lt;Slides&gt;\n\n\n16 May\nChapter 15\n[17] Measurement Error  [18] Missing Data\n\n\n30 May\nChapters 16 and 17\n[19] Beyond GLMs: State-space Models, ODEs  [20] Horoscopes\n\n\n\n\n\n\n\n\n\nMeeting date\nHomework\nSolutions\n\n\n\n\n1 February\nHomework 1\nSolutions\n\n\n15 February\nHomework 2\nSolutions\n\n\n29 February\nHomework 3\nSolutions\n\n\n14 March\nHomework 4\nSolutions\n\n\n28 March\nHomework 5\nSolutions\n\n\n11 April\nHomework 6\nSolutions\n\n\n25 April\nHomework 7\nSolutions\n\n\n9 May\nHomework 8\nSolutions\n\n\n23 May\nHomework 9\nSolutions\n\n\n30 May\nHomework 10\nSolutions"
  },
  {
    "objectID": "index.html#participant-notes-and-homework-solutions",
    "href": "index.html#participant-notes-and-homework-solutions",
    "title": "Statistical Rethinking Colearning 2023",
    "section": "",
    "text": "Alec\nBella (this repo)"
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Statistical Rethinking Colearning 2023",
    "section": "",
    "text": "Additional material using other packages or languages\n\nOriginal R: https://github.com/rmcelreath/rethinking/\nR + Tidyverse + ggplot2 + brms: https://bookdown.org/content/4857/\nPython and PyMC3: Python/PyMC3\nJulia and Turing: https://github.com/StatisticalRethinkingJulia and https://github.com/StatisticalRethinkingJulia/TuringModels.jl\n\nSee Richard’s comments about these here: https://github.com/rmcelreath/stat_rethinking_2023#coding\n2022 colearning:\n\nLectures: https://github.com/rmcelreath/stat_rethinking_2022#calendar--topical-outline\nHomework: https://github.com/rmcelreath/stat_rethinking_2022/tree/main/homework\n\nAlso, Alec’s notes and solutions of the 2019 material: https://github.com/robitalec/statistical-rethinking and https://www.statistical-rethinking.robitalec.ca/"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Statistical Rethinking Colearning 2023",
    "section": "",
    "text": "Package specific install directions. We’ll update these as we go!\nRethinking\n\nrethinking\n\nStan\n\ncmdstanr\nRStan\nbrms\n\nTargets\n\ntargets\nstantargets\n\nV8, needed for the dagitty package\n\nV8"
  },
  {
    "objectID": "index.html#code-of-conduct",
    "href": "index.html#code-of-conduct",
    "title": "Statistical Rethinking Colearning 2023",
    "section": "",
    "text": "Please note that this project is released with a Code of Conduct. By participating in this project you agree to abide by its terms."
  },
  {
    "objectID": "homework/targets.html",
    "href": "homework/targets.html",
    "title": "_targets.R",
    "section": "",
    "text": "_targets.R\n\n\n# === Targets -------------------------------------------------------------\n# Alec L. Robitaille\n\n\n\n# Source ------------------------------------------------------------------\nlapply(dir('R', '*.R', full.names = TRUE), source)\n\n\n\n# Options -----------------------------------------------------------------\n# Targets\ntar_option_set(format = 'qs')\n\n# Stan\noptions(mc.cores = 2,\n        scipen = 999,\n        digits = 2)\n\n\n# Data --------------------------------------------------------------------\ndata(Howell1)\ndata(Oxboys)\ndata(foxes)\ndata(Dinosaurs)\ndata(NWOGrants)\ndata(reedfrogs)\n\nmarriage &lt;- sim_happiness(seed = 1977, N_years = 1000) %&gt;%\n  filter(age &gt; 17) %&gt;%\n  mutate(A = (age - 18)/(65-18))\n\nlagged_obs &lt;- Dinosaurs %&gt;%\n  filter(species == \"Massospondylus carinatus\") %&gt;%\n  mutate(time_diff = age - lag(age),\n         sizelast = lag(mass)) %&gt;%\n  slice(-1)\n\n\n# Targets: homework   -----------------------------------------------------\ntargets_homework &lt;- c(\n  \n  tar_target(\n    d,\n    Howell1 %&gt;%\n      filter(age &lt;= 13) %&gt;%\n      select(c(weight, age))\n  ),\n  \n  tar_target(\n    ox,\n    Oxboys %&gt;%\n      group_by(Subject) %&gt;%\n      mutate(growth = height - lag(height, default = first(height), order_by = Occasion)) %&gt;%\n      # remove first occasion because there is no growth\n      filter(Occasion != 1)\n  ),\n  \n  tar_target(\n    fox,\n    foxes %&gt;%\n      mutate(avgfood_s = scale(avgfood),\n             area_s = scale(area),\n             weight_s = scale(weight),\n             groupsize_s = scale(groupsize))\n  ),\n  \n  tar_target(\n    r,\n    reedfrogs %&gt;%\n      mutate(tank = 1:nrow(reedfrogs))\n  ),\n  \n  \n  tar_target(\n    h02_mAW_prior,\n    brm(formula = weight ~ age,\n        data = d,\n        family = gaussian(),\n        sample_prior = \"only\",\n        prior = c(set_prior(\"normal(35, 2)\", class = \"Intercept\"),\n                  set_prior(\"uniform(0, 10)\", class = \"b\"), # uniform so it stays positive\n                  set_prior(\"exponential(1)\", class = \"sigma\")),\n        chains = 4,\n        cores = 1,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h02_mAW,\n    brm(formula = weight ~ age,\n        data = d,\n        family = gaussian(),\n        prior = c(set_prior(\"normal(35, 2)\", class = \"Intercept\"),\n                  set_prior(\"uniform(0, 10)\", class = \"b\"), # uniform so it stays positive\n                  set_prior(\"exponential(1)\", class = \"sigma\")),\n        chains = 4,\n        cores = 1,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h02_mGO_prior,\n    brm(formula = growth ~ 1,\n        data = ox,\n        family = gaussian(),\n        sample_prior = \"only\",\n        prior = c(prior(normal(1.6, 0.5), class = \"Intercept\", lb = 0),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h02_mGO,\n    brm(formula = growth ~ 1,\n        data = ox,\n        family = gaussian(),\n        prior = c(prior(normal(1.6, 0.5), class = \"Intercept\", lb = 0),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h03_q1_prior,\n    brm(formula = avgfood_s ~ area_s,\n        data = fox,\n        sample_prior = \"only\",\n        family = gaussian(),\n        prior = c(prior(normal(0, 0.5), class = \"Intercept\"),\n                  prior(normal(0, 0.5), class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h03_q1,\n    brm(formula = avgfood_s ~ area_s,\n        data = fox,\n        family = gaussian(),\n        prior = c(prior(normal(0, 0.5), class = \"Intercept\"),\n                  prior(normal(0, 0.5), class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h03_q2_prior,\n    brm(formula = weight_s ~ avgfood_s,\n        sample_prior = \"only\",\n        data = fox,\n        family = gaussian(),\n        prior = c(prior(normal(0, 0.5), class = \"Intercept\"),\n                  prior(normal(0, 0.5), class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h03_q2,\n    brm(formula = weight_s ~ avgfood_s,\n        data = fox,\n        family = gaussian(),\n        prior = c(prior(normal(0, 0.5), class = \"Intercept\"),\n                  prior(normal(0, 0.5), class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  \n  tar_target(\n    h03_q3_prior,\n    brm(formula = weight_s ~ avgfood_s + groupsize_s,\n        sample_prior = \"only\",\n        data = fox,\n        family = gaussian(),\n        prior = c(prior(normal(0, 0.5), class = \"Intercept\"),\n                  prior(normal(0, 0.5), class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h03_q3,\n    brm(formula = weight_s ~ avgfood_s + groupsize_s,\n        data = fox,\n        family = gaussian(),\n        prior = c(prior(normal(0, 0.5), class = \"Intercept\"),\n                  prior(normal(0, 0.5), class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h04_q1a,\n    brm(formula = happiness ~ A + (1|married),\n        data = marriage,\n        family = gaussian(),\n        prior = c(prior(normal(0, 1), class = \"Intercept\"),\n                  prior(normal(0, 2), class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h04_q1b,\n    brm(formula = happiness ~ A,\n        data = marriage,\n        family = gaussian(),\n        prior = c(prior(normal(0, 1), class = \"Intercept\"),\n                  prior(normal(0, 2), class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h04_q2,\n    brm(formula = weight_s ~ avgfood_s + groupsize_s + area_s,\n        data = fox,\n        family = gaussian(),\n        prior = c(prior(normal(0, 0.5), class = \"Intercept\"),\n                  prior(normal(0, 0.5), class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h04_q3a,\n    brm(formula = mass ~ age,\n        data = Dinosaurs %&gt;% filter(species == \"Massospondylus carinatus\"),\n        prior = c(prior(normal(90, 20), class = \"Intercept\"),\n                  prior(normal(0, 5), class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h04_q3b,\n    brm(formula = bf(mass ~ sizelast * exp(- exp(logR) * time_diff) +\n                       sizeMax * (1 - exp(-exp(logR) * time_diff)),\n                     logR ~ 1,\n                     sizeMax ~ 1, nl = TRUE),\n        data = lagged_obs,\n        prior = c(prior(normal(245, 50), nlpar = \"sizeMax\", class = \"b\"),\n                  prior(normal(0, 5), nlpar = \"logR\", class = \"b\"),\n                  prior(exponential(1), class = \"sigma\")),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  tar_target(\n    h04_q3c,\n    brm(formula = bf(mass ~ a * b ^ (c * age + d),\n                     a + b + c + d ~ 1,\n                     nl = TRUE),\n        data = Dinosaurs %&gt;% filter(species == \"Massospondylus carinatus\"),\n        prior = c(\n          prior(normal(0, 20), nlpar = 'a'),\n          prior(normal(0, 20), nlpar = 'b'),\n          prior(normal(0, 20), nlpar = 'c', lb = 0),\n          prior(normal(0, 20), nlpar = 'd'),\n          prior(exponential(1), sigma)\n        ),\n        chains = 4,\n        cores = 2,\n        iter = 2000)\n  ),\n  \n  zar_brms(\n    h05_q1,\n    formula = awards | trials(applications) ~ gender,\n    data = NWOGrants,\n    family = 'binomial',\n    prior = c(\n      prior(normal(0, 1.5), class = \"Intercept\"),\n      prior(normal(0, 0.5), class = \"b\"))\n  ),\n  \n  zar_brms(\n    h05_q2,\n    formula = awards | trials(applications) ~ gender*discipline,\n    data = NWOGrants,\n    family = 'binomial',\n    prior = c(\n      prior(normal(0, 1.5), class = \"Intercept\"),\n      prior(normal(0, 0.5), class = \"b\"))\n  ),\n  \n  tar_target(\n    h06_q1_a,\n    brm(formula = surv | trials(density) ~ 1 + (1 | tank),\n        family = 'binomial', \n        sample_prior = 'only',\n        data = r,\n        prior = c(prior(normal(0, 1.5), class = \"Intercept\"),\n                  prior(exponential(1), class = \"sd\")))\n  ),\n  \n  tar_target(\n    h06_q1_b,\n    brm(formula = surv | trials(density) ~ 1 + (1 | tank),\n        family = 'binomial', \n        sample_prior = 'only',\n        data = r,\n        prior = c(prior(normal(0, 1.5), class = \"Intercept\"),\n                  prior(exponential(10), class = \"sd\")))\n  ),\n  \n  tar_target(\n    h06_q1_c,\n    brm(formula = surv | trials(density) ~ 1 + (1 | tank),\n        family = 'binomial', \n        sample_prior = 'only',\n        data = r,\n        prior = c(prior(normal(0, 1.5), class = \"Intercept\"),\n                  prior(exponential(0.1), class = \"sd\")))\n  ),\n  \n  zar_brms(\n    h06_q2, \n    formula = surv | trials(density) ~ 1 + pred*size + (1 | tank),\n    family = 'binomial',\n    data = r, \n    prior = c(prior(normal(0, 1.5), class = \"Intercept\"),\n              prior(exponential(0.1), class = \"sd\"),\n              prior(normal(0, 1), class = \"b\"))\n  )\n  \n)\n\n\n# Quarto ------------------------------------------------------------------\ntargets_quarto &lt;- c(\n  tar_quarto(site, path = '.')\n)\n\n\n\n# Targets: all ------------------------------------------------------------\n# Automatically grab all the \"targets_*\" lists above\nlapply(grep('targets', ls(), value = TRUE), get)"
  },
  {
    "objectID": "homework/homework-04.html",
    "href": "homework/homework-04.html",
    "title": "Homework - Week 04",
    "section": "",
    "text": "Revisit the marriage, age, and happiness collider bias example from Chapter 6. Run models m6.9 and m6.10 again (pages 178–179). Compare these two models using both PSIS and WAIC. Which model is expected to make better predictions, according to these criteria, and which model yields the correct causal inference?\n\n\nm6.9 &lt;- tar_read(h04_q1a)\nm6.10 &lt;- tar_read(h04_q1b)\n\nm6.9 &lt;- add_criterion(m6.9, criterion = \"waic\") \nm6.9 &lt;- add_criterion(m6.9, criterion = \"loo\") \n\nm6.10 &lt;- add_criterion(m6.10, criterion = \"waic\") \nm6.10 &lt;- add_criterion(m6.10, criterion = \"loo\")\n\nloo_compare(m6.9, m6.10)\n\n      elpd_diff se_diff\nm6.9     0.0       0.0 \nm6.10 -193.9      17.6 \n\n\nWe see that the model with both age and marriage is the best predictor using both metrics. Causally, marriage status in this problem is a collider because it is a common consquence of age and happiness. Therefore, the model with just age is the causally correct model."
  },
  {
    "objectID": "homework/homework-04.html#q1",
    "href": "homework/homework-04.html#q1",
    "title": "Homework - Week 04",
    "section": "",
    "text": "Revisit the marriage, age, and happiness collider bias example from Chapter 6. Run models m6.9 and m6.10 again (pages 178–179). Compare these two models using both PSIS and WAIC. Which model is expected to make better predictions, according to these criteria, and which model yields the correct causal inference?\n\n\nm6.9 &lt;- tar_read(h04_q1a)\nm6.10 &lt;- tar_read(h04_q1b)\n\nm6.9 &lt;- add_criterion(m6.9, criterion = \"waic\") \nm6.9 &lt;- add_criterion(m6.9, criterion = \"loo\") \n\nm6.10 &lt;- add_criterion(m6.10, criterion = \"waic\") \nm6.10 &lt;- add_criterion(m6.10, criterion = \"loo\")\n\nloo_compare(m6.9, m6.10)\n\n      elpd_diff se_diff\nm6.9     0.0       0.0 \nm6.10 -193.9      17.6 \n\n\nWe see that the model with both age and marriage is the best predictor using both metrics. Causally, marriage status in this problem is a collider because it is a common consquence of age and happiness. Therefore, the model with just age is the causally correct model."
  },
  {
    "objectID": "homework/homework-04.html#q2",
    "href": "homework/homework-04.html#q2",
    "title": "Homework - Week 04",
    "section": "Q2",
    "text": "Q2\n\nReconsider the urban fox analysis from last week’s homework. On the basis of PSIS and WAIC scores, which combination of variables best predicts body weight (W, weight)? What causal interpretation can you assign each coefficient (parameter) from the best scoring model??\n\n\nfood &lt;- tar_read(h03_q2)\nfood_groupsize &lt;- tar_read(h03_q3)\nfood_groupsize_area &lt;- tar_read(h04_q2)\n\nfood &lt;- add_criterion(food, criterion = \"waic\") \nfood &lt;- add_criterion(food, criterion = \"loo\") \n\nfood_groupsize &lt;- add_criterion(food_groupsize, criterion = \"waic\") \nfood_groupsize &lt;- add_criterion(food_groupsize, criterion = \"loo\")\n\nfood_groupsize_area &lt;- add_criterion(food_groupsize_area, criterion = \"waic\")\nfood_groupsize_area &lt;- add_criterion(food_groupsize_area, criterion = \"loo\")\n\nloo_compare(food, food_groupsize, food_groupsize_area)\n\n                    elpd_diff se_diff\nfood_groupsize_area  0.0       0.0   \nfood_groupsize      -0.5       1.7   \nfood                -5.4       3.3   \n\n\nFor prediction, the best model is the model with food, group size, and area included (though it is very similar to the food + group size model). Food is a descendent of area, which means that conditioning on both means we are estimating the effect of area independent of food availability. In this model, we are only causally assessing the effect of food on weight, independent of area."
  },
  {
    "objectID": "homework/homework-04.html#q3-optional",
    "href": "homework/homework-04.html#q3-optional",
    "title": "Homework - Week 04",
    "section": "Q3 (optional)",
    "text": "Q3 (optional)\n\nThe data in data(Dinosaurs) are body mass estimates at different estimated ages for six different dinosaur species. See ?Dinosaurs for more details. Choose one or more of these species (at least one, but as many as you like) and model its growth. To be precise: Make a predictive model of body mass using age as a predictor. Consider two or more model types for the function relating age to body mass and score each using PSIS and WAIC. Which model do you think is best, on predictive grounds? On scientific grounds? If your answers to these questions differ, why? This is a challenging exercise, because the data are so scarce. But it is also a realistic example, because people publish Nature papers with even less data. So do your best, and I look forward to seeing your growth curves.\n\nGoing to attempt to use the Von Bertanaffy growth equation in brms (source):\n\\[\nL_T = L_0e^{-rt} + L_{max}(1 - e^{-rt})\n\\]\n\nsoi &lt;- Dinosaurs %&gt;% \n  filter(species == \"Massospondylus carinatus\")\n\n## Model 1: Linear Model \nlinear &lt;- tar_read(h04_q3a)\n\nepred &lt;- linear %&gt;% \n  epred_draws(soi)\n\nggplot(data = soi, aes(x = age)) + \n  stat_lineribbon(aes(x = age, y = .epred), data = epred) +\n  geom_jitter(aes(y = mass), width = .1, height = 0, alpha = 0.7) +\n  scale_fill_brewer(palette = \"Greys\") +\n  labs(y = 'Linear Model Predicted Mass (kg)', x = \"Age (yrs)\", fill = \"Credible Interval\") + \n  theme_classic()\n\n\n\n## Model 2: Growth Curve\nlagged_obs &lt;- Dinosaurs %&gt;% \n  filter(species == \"Massospondylus carinatus\") %&gt;% \n  mutate(time_diff = age - lag(age),\n         sizelast = lag(mass)) %&gt;% \n  slice(-1)\n\n# Von Bertanaffy growth equation\nvb_formula &lt;- bf(mass ~ sizelast * exp(- exp(logR) * time_diff) + \n                   sizeMax * (1 - exp(-exp(logR) * time_diff)),\n                 logR ~ 1,\n                 sizeMax ~ 1, nl = TRUE)\n\n\ngrowth &lt;- tar_read(h04_q3b)\n\nepredg &lt;- growth %&gt;% \n  epred_draws(lagged_obs)\n\nggplot(data = lagged_obs, aes(x = age)) + \n  stat_lineribbon(aes(x = age, y = .epred), data = epredg) +\n  geom_jitter(aes(y = mass), width = .1, height = 0, alpha = 0.7) +\n  scale_fill_brewer(palette = \"Greys\") +\n  labs(y = 'Growth Model Predicted Mass (kg)', x = \"Age (yrs)\", fill = \"Credible Interval\") + \n  theme_classic()\n\n\n\n## Model 3: Exponential\nexponential &lt;- tar_read(h04_q3c)\n\neprede &lt;- exponential %&gt;% \n  epred_draws(soi)\n\nggplot(data = soi, aes(x = age)) + \n  stat_lineribbon(aes(x = age, y = .epred), data = eprede) +\n  geom_jitter(aes(y = mass), width = .1, height = 0, alpha = 0.7) +\n  scale_fill_brewer(palette = \"Greys\") +\n  labs(y = 'Exponential Model Predicted Mass (kg)', x = \"Age (yrs)\", fill = \"Credible Interval\") + \n  theme_classic()\n\n\n\n# Compare performance\ndata.frame(model = c('linear', 'growth', 'exponential'), \n           waic = c(waic(linear)[[3]], waic(growth)[[3]], waic(exponential)[[3]]),\n           psis = c(loo(linear)[[1]][[3]], loo(growth)[[1]][[3]], loo(exponential)[[1]][[3]]))\n\n        model      waic      psis\n1      linear -51.78877 104.69629\n2      growth -46.62851  93.93894\n3 exponential -41.85655  85.62959\n\n\nGrowth model performs best predictively. On scientific grounds, maybe the growth model as well since it is rooted in literature and an established equation?"
  },
  {
    "objectID": "homework/homework-03.html",
    "href": "homework/homework-03.html",
    "title": "Homework - Week 03",
    "section": "",
    "text": "The first two problems are based on the same data. The data in data(foxes) are 116 foxes from 30 different urban groups in England. These fox groups are like street gangs. Group size (groupsize) varies from 2 to 8 individuals. Each group maintains its own (almost exclusive) urban territory. Some territories are larger than others. The area variable encodes this information. Some territories also have more avgfood than others. And food influences the weight of each fox. Assume this DAG:\n\n\n\n\n\n\n\nwhere F is avgfood, G is groupsize, A is area, and W is weight. Use the backdoor criterion and estimate the total causal influence of A on F. What effect would increasing the area of a territory have on the amount of food inside it?\n\nTo estimate the total effect of A on F, we just need to model F ~ A because there are no shared causes.\n\ntar_load(fox)\ntar_load(h03_q1_prior)\n\n# look at priors we selected\nprior_summary(h03_q1_prior)\n\n          prior     class   coef group resp dpar nlpar lb ub       source\n normal(0, 0.5)         b                                            user\n normal(0, 0.5)         b area_s                             (vectorized)\n normal(0, 0.5) Intercept                                            user\n exponential(1)     sigma                               0            user\n\n# prior predictive\nepred &lt;- add_epred_draws(fox, h03_q1_prior, ndraws = 100)\n    \nggplot(epred, aes(x = area_s, y = .epred)) +\n      geom_line(aes(group=.draw), alpha = 0.1) +\n      labs(y = \"Predicted Food (standardized)\", x = \"Area (standardized)\") +\n      theme_classic()\n\n\n\n# posterior distribution\ntar_load(h03_q1)\n\n# make dataset sequencing from -2 to 2 (reasonable range of values for standardized numbers)\ndf &lt;- data.frame(area_s = seq(-2, 2, length.out = 1000))\n\nepred_data &lt;- h03_q1 %&gt;% \n  epred_draws(df)\n    \n# plot slopes\np &lt;- ggplot(data = fox, aes(x = area_s)) +\n  stat_lineribbon(aes(x = area_s, y = .epred), data = epred_data) +\n  geom_jitter(aes(y = avgfood_s), width = .1, height = 0, alpha = 0.7) +\n  scale_fill_brewer(palette = \"Greys\") +\n  theme_classic() + \n  scale_y_continuous(limits = c(-2, 2), breaks = c(-2, -1, 0.5, 0, 0.5, 1, 2, 5))\n      \n# extract plot breaks on x and y axes\natx &lt;- c(as.numeric(na.omit(layer_scales(p)$x$break_positions())))\naty &lt;- c(as.numeric(na.omit(layer_scales(p)$y$break_positions())))\n    \n# unscale axis labels for interpretation\np +\n  scale_x_continuous(name = \"Area\",\n                     breaks = atx,\n                     labels = round(atx * sd(fox$area) + mean(fox$area), 1))  +\n  scale_y_continuous(name = \"Average Food\", \n                     breaks = aty,\n                     labels = round(aty * sd(fox$avgfood) + mean(fox$avgfood), 1)) + \n  labs(fill = \"Credible Interval\")\n\n\n\n\nAs area of a territory goes up, average food also increases."
  },
  {
    "objectID": "homework/homework-03.html#q1",
    "href": "homework/homework-03.html#q1",
    "title": "Homework - Week 03",
    "section": "",
    "text": "The first two problems are based on the same data. The data in data(foxes) are 116 foxes from 30 different urban groups in England. These fox groups are like street gangs. Group size (groupsize) varies from 2 to 8 individuals. Each group maintains its own (almost exclusive) urban territory. Some territories are larger than others. The area variable encodes this information. Some territories also have more avgfood than others. And food influences the weight of each fox. Assume this DAG:\n\n\n\n\n\n\n\nwhere F is avgfood, G is groupsize, A is area, and W is weight. Use the backdoor criterion and estimate the total causal influence of A on F. What effect would increasing the area of a territory have on the amount of food inside it?\n\nTo estimate the total effect of A on F, we just need to model F ~ A because there are no shared causes.\n\ntar_load(fox)\ntar_load(h03_q1_prior)\n\n# look at priors we selected\nprior_summary(h03_q1_prior)\n\n          prior     class   coef group resp dpar nlpar lb ub       source\n normal(0, 0.5)         b                                            user\n normal(0, 0.5)         b area_s                             (vectorized)\n normal(0, 0.5) Intercept                                            user\n exponential(1)     sigma                               0            user\n\n# prior predictive\nepred &lt;- add_epred_draws(fox, h03_q1_prior, ndraws = 100)\n    \nggplot(epred, aes(x = area_s, y = .epred)) +\n      geom_line(aes(group=.draw), alpha = 0.1) +\n      labs(y = \"Predicted Food (standardized)\", x = \"Area (standardized)\") +\n      theme_classic()\n\n\n\n# posterior distribution\ntar_load(h03_q1)\n\n# make dataset sequencing from -2 to 2 (reasonable range of values for standardized numbers)\ndf &lt;- data.frame(area_s = seq(-2, 2, length.out = 1000))\n\nepred_data &lt;- h03_q1 %&gt;% \n  epred_draws(df)\n    \n# plot slopes\np &lt;- ggplot(data = fox, aes(x = area_s)) +\n  stat_lineribbon(aes(x = area_s, y = .epred), data = epred_data) +\n  geom_jitter(aes(y = avgfood_s), width = .1, height = 0, alpha = 0.7) +\n  scale_fill_brewer(palette = \"Greys\") +\n  theme_classic() + \n  scale_y_continuous(limits = c(-2, 2), breaks = c(-2, -1, 0.5, 0, 0.5, 1, 2, 5))\n      \n# extract plot breaks on x and y axes\natx &lt;- c(as.numeric(na.omit(layer_scales(p)$x$break_positions())))\naty &lt;- c(as.numeric(na.omit(layer_scales(p)$y$break_positions())))\n    \n# unscale axis labels for interpretation\np +\n  scale_x_continuous(name = \"Area\",\n                     breaks = atx,\n                     labels = round(atx * sd(fox$area) + mean(fox$area), 1))  +\n  scale_y_continuous(name = \"Average Food\", \n                     breaks = aty,\n                     labels = round(aty * sd(fox$avgfood) + mean(fox$avgfood), 1)) + \n  labs(fill = \"Credible Interval\")\n\n\n\n\nAs area of a territory goes up, average food also increases."
  },
  {
    "objectID": "homework/homework-03.html#q2",
    "href": "homework/homework-03.html#q2",
    "title": "Homework - Week 03",
    "section": "Q2",
    "text": "Q2\n\nInfer the total causal effect of adding food F to a territory on the weight W of foxes. Can you calculate the causal effect by simulating an intervention on food?\n\nTotal effect of food on weight is estimated by modelling W ~ F (no backdoor paths).\n\ntar_load(fox)\ntar_load(h03_q2_prior)\n\n# look at priors we selected\nprior_summary(h03_q2_prior)\n\n          prior     class      coef group resp dpar nlpar lb ub       source\n normal(0, 0.5)         b                                               user\n normal(0, 0.5)         b avgfood_s                             (vectorized)\n normal(0, 0.5) Intercept                                               user\n exponential(1)     sigma                                  0            user\n\n# prior predictive\nepred &lt;- add_epred_draws(fox, h03_q2_prior, ndraws = 100)\n    \nggplot(epred, aes(x = avgfood_s, y = .epred)) +\n      geom_line(aes(group=.draw), alpha = 0.1) +\n      labs(y = \"Predicted Weight (standardized)\", x = \"Area (standardized)\") +\n      theme_classic()\n\n\n\n# posterior distribution\ntar_load(h03_q2)\n\n# make dataset sequencing from -2 to 2 (reasonable range of values for standardized numbers)\ndf &lt;- data.frame(avgfood_s = seq(-2, 2, length.out = 1000))\n\nepred_data &lt;- h03_q2 %&gt;% \n  epred_draws(df)\n    \n# plot slopes\np &lt;- ggplot(data = fox, aes(x = avgfood_s)) +\n  stat_lineribbon(aes(x = avgfood_s, y = .epred), data = epred_data) +\n  geom_jitter(aes(y = weight_s), width = .1, height = 0, alpha = 0.7) +\n  scale_fill_brewer(palette = \"Greys\") +\n  theme_classic() + \n  scale_y_continuous(limits = c(-2, 2), breaks = c(-2, -1, 0.5, 0, 0.5, 1, 2, 5))\n      \n# extract plot breaks on x and y axes\natx &lt;- c(as.numeric(na.omit(layer_scales(p)$x$break_positions())))\naty &lt;- c(as.numeric(na.omit(layer_scales(p)$y$break_positions())))\n    \n# unscale axis labels for interpretation\np +\n  scale_x_continuous(name = \"Average Food\",\n                     breaks = atx,\n                     labels = round(atx * sd(fox$avgfood) + mean(fox$avgfood), 1))  +\n  scale_y_continuous(name = \"Weight\", \n                     breaks = aty,\n                     labels = round(aty * sd(fox$weight) + mean(fox$weight), 1)) + \n  labs(fill = \"Credible Interval\")\n\n\n\n# does slope change at different values of food? \nh03_q2 %&gt;% \n  emtrends(~ avgfood_s,\n           var = \"avgfood_s\", \n           at = list(avgfood_s = c(0, 2)),\n           epred = TRUE, re_formula = NA) \n\n avgfood_s avgfood_s.trend lower.HPD upper.HPD\n         0         -0.0253    -0.202     0.172\n         2         -0.0253    -0.202     0.172\n\nPoint estimate displayed: median \nHPD interval probability: 0.95 \n\ncont &lt;- h03_q2 %&gt;% \n  emtrends(~ avgfood_s,\n           var = \"avgfood_s\", \n           at = list(avgfood_s = c(0, 2)),\n           epred = TRUE, re_formula = NA) %&gt;% \n  gather_emmeans_draws()\n\nggplot(cont, aes(x = .value, fill = factor(avgfood_s))) +\n  stat_halfeye(slab_alpha = 0.75) +\n  scale_fill_manual(values = c('darkseagreen', 'lightblue')) +\n  labs(y = \"Density\", x = \"Average marginal effect of a unit increase in avgfood\", fill = \"avgfood (standardized)\") + \n  theme_classic() + \n  theme(legend.position = \"bottom\")\n\n\n\n# NO! Linear model, slope doesn't change across different values\n\n# simulate an intervention: calculate the contrast between a lot of food and average amount of food\nmf &lt;- data.frame(avgfood_s = 0)\nhf &lt;- data.frame(avgfood_s = 1)\n\nmed &lt;- h03_q2 %&gt;% \n  epred_draws(newdata = mf)\n\nhigh &lt;- h03_q2 %&gt;% \n  epred_draws(newdata = hf)\n\ncont &lt;- data.frame(cont = med$.epred - high$.epred)\n\nggplot(cont, aes(x = cont)) + \n  stat_halfeye() +\n  labs(x = \"avgfood_s of 0 - avgfood_s of 1\", y = \"\") + \n  theme_classic() \n\n\n\n\nTotal effect of food on weight is very small, we see very little effect of increasing food"
  },
  {
    "objectID": "homework/homework-03.html#q3",
    "href": "homework/homework-03.html#q3",
    "title": "Homework - Week 03",
    "section": "Q3",
    "text": "Q3\n\nInfer the direct causal effect of adding food F to a territory on the weight W of foxes. In light of your estimates from this problem and the previous one, what do you think is going on with these foxes?\n\nDirect causal effect of food on weight requires stratifying by groupsize (G).\n\ntar_load(h03_q3)\n\n\n# make dataset sequencing from -2 to 2 (reasonable range of values for standardized numbers)\n# hold groupsize constant (at average level)\ndf &lt;- data.frame(avgfood_s = seq(-2, 2, length.out = 1000),\n                 groupsize_s = 0)\n\nepred_data &lt;- h03_q3 %&gt;% \n  epred_draws(df)\n    \n# plot slopes\np &lt;- ggplot(data = fox, aes(x = avgfood_s)) +\n  stat_lineribbon(aes(x = avgfood_s, y = .epred), data = epred_data) +\n  geom_jitter(aes(y = weight_s), width = .1, height = 0, alpha = 0.7) +\n  scale_fill_brewer(palette = \"Greys\") +\n  theme_classic() + \n  scale_y_continuous(limits = c(-2, 2), breaks = c(-2, -1, 0.5, 0, 0.5, 1, 2, 5))\n      \n# extract plot breaks on x and y axes\natx &lt;- c(as.numeric(na.omit(layer_scales(p)$x$break_positions())))\naty &lt;- c(as.numeric(na.omit(layer_scales(p)$y$break_positions())))\n    \n# unscale axis labels for interpretation\np +\n  scale_x_continuous(name = \"Average Food\",\n                     breaks = atx,\n                     labels = round(atx * sd(fox$avgfood) + mean(fox$avgfood), 1))  +\n  scale_y_continuous(name = \"Weight\", \n                     breaks = aty,\n                     labels = round(aty * sd(fox$weight) + mean(fox$weight), 1)) + \n  labs(fill = \"Credible Interval\", title = \"Group size held constant\")\n\n\n\n\nWhen we stratify by group size, the direct effect of food on weight is strongly positive. Group size may diminish the total effect of food on weight because as avgfood increases, group size increases and the same amount of food is available for each individual, resulting in no change in weight."
  },
  {
    "objectID": "homework/homework-03.html#q4-optional",
    "href": "homework/homework-03.html#q4-optional",
    "title": "Homework - Week 03",
    "section": "Q4 (optional)",
    "text": "Q4 (optional)\n\nSuppose there is an unobserved confound that influences F and G, like this:\n\n\n\n\n\n\n\nAssuming the DAG above is correct, again estimate both the total and direct causal effects of F on W. What impact does the unobserved confound have?\n\nTotal causal effect is impossible to estimate, because you can’t close the backdoor path through U. Direct causal effect is the same, estimated by stratifying on G."
  },
  {
    "objectID": "homework/homework-02.html",
    "href": "homework/homework-02.html",
    "title": "Homework - Week 02",
    "section": "",
    "text": "From the Howell1 dataset, consider only the people younger than 13 years old. Estimate the causal association between age and weight. Assume that age influences weight through two paths. First, age influences height. Second, age directly influences weight through age-related changes in muscle growth and body proportions. Draw the DAG that represents these causal relationships. And then write a generative simulation that takes age as an input and simulates height and weight, obeying the relationships in the DAG.\n\nDAG:\n\ndagified &lt;- dagify(\n    # outline relationships between your variables\n    Weight ~ Age + Height,\n    Height ~ Age,\n   # assign exposure and outcome\n    exposure = 'Age',\n    outcome = 'Weight', \n   # assign coordinates so they aren't randomly assigned\n    coords = list(x = c(Age = -1, Height = 0, Weight = 0),\n                  y = c(Age = 0, Height = 1, Weight = -1))) %&gt;%\n    # tidy_dagitty makes dag into tidy table format\n    tidy_dagitty() %&gt;%\n    # add column that assigns variables to groups that you want to colour code\n    mutate(status = case_when(name == \"Age\" ~ 'exposure',\n                              name == \"Weight\" ~ 'outcome',\n                              .default = 'NA'))\n\n  ggplot(dagified, aes(x = x, y = y, xend = xend, yend = yend)) +\n    theme_dag() +\n    # colour nodes by the column you made in previous step\n    geom_dag_point(aes(color = status)) +\n    # add labels so you can have more readable variable names\n    geom_dag_label_repel(aes(label = name, fill = status),\n                         color = \"white\", fontface = \"bold\") +\n    # adding geom_dag_edges here so that the arrows will go over the labels\n    geom_dag_edges() +\n    # assign the colours that you want\n    scale_fill_manual(values = c('darkseagreen', 'grey', 'lightblue')) +\n    scale_colour_manual(values = c('darkseagreen', 'grey', 'lightblue')) +\n   # removing colour legend here\n    theme(legend.position = 'none')\n\n\n\n\n\n\\[\nWeight = f_{Weight}(Age, Height)\n\\]\n\nGenerative Simulation:\n\nN &lt;- 1e3\n\n# generate 1000 youth ranging from 1-12\nage &lt;- sample(seq(from = 1, to = 12), size = N, replace = T)\n\n# generate heights that are variable but increase with increasing age \n# height is 8 * age with 2 SD (maybe too small for babies but generally okay)\nbAH &lt;- 8\nheight &lt;- rnorm(N, bAH*age, 2)\n\n# generate weights that are variable but increase with increasing height and age (but are smaller than heights)\nbAW &lt;- 0.1\nbHW &lt;- 0.5\nweight &lt;- rnorm(N, bAW*age + bHW*height, 2)\n\ngen &lt;- data.frame(age, height, weight)\n\nhead(gen)\n\n  age   height   weight\n1  10 80.56326 42.92326\n2   8 62.59013 30.63146\n3  10 79.20380 39.97908\n4   8 62.66670 33.18036\n5  10 79.87202 36.92906\n6  10 82.97218 42.05611"
  },
  {
    "objectID": "homework/homework-02.html#q1",
    "href": "homework/homework-02.html#q1",
    "title": "Homework - Week 02",
    "section": "",
    "text": "From the Howell1 dataset, consider only the people younger than 13 years old. Estimate the causal association between age and weight. Assume that age influences weight through two paths. First, age influences height. Second, age directly influences weight through age-related changes in muscle growth and body proportions. Draw the DAG that represents these causal relationships. And then write a generative simulation that takes age as an input and simulates height and weight, obeying the relationships in the DAG.\n\nDAG:\n\ndagified &lt;- dagify(\n    # outline relationships between your variables\n    Weight ~ Age + Height,\n    Height ~ Age,\n   # assign exposure and outcome\n    exposure = 'Age',\n    outcome = 'Weight', \n   # assign coordinates so they aren't randomly assigned\n    coords = list(x = c(Age = -1, Height = 0, Weight = 0),\n                  y = c(Age = 0, Height = 1, Weight = -1))) %&gt;%\n    # tidy_dagitty makes dag into tidy table format\n    tidy_dagitty() %&gt;%\n    # add column that assigns variables to groups that you want to colour code\n    mutate(status = case_when(name == \"Age\" ~ 'exposure',\n                              name == \"Weight\" ~ 'outcome',\n                              .default = 'NA'))\n\n  ggplot(dagified, aes(x = x, y = y, xend = xend, yend = yend)) +\n    theme_dag() +\n    # colour nodes by the column you made in previous step\n    geom_dag_point(aes(color = status)) +\n    # add labels so you can have more readable variable names\n    geom_dag_label_repel(aes(label = name, fill = status),\n                         color = \"white\", fontface = \"bold\") +\n    # adding geom_dag_edges here so that the arrows will go over the labels\n    geom_dag_edges() +\n    # assign the colours that you want\n    scale_fill_manual(values = c('darkseagreen', 'grey', 'lightblue')) +\n    scale_colour_manual(values = c('darkseagreen', 'grey', 'lightblue')) +\n   # removing colour legend here\n    theme(legend.position = 'none')\n\n\n\n\n\n\\[\nWeight = f_{Weight}(Age, Height)\n\\]\n\nGenerative Simulation:\n\nN &lt;- 1e3\n\n# generate 1000 youth ranging from 1-12\nage &lt;- sample(seq(from = 1, to = 12), size = N, replace = T)\n\n# generate heights that are variable but increase with increasing age \n# height is 8 * age with 2 SD (maybe too small for babies but generally okay)\nbAH &lt;- 8\nheight &lt;- rnorm(N, bAH*age, 2)\n\n# generate weights that are variable but increase with increasing height and age (but are smaller than heights)\nbAW &lt;- 0.1\nbHW &lt;- 0.5\nweight &lt;- rnorm(N, bAW*age + bHW*height, 2)\n\ngen &lt;- data.frame(age, height, weight)\n\nhead(gen)\n\n  age   height   weight\n1  10 80.56326 42.92326\n2   8 62.59013 30.63146\n3  10 79.20380 39.97908\n4   8 62.66670 33.18036\n5  10 79.87202 36.92906\n6  10 82.97218 42.05611"
  },
  {
    "objectID": "homework/homework-02.html#q2",
    "href": "homework/homework-02.html#q2",
    "title": "Homework - Week 02",
    "section": "Q2",
    "text": "Q2\n\nEstimate the total causal effect of each year of growth on weight.\n\n\nTotal causal effect does not stratify by height, it includes both direct and indirect effects\n\nPrior predictive:\n\ntar_load(h02_mAW_prior)\nprint(h02_mAW_prior$formula)\n\nweight ~ age \n\nprior_summary(h02_mAW_prior)\n\n          prior     class coef group resp dpar nlpar lb ub       source\n uniform(0, 10)         b                                          user\n uniform(0, 10)         b  age                             (vectorized)\n  normal(35, 2) Intercept                                          user\n exponential(1)     sigma                             0            user\n\ngen_sub &lt;- gen %&gt;% select(c(age))\n\nepred &lt;- add_epred_draws(gen_sub, h02_mAW_prior, ndraws = 100)\n    \nggplot(epred, aes(x = age, y = .epred)) +\n      geom_line(aes(group=.draw), alpha = 0.1) +\n      labs(y = \"Predicted Weight\", x = \"Age\") +\n      theme_classic()\n\n\n\n\nPosterior Distribution:\n\ntar_load(h02_mAW)\nprint(h02_mAW$formula)\n\nweight ~ age \n\ndata(Howell1)\nyouth &lt;- Howell1 %&gt;% filter(age &lt; 13)\n\navg_youth &lt;- youth %&gt;% \n  summarize(age = mean(age))\n\n\npred_mean &lt;- h02_mAW %&gt;% \n  epred_draws(newdata = avg_youth)\n\n\nggplot(pred_mean, aes(x = .epred)) + \n  stat_halfeye() +\n  labs(x = \"Weight (kg) for kid of average age\", y = \"\") + \n  theme_classic() \n\n\n\n# prediction for relationship between age and weight\nepred &lt;- h02_mAW %&gt;% \n      epred_draws(youth)\n\n# plot slopes\nggplot(data = youth, aes(x = age)) +\n  stat_lineribbon(aes(x = age, y = .epred), data = epred) +\n  geom_jitter(aes(y = weight), width = .1, height = 0, alpha = 0.7) +\n  scale_fill_brewer(palette = \"Greys\") +\n  labs(y = 'Linear Model Predicted Weight (kg)', x = \"Age (yrs)\", fill = \"Credible Interval\") + \n  theme_classic()\n\n\n\n\nPosterior Predictive:\n\n# prediction for average kid\npred_mean &lt;- h02_mAW %&gt;% \n  predicted_draws(newdata = avg_youth)\n\n\nggplot(pred_mean, aes(x = .prediction)) + \n  stat_halfeye() +\n  labs(x = \"Weight (kg) for kid of average age\", y = \"\") + \n  theme_classic() \n\n\n\n# prediction for relationship between age and weight\npred &lt;- h02_mAW %&gt;% \n      predicted_draws(youth)\n\n# plot slopes\nggplot(data = youth, aes(x = age)) +\n  stat_lineribbon(aes(x = age, y = .prediction), data = pred) +\n  geom_jitter(aes(y = weight), width = .1, height = 0, alpha = 0.7) +\n  scale_fill_brewer(palette = \"Greys\") +\n  labs(y = 'Predicted Weight (kg)', x = \"Age (yrs)\", fill = \"Credible Interval\") + \n  theme_classic()"
  },
  {
    "objectID": "homework/homework-02.html#q3-optional",
    "href": "homework/homework-02.html#q3-optional",
    "title": "Homework - Week 02",
    "section": "Q3 (optional):",
    "text": "Q3 (optional):\n\nThe data in data(Oxboys) (rethinking package) are growth records for 26 boys measured over 9 periods. I want you to model their growth. Specifically, model the increments in growth from one period (Occassion in the data table) to the next. Each increment is simply the difference between height in one occasion and height in the previous occasion. Since none of these boys shrunk during the study, all of the growth increments are greater than zero. Estimate the posterior distribution of these increments. Constrain the distribution so it is always positive - it should not be possible for the model to think that boys can shrink from year to year. Finally compute the posterior distribution of the total growth over all 9 occasions.\n\n\n\\[Growth = f(Time)\\]\n\nwhere Growth = \\[\\Delta Height\\]\nand Time = Occasion\n\\[\n\\Delta Height = f(Occasion)\n\\]\n\n\nCheck that our priors are constrained to positive values:\n\ndata(Oxboys)\n\nox &lt;- Oxboys %&gt;% \n  group_by(Subject) %&gt;% \n  mutate(growth = height - lag(height, default = first(height), order_by = Occasion)) %&gt;% \n  # remove first occasion because there is no growth \n  filter(Occasion != 1)\n\ntar_load(h02_mGO_prior)\nprior_summary(h02_mGO_prior)\n\n            prior     class coef group resp dpar nlpar lb ub source\n normal(1.6, 0.5) Intercept                             0      user\n   exponential(1)     sigma                             0      user\n\nposprior &lt;- add_epred_draws(ox, h02_mGO_prior, ndraws = 100)\n    \nggplot(posprior, aes(x = .epred)) +\n  geom_histogram() +\n  labs(x = \"Intercept\")+ \n  theme_classic()\n\n\n\n\nSuccess! We see no negative intercept values in our prior.\nInvestigate posterior distribution:\n\ntar_load(h02_mGO)\nh02_mGO$formula\n\ngrowth ~ 1 \n\npost_growth &lt;- h02_mGO %&gt;% \n  predicted_draws(newdata = ox)\n\nggplot(post_growth, aes(x = .prediction)) + \n  stat_halfeye() +\n  labs(x = \"Growth\", y = \"\") + \n  theme_classic() \n\n\n\n\nHmm… maybe not a success …\nTotal growth over 8 occasions:\n\n# need to randomly sample the posterior 8 times and then sum the samples, 1000 times \n\nt &lt;- data.frame(total_growth = replicate(1000, {sum(sample(post_growth$.prediction, 8, replace = T))}))\n\nggplot(t, aes(x = total_growth)) + \n  stat_halfeye() +\n  labs(x = \"Growth\", y = \"\") + \n  theme_classic()"
  },
  {
    "objectID": "homework/homework-06.html",
    "href": "homework/homework-06.html",
    "title": "Homework - Week 06",
    "section": "",
    "text": "Conduct a prior predictive simulation for the Reedfrog model. By this I mean to simulate the prior distribution of tank survival probabilities αj. Start by using this prior:\n\n$$\n_j Normal({}, )\n\\\n{} Normal(0, 1)\n\\\nExponential(1)\n$$\n\nBe sure to transform the αj values to the probability scale for plotting and summary. How does increasing the width of the prior on σ change the prior distribution of αj? You might try Exponential(10) and Exponential(0.1) for example.\n\n\nr &lt;- reedfrogs %&gt;% \n  mutate(tank = 1:nrow(reedfrogs))\n\nexp1 &lt;- tar_read(h06_q1_a)\nexp10 &lt;- tar_read(h06_q1_b)\nexp0.1 &lt;- tar_read(h06_q1_c)\n\n# Prior Predictive Simulation 1 \nexp1 %&gt;% \n  add_predicted_draws(newdata = r,\n                  re_formula = NA) %&gt;% \n  ggplot() + \n  stat_pointinterval(aes(tank, .prediction/density), .width = 0.95) + \n  geom_point(aes(x = tank, y = surv/density), colour = 'red') + \n  geom_hline(yintercept = 0.8, linetype = 2, linewidth = 1/4) +\n  geom_vline(xintercept = c(16.5, 32.5), linewidth = 1/4, color = \"grey25\") + \n  labs(y = 'Prior predicted survival rate', x = 'Tank') + \n  ggtitle(\"sigma = 1\") + \n  theme_classic()\n\n\n\n# Prior Predictive Simulation 2\nexp10 %&gt;% \n  predicted_draws(newdata = r,\n                  re_formula = NA) %&gt;%\n  ggplot() + \n  stat_pointinterval(aes(tank, .prediction/density), .width = 0.95) + \n  geom_point(aes(x = tank, y = surv/density), colour = 'red') + \n  geom_hline(yintercept = 0.8, linetype = 2, linewidth = 1/4) +\n  geom_vline(xintercept = c(16.5, 32.5), linewidth = 1/4, color = \"grey25\") + \n  labs(y = 'Prior predicted survival rate', x = 'Tank') + \n  ggtitle(\"sigma = 10\") + \n  theme_classic()\n\n\n\n# Prior Predictive Simulation 3\nexp0.1 %&gt;% \n  predicted_draws(newdata = r,\n                  re_formula = NA) %&gt;% \n  ggplot() + \n  stat_pointinterval(aes(tank, .prediction/density), .width = 0.95) + \n  geom_point(aes(x = tank, y = surv/density), colour = 'red') + \n  geom_hline(yintercept = 0.8, linetype = 2, linewidth = 1/4) +\n  geom_vline(xintercept = c(16.5, 32.5), linewidth = 1/4, color = \"grey25\") +\n  labs(y = 'Prior predicted survival rate', x = 'Tank') + \n  ggtitle(\"sigma = 0.1\") + \n  theme_classic()\n\n\n\n\nNOTE: did this wrong!! This is not \\(\\alpha_j\\), this is \\(\\bar{\\alpha}\\) . Checked Richard’s answers and I should be visualizing the population level effect (duh) - going to attempt this here:\n\nexp1 %&gt;% \n  add_predicted_draws(newdata = r,\n                  re_formula = NA) %&gt;% \n  ggplot() +\n  stat_histinterval(aes(x = .prediction/density)) + \n  labs(x = \"Prior predicted survival\", y = \"Density\") + \n  ggtitle(label = \"Sigma = 1\") + \n  theme_classic()\n\n\n\nexp10 %&gt;% \n  add_predicted_draws(newdata = r) %&gt;% \n  ggplot() +\n  stat_histinterval(aes(x = .prediction/density)) + \n  labs(x = \"Prior predicted survival\", y = \"Density\") + \n  ggtitle(label = \"Sigma = 10\") + \n  theme_classic()\n\n\n\nexp0.1 %&gt;% \n  add_predicted_draws(newdata = r) %&gt;% \n  ggplot() +\n  stat_histinterval(aes(x = .prediction/density)) + \n  labs(x = \"Prior predicted survival\", y = \"Density\") + \n  ggtitle(label = \"Sigma = 0.1\") + \n  theme_classic()\n\n\n\n\nIncreasing sigma evens out the probability distribution instead of having it bunched in two extremes like we see at 0.1"
  },
  {
    "objectID": "homework/homework-06.html#q1",
    "href": "homework/homework-06.html#q1",
    "title": "Homework - Week 06",
    "section": "",
    "text": "Conduct a prior predictive simulation for the Reedfrog model. By this I mean to simulate the prior distribution of tank survival probabilities αj. Start by using this prior:\n\n$$\n_j Normal({}, )\n\\\n{} Normal(0, 1)\n\\\nExponential(1)\n$$\n\nBe sure to transform the αj values to the probability scale for plotting and summary. How does increasing the width of the prior on σ change the prior distribution of αj? You might try Exponential(10) and Exponential(0.1) for example.\n\n\nr &lt;- reedfrogs %&gt;% \n  mutate(tank = 1:nrow(reedfrogs))\n\nexp1 &lt;- tar_read(h06_q1_a)\nexp10 &lt;- tar_read(h06_q1_b)\nexp0.1 &lt;- tar_read(h06_q1_c)\n\n# Prior Predictive Simulation 1 \nexp1 %&gt;% \n  add_predicted_draws(newdata = r,\n                  re_formula = NA) %&gt;% \n  ggplot() + \n  stat_pointinterval(aes(tank, .prediction/density), .width = 0.95) + \n  geom_point(aes(x = tank, y = surv/density), colour = 'red') + \n  geom_hline(yintercept = 0.8, linetype = 2, linewidth = 1/4) +\n  geom_vline(xintercept = c(16.5, 32.5), linewidth = 1/4, color = \"grey25\") + \n  labs(y = 'Prior predicted survival rate', x = 'Tank') + \n  ggtitle(\"sigma = 1\") + \n  theme_classic()\n\n\n\n# Prior Predictive Simulation 2\nexp10 %&gt;% \n  predicted_draws(newdata = r,\n                  re_formula = NA) %&gt;%\n  ggplot() + \n  stat_pointinterval(aes(tank, .prediction/density), .width = 0.95) + \n  geom_point(aes(x = tank, y = surv/density), colour = 'red') + \n  geom_hline(yintercept = 0.8, linetype = 2, linewidth = 1/4) +\n  geom_vline(xintercept = c(16.5, 32.5), linewidth = 1/4, color = \"grey25\") + \n  labs(y = 'Prior predicted survival rate', x = 'Tank') + \n  ggtitle(\"sigma = 10\") + \n  theme_classic()\n\n\n\n# Prior Predictive Simulation 3\nexp0.1 %&gt;% \n  predicted_draws(newdata = r,\n                  re_formula = NA) %&gt;% \n  ggplot() + \n  stat_pointinterval(aes(tank, .prediction/density), .width = 0.95) + \n  geom_point(aes(x = tank, y = surv/density), colour = 'red') + \n  geom_hline(yintercept = 0.8, linetype = 2, linewidth = 1/4) +\n  geom_vline(xintercept = c(16.5, 32.5), linewidth = 1/4, color = \"grey25\") +\n  labs(y = 'Prior predicted survival rate', x = 'Tank') + \n  ggtitle(\"sigma = 0.1\") + \n  theme_classic()\n\n\n\n\nNOTE: did this wrong!! This is not \\(\\alpha_j\\), this is \\(\\bar{\\alpha}\\) . Checked Richard’s answers and I should be visualizing the population level effect (duh) - going to attempt this here:\n\nexp1 %&gt;% \n  add_predicted_draws(newdata = r,\n                  re_formula = NA) %&gt;% \n  ggplot() +\n  stat_histinterval(aes(x = .prediction/density)) + \n  labs(x = \"Prior predicted survival\", y = \"Density\") + \n  ggtitle(label = \"Sigma = 1\") + \n  theme_classic()\n\n\n\nexp10 %&gt;% \n  add_predicted_draws(newdata = r) %&gt;% \n  ggplot() +\n  stat_histinterval(aes(x = .prediction/density)) + \n  labs(x = \"Prior predicted survival\", y = \"Density\") + \n  ggtitle(label = \"Sigma = 10\") + \n  theme_classic()\n\n\n\nexp0.1 %&gt;% \n  add_predicted_draws(newdata = r) %&gt;% \n  ggplot() +\n  stat_histinterval(aes(x = .prediction/density)) + \n  labs(x = \"Prior predicted survival\", y = \"Density\") + \n  ggtitle(label = \"Sigma = 0.1\") + \n  theme_classic()\n\n\n\n\nIncreasing sigma evens out the probability distribution instead of having it bunched in two extremes like we see at 0.1"
  },
  {
    "objectID": "homework/homework-06.html#q2",
    "href": "homework/homework-06.html#q2",
    "title": "Homework - Week 06",
    "section": "Q2",
    "text": "Q2\n\nRevisit the Reedfrog survival data, data(reedfrogs). Start with the varying effects model from the book and lecture. Then modify it to estimate the causal effects of the treatment variables pred and size, including how size might modify the effect of predation. An easy approach is to estimate an effect for each combination of pred and size. Justify your model with a DAG of this experiment.\n\nThe DAG presented in the lecture appears as:\n\n\n\n\n\nI mostly agree with this, although I think that in a natural setting the DAG would look different and there would be confounds. In this case, we can add everything to the model and independently examine the effects (total and direct are the same) of each variable. However, in Richard’s answers he has an interaction between predation (P) and size (G) - which makes sense. Larger individuals are more likely to be noticed and predated upon.\nSo my model looks like:\n\nm &lt;- tar_read(h06_q2_brms_sample)\n\nprint(m$formula)\n\nsurv | trials(density) ~ 1 + pred * size + (1 | tank) \n\nprior_summary(m)\n\n            prior     class               coef group resp dpar nlpar lb ub\n     normal(0, 1)         b                                               \n     normal(0, 1)         b           predpred                            \n     normal(0, 1)         b predpred:sizesmall                            \n     normal(0, 1)         b          sizesmall                            \n   normal(0, 1.5) Intercept                                               \n exponential(0.1)        sd                                           0   \n exponential(0.1)        sd                     tank                  0   \n exponential(0.1)        sd          Intercept  tank                  0   \n       source\n         user\n (vectorized)\n (vectorized)\n (vectorized)\n         user\n         user\n (vectorized)\n (vectorized)\n\nsummary(m)\n\n Family: binomial \n  Links: mu = logit \nFormula: surv | trials(density) ~ 1 + pred * size + (1 | tank) \n   Data: h06_q2_brms_data (Number of observations: 48) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~tank (Number of levels: 48) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.77      0.15     0.50     1.08 1.00     1571     2645\n\nPopulation-Level Effects: \n                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept              2.44      0.29     1.88     3.04 1.00     2469     2597\npredpred              -2.68      0.38    -3.39    -1.94 1.00     1781     2545\nsizesmall              0.19      0.39    -0.55     0.97 1.00     2203     2665\npredpred:sizesmall     0.49      0.49    -0.47     1.44 1.00     1802     2422\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nbrms eats the comparative levels, so we need to push them out (and make figures anyways!)\n\nm %&gt;% \n  add_epred_draws(newdata = r, \n                  re_formula = NA) %&gt;% \n  rowwise() %&gt;% \n  mutate(interaction = paste0(pred,\"+\", size)) %&gt;% \n  ggplot() + \n  stat_halfeye(aes(y = interaction, x = .epred/density,)) + \n  theme_classic() + \n  labs(y = \"\", x = \"Survival Rate\")\n\n\n\n\nWe see that size doesn’t matter in the absence of predators. Predators predictably decrease survival rate, but decrease survival rate for big tadpoles the most.\nIneractions are not in DAGs (always???)"
  },
  {
    "objectID": "homework/homework-06.html#q3-optional",
    "href": "homework/homework-06.html#q3-optional",
    "title": "Homework - Week 06",
    "section": "Q3 (optional)",
    "text": "Q3 (optional)\n\nReturn to the Trolley data, data(Trolley), from Chapter 12. Define and fit a varying intercepts model for these data. By this I mean to add an intercept parameter for the individual participants to the linear model. Cluster the varying intercepts on individual participants, as indicated by the unique values in the id variable. Include action, intention, and contact as treatment effects of interest. Compare the varying intercepts model and a model that ignores individuals. What is the impact of individual variation in these data?\n\n\ndata(Trolley)\n\n\ntrolley &lt;- Trolley %&gt;% \n  mutate(contact = as.factor(contact),\n         action = as.factor(action),\n         intention = as.factor(intention))\n\nmod_naive &lt;- tar_read(h06_q3b)\nmod_ind &lt;- tar_read(h06_q3)\n\nsummary(mod_naive)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: response ~ 1 + action + contact + intention \n   Data: trolley (Number of observations: 9930) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]    -2.83      0.05    -2.92    -2.74 1.00     2301     2772\nIntercept[2]    -2.15      0.04    -2.24    -2.07 1.00     2712     2963\nIntercept[3]    -1.57      0.04    -1.65    -1.49 1.00     3184     2922\nIntercept[4]    -0.55      0.04    -0.62    -0.48 1.00     3395     2882\nIntercept[5]     0.12      0.04     0.05     0.19 1.00     3652     3554\nIntercept[6]     1.03      0.04     0.95     1.10 1.00     4088     3257\naction1         -0.71      0.04    -0.78    -0.63 1.00     3485     3073\ncontact1        -0.96      0.05    -1.06    -0.86 1.00     3847     3177\nintention1      -0.72      0.04    -0.79    -0.65 1.00     3856     3039\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nsummary(mod_ind)\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: response ~ 1 + action + contact + intention + (1 | id) \n   Data: trolley (Number of observations: 9930) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~id (Number of levels: 331) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.89      0.08     1.74     2.06 1.01      704     1694\n\nPopulation-Level Effects: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]    -3.98      0.12    -4.21    -3.74 1.01      273      846\nIntercept[2]    -3.05      0.12    -3.29    -2.82 1.01      257      681\nIntercept[3]    -2.27      0.12    -2.50    -2.04 1.01      247      694\nIntercept[4]    -0.80      0.11    -1.02    -0.58 1.01      237      665\nIntercept[5]     0.24      0.11     0.01     0.46 1.01      239      592\nIntercept[6]     1.64      0.12     1.41     1.87 1.01      252      776\naction1         -0.96      0.04    -1.04    -0.88 1.00     6304     3276\ncontact1        -1.27      0.05    -1.37    -1.17 1.00     7010     3181\nintention1      -0.96      0.04    -1.03    -0.88 1.00     9235     2834\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nwaic(mod_naive)\n\n\nComputed from 4000 by 9930 log-likelihood matrix\n\n          Estimate   SE\nelpd_waic -18545.0 38.1\np_waic         9.0  0.0\nwaic       37089.9 76.2\n\nwaic(mod_ind)\n\n\nComputed from 4000 by 9930 log-likelihood matrix\n\n          Estimate    SE\nelpd_waic -15670.0  88.8\np_waic       355.1   4.6\nwaic       31340.0 177.6\n\n1 (0.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\npp_check(mod_naive)\n\n\n\npp_check(mod_ind)"
  },
  {
    "objectID": "homework/homework-01.html",
    "href": "homework/homework-01.html",
    "title": "Homework - Week 01",
    "section": "",
    "text": "Suppose the globe tossing data had turned out to be 3 water and 11 land. Construct the posterior distribution.\n\nDAG:\n\n\n\n\n\nPosterior:\n\n# create the sample manually\nN_W &lt;- 3\nN_L &lt;- 11\nsample &lt;- c(rep(\"W\", N_W), rep(\"L\", N_L))\n\n# use compute_posterior with the sample function to compute the posterior \ncompute_posterior &lt;- function(the_sample, poss = seq(0, 1, length.out = 1000)){\n  W &lt;- sum(the_sample==\"W\")\n  L &lt;- sum(the_sample==\"L\")\n  ways &lt;- sapply(poss, function(q) (q*4)^W * ((1-q)*4)^L)\n  post &lt;- ways/sum(ways)\n  #bars &lt;- sapply(post, function(q) make_bar(q))\n  data.frame(poss, ways, post = round(post, 3))\n}\n\npost &lt;- compute_posterior(sample)\n\nggplot(post) + \n  geom_smooth(aes(x = poss, y = post), se = F) + \n  labs(y = \"Posterior Probability\", x = \"p\") + \n  theme_classic()"
  },
  {
    "objectID": "homework/homework-01.html#q1",
    "href": "homework/homework-01.html#q1",
    "title": "Homework - Week 01",
    "section": "",
    "text": "Suppose the globe tossing data had turned out to be 3 water and 11 land. Construct the posterior distribution.\n\nDAG:\n\n\n\n\n\nPosterior:\n\n# create the sample manually\nN_W &lt;- 3\nN_L &lt;- 11\nsample &lt;- c(rep(\"W\", N_W), rep(\"L\", N_L))\n\n# use compute_posterior with the sample function to compute the posterior \ncompute_posterior &lt;- function(the_sample, poss = seq(0, 1, length.out = 1000)){\n  W &lt;- sum(the_sample==\"W\")\n  L &lt;- sum(the_sample==\"L\")\n  ways &lt;- sapply(poss, function(q) (q*4)^W * ((1-q)*4)^L)\n  post &lt;- ways/sum(ways)\n  #bars &lt;- sapply(post, function(q) make_bar(q))\n  data.frame(poss, ways, post = round(post, 3))\n}\n\npost &lt;- compute_posterior(sample)\n\nggplot(post) + \n  geom_smooth(aes(x = poss, y = post), se = F) + \n  labs(y = \"Posterior Probability\", x = \"p\") + \n  theme_classic()"
  },
  {
    "objectID": "homework/homework-01.html#q2",
    "href": "homework/homework-01.html#q2",
    "title": "Homework - Week 01",
    "section": "Q2",
    "text": "Q2\n\nUsing the posterior distribution from Q1, compute the posterior predictive distribution for the next 5 tosses of the same globe. I recommend you use the sampling method.\n\nSampling:\n\n# first sample your posterior \nn &lt;- 1e4\nsamples &lt;- sample(post$poss, prob = post$post, size = n, replace = T)\n\n# now simulate 5 tosses using the probability of each possible value \nN_toss &lt;- 5\nposterior_predict &lt;- data.frame(probpredict = rbinom(n, size = N_toss, prob = samples))\n\n# plot probability for each number of water samples you will get in 5 tosses\nggplot(posterior_predict) + \n  geom_bar(aes(x = probpredict)) + \n  labs(x = \"Number of W Tosses\") + \n  theme_classic()"
  },
  {
    "objectID": "homework/homework-01.html#q3-optional",
    "href": "homework/homework-01.html#q3-optional",
    "title": "Homework - Week 01",
    "section": "Q3 (optional):",
    "text": "Q3 (optional):\n\nSuppose you observe W = 7 water points, but you forgot to write down how many times the globe was tossed, so you don’t know the number of land points, L. Assume that p = 0.7 and compute the posterior distribution of the number of tosses N. Hint: Use the binomial distribution.\n\n\nN_tosses &lt;- seq(7, 20)\n\nprob_tosses &lt;- data.frame(N_tosses = N_tosses, prob = dbinom(x = 7, size = N_tosses, prob = 0.7))\n\nggplot(prob_tosses) + \n  geom_col(aes(x = N_tosses, y = prob)) + \n  labs(x = \"Number of Tosses to get W = 7 when p = 0.7\", y = \"Probability\") + \n  scale_x_continuous(n.breaks = 13) + \n  theme_classic()"
  },
  {
    "objectID": "homework/homework-05.html",
    "href": "homework/homework-05.html",
    "title": "Homework - Week 05",
    "section": "",
    "text": "The data in data(NWOGrants) are outcomes for scientific funding applications for the Netherlands Organization for Scientific Research (NWO) from 2010–2012 (see van der Lee and Ellemers doi:10.1073/pnas.1510159112). These data have a structure similar to the UCBAdmit data discussed in Chapter 11 and in lecture. There are applications and each has an associated gender (of the lead researcher). But instead of departments, there are disciplines. Draw a DAG for this sample. Then use the backdoor criterion and a binomial GLM to estimate the TOTAL causal effect of gender on grant awards.\n\n\n\n\n\n\nTotal causal effect of gender requires no adjustment sets, although we could add referee ID to the model to help it fit better, as it is additional information in the system that is not connected through backdoor paths. I will model as:\n$$ Awards_i | Applications_i Binomial(N_i, p_i) \\ logit(p_i) = \\ = [_f, _m] \\ Normal(0, 1.5) \\ Normal(0, 0.5)\n$$ question: why do we use binomial and he uses Bernoulli?\n\nmod1 &lt;- tar_read(h05_q1_brms_sample)\n\n# plot predicted draws for each group using modelled dataset\nepred &lt;- mod1 %&gt;% \n  predicted_draws(newdata = NWOGrants)\n\nggplot(epred, aes(x = .prediction, fill = gender)) +\n  stat_halfeye(alpha = 0.7) +\n  labs(x = \"Awards\", y = \"Density\", fill = \"Gender\") +\n  theme_classic() +\n  theme(legend.position = \"top\")\n\n\n\n# calculate contrast using emmeans \ntotal_gender_effect &lt;- mod1 %&gt;% \n  emmeans(~ gender,\n          # undo link transformation\n          regrid = 'response') %&gt;% \n  contrast(method = \"pairwise\") %&gt;% \n  gather_emmeans_draws()\n\nggplot(total_gender_effect, aes(x = .value)) +\n  stat_halfeye() +\n  labs(x = \"Total causal effect of gender (female - male)\", y = \"Density\") +\n  theme_classic() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "homework/homework-05.html#q1",
    "href": "homework/homework-05.html#q1",
    "title": "Homework - Week 05",
    "section": "",
    "text": "The data in data(NWOGrants) are outcomes for scientific funding applications for the Netherlands Organization for Scientific Research (NWO) from 2010–2012 (see van der Lee and Ellemers doi:10.1073/pnas.1510159112). These data have a structure similar to the UCBAdmit data discussed in Chapter 11 and in lecture. There are applications and each has an associated gender (of the lead researcher). But instead of departments, there are disciplines. Draw a DAG for this sample. Then use the backdoor criterion and a binomial GLM to estimate the TOTAL causal effect of gender on grant awards.\n\n\n\n\n\n\nTotal causal effect of gender requires no adjustment sets, although we could add referee ID to the model to help it fit better, as it is additional information in the system that is not connected through backdoor paths. I will model as:\n$$ Awards_i | Applications_i Binomial(N_i, p_i) \\ logit(p_i) = \\ = [_f, _m] \\ Normal(0, 1.5) \\ Normal(0, 0.5)\n$$ question: why do we use binomial and he uses Bernoulli?\n\nmod1 &lt;- tar_read(h05_q1_brms_sample)\n\n# plot predicted draws for each group using modelled dataset\nepred &lt;- mod1 %&gt;% \n  predicted_draws(newdata = NWOGrants)\n\nggplot(epred, aes(x = .prediction, fill = gender)) +\n  stat_halfeye(alpha = 0.7) +\n  labs(x = \"Awards\", y = \"Density\", fill = \"Gender\") +\n  theme_classic() +\n  theme(legend.position = \"top\")\n\n\n\n# calculate contrast using emmeans \ntotal_gender_effect &lt;- mod1 %&gt;% \n  emmeans(~ gender,\n          # undo link transformation\n          regrid = 'response') %&gt;% \n  contrast(method = \"pairwise\") %&gt;% \n  gather_emmeans_draws()\n\nggplot(total_gender_effect, aes(x = .value)) +\n  stat_halfeye() +\n  labs(x = \"Total causal effect of gender (female - male)\", y = \"Density\") +\n  theme_classic() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "homework/homework-05.html#q2",
    "href": "homework/homework-05.html#q2",
    "title": "Homework - Week 05",
    "section": "Q2",
    "text": "Q2\n\nNow estimate the DIRECT causal effect of gender on grant awards. Use the same DAG as above to justify one or more binomial models. Compute the average direct causal effect of gender, weighting each discipline in proportion to the number of applications in the sample. Refer to the marginal effect example in Lecture 9 for help.\n\nTo calculate the direct causal effect of gender on grant awards, add discipline to the model.\n$$ Awards_i | Applications_i Binomial(N_i, p_i) \\ logit(p_i) = \\ Normal(0, 1.5) \\ Normal(0, 0.5)\n$$\n\nmod2 &lt;- tar_read(h05_q2_brms_sample)\n\n# calculate contrast using emmeans \ndirect_gender_effect &lt;- mod2 %&gt;% \n  emmeans(~ gender|discipline,\n          # undo link transformation\n          regrid = 'response') %&gt;% \n  contrast(method = \"pairwise\") %&gt;% \n  gather_emmeans_draws()\n\nggplot(direct_gender_effect, aes(x = .value, fill = discipline)) +\n  stat_halfeye(alpha = 0.5) +\n  labs(x = \"Direct causal effect of gender (female - male)\", y = \"Density\", fill = \"\") +\n  theme_classic() +\n  theme(legend.position = \"top\")\n\n\n\n\nWeight the sample based on number of applications (post-stratification):\n\npost &lt;- NWOGrants %&gt;%\n  group_by(discipline) %&gt;% \n  summarize(n_app = sum(applications)) %&gt;% \n  ungroup() %&gt;% \n  mutate(prop_app = n_app / sum(n_app)) %&gt;% \n  right_join(., direct_gender_effect, by = \"discipline\") %&gt;% \n  group_by(discipline, .draw) %&gt;% \n  summarize(post_predict = sum(.value * prop_app)) %&gt;% \n  mean_qi(post_predict)\n\nggplot(data = post, aes(x = post_predict, xmin = .lower, xmax = .upper, y = discipline)) + \n  geom_pointrange(color = \"orange2\", linewidth = 0.8, fatten = 2)"
  },
  {
    "objectID": "homework/homework-05.html#q3-optional",
    "href": "homework/homework-05.html#q3-optional",
    "title": "Homework - Week 05",
    "section": "Q3 (optional)",
    "text": "Q3 (optional)\n\nThe data in data(UFClefties) are the outcomes of 205 Ultimate Fighting Championship (UFC) matches (see ?UFClefties for details). It is widely believed that left-handed fighters (aka “Southpaws”) have an advantage against right-handed fighters, and left-handed men are indeed over-represented among fighters (and fencers and tennis players) compared to the general population. Estimate the average advantage, if any, that a left-handed fighter has against right-handed fighters. Based upon your estimate, why do you think left-handers are over-represented among UFC fighters?"
  },
  {
    "objectID": "notes/notes-04.html",
    "href": "notes/notes-04.html",
    "title": "Lecture 04 - Categories & Curves",
    "section": "",
    "text": "Rose: “Unobserved causes are ignorable unless they are shared”\nThorn:"
  },
  {
    "objectID": "notes/notes-04.html#rose-thorn",
    "href": "notes/notes-04.html#rose-thorn",
    "title": "Lecture 04 - Categories & Curves",
    "section": "",
    "text": "Rose: “Unobserved causes are ignorable unless they are shared”\nThorn:"
  },
  {
    "objectID": "notes/notes-04.html#drawing-inferences",
    "href": "notes/notes-04.html#drawing-inferences",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Drawing Inferences",
    "text": "Drawing Inferences\n\nlinear model can accomodate anything, thus we need to think carefully about our scientific model\ngenerative model + multiple estimands = multiple estimators\nquite often the estimate we want is not in a summary table because it depends on multiple unknowns in the posterior distribution or making assumptions about the population, so we often need to do post-processing"
  },
  {
    "objectID": "notes/notes-04.html#categories",
    "href": "notes/notes-04.html#categories",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Categories",
    "text": "Categories\n\ncategories are discrete and non-linear\ndiscrete, unordered types\nwe want to stratify by category, to fit a separate line for each"
  },
  {
    "objectID": "notes/notes-04.html#howell-data",
    "href": "notes/notes-04.html#howell-data",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Howell Data",
    "text": "Howell Data\n\n\nLoading required package: cmdstanr\n\n\nThis is cmdstanr version 0.7.1\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/icrichmond/.cmdstan/cmdstan-2.34.1\n\n\n- CmdStan version: 2.34.1\n\n\nLoading required package: posterior\n\n\nThis is posterior version 1.4.1\n\n\n\nAttaching package: 'posterior'\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nLoading required package: parallel\n\n\nrethinking (Version 2.40)\n\n\n\nAttaching package: 'rethinking'\n\n\nThe following object is masked from 'package:stats':\n\n    rstudent\n\n\n\nhow are height, weight, and sex causally related?\nhow are height, weight, and sex statistically related?\n\n\nd &lt;- dagitty(\"dag {\n                H -&gt; W\n                S -&gt; W\n                S -&gt; H\n             }\")\n\ndrawdag(d)\n\n\n\n\n\nheight influences weight\nsex influences weight and height\nweight is influenced by height and sex\ninfluence of sex is both direct and indirect on weight\n\\(H = f_{H}(S)\\)\n\\(W = f_{W}(H,S)\\)\nUnobserved causes are ignorable unless they are shared between variables (common cause) = confound\n\n\nsim_HW &lt;- function(S, b, a){\n  N &lt;- length(S)\n  H &lt;- ifelse(S==1, 150, 160) + rnorm(N, 0, 5)\n  W &lt;- a[S] + b[S]*H + rnorm(N, 0, 5)\n  data.frame(S, H, W)\n}\n\n# S = 1 female : S = 2 male\nS &lt;- rbern(100)+1\ndat &lt;- sim_HW(S, b=c(0.5, 0.6), a=c(0,0))\nhead(dat)\n\n  S        H         W\n1 2 150.5049  86.82130\n2 2 159.7818 102.02878\n3 2 153.1642  92.57466\n4 2 160.9448  87.15679\n5 2 151.7519  93.45122\n6 2 163.3954  89.48941\n\n\n\nscientific questions:\n\ncausal effect of H on W?\ncausal effect of S on W?\ndirect causal effect of S on W?\n\nwe need to stratify by S to answer qs 2 and 3\ncoding categorical variables\n\nindicator variables (0/1)\nindex variables (1,2,3,4)\nindex variables are generally preferable"
  },
  {
    "objectID": "notes/notes-04.html#index-variables",
    "href": "notes/notes-04.html#index-variables",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Index Variables",
    "text": "Index Variables\n\noften we want to give each index the same prior\nInfluence of colour coded by: \\(\\alpha = [\\alpha_1 , \\alpha_2, \\alpha_3, \\alpha_4 ]\\)\n\\(y_i \\sim Normal(\\mu_i, \\sigma)\\)\n\\(\\mu_i = \\alpha_{S[i]}\\)\nPriors\n\n\\(\\alpha_j \\sim Normal(60, 10)\\)\n\\(\\sigma \\sim Uniform(0, 10)\\)\nIf you use indicator variables, one becomes the default and the other is the adjustment so you must set separate priors for both"
  },
  {
    "objectID": "notes/notes-04.html#total-causal-effect-of-sex-on-weight",
    "href": "notes/notes-04.html#total-causal-effect-of-sex-on-weight",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Total Causal Effect of Sex on Weight",
    "text": "Total Causal Effect of Sex on Weight\n\nS &lt;- rep(1, 100)\nsimF &lt;- sim_HW(S, b=c(0.5, 0.6), a=c(0,0))\n\nS &lt;- rep(2, 100)\nsimM &lt;- sim_HW(S, b=c(0.5, 0.6), a=c(0,0))\n\n# effect of sex (male-female)\nmean(simM$W - simF$W)\n\n[1] 21.27486\n\n\n\nestimating model and synthetic example\n\n\nS &lt;- rbern(100)+1\ndat &lt;- sim_HW(S, b = c(0.5,0.6), a = c(0,0))\n\nm_SW &lt;- quap(alist(\n  W ~ dnorm(mu, sigma),\n  mu &lt;- a[S],\n  a[S] ~ dnorm(60, 10),\n  sigma ~ dunif(0, 10)\n), data = dat)\n\nprecis(m_SW, depth = 2)\n\n           mean        sd      5.5%     94.5%\na[1]  75.000697 0.7769980 73.758905 76.242490\na[2]  95.008489 0.7323275 93.838088 96.178889\nsigma  5.342249 0.3780561  4.738042  5.946456\n\n\n\nanalyze the real sample\n\n\nd &lt;- Howell1\nd &lt;- d[ d$age &gt;= 18,]\n\ndat &lt;- list(\n  W = d$weight,\n  S = d$male + 1\n)\n\nm_SW &lt;- quap(alist(\n  W ~ dnorm(mu, sigma), \n  mu &lt;- a[S],\n  a[S] ~ dnorm(60, 10),\n  sigma ~ dunif(0, 10)\n), data = dat)\n\n\nposterior means and predictions\na1 and a2 are often not what we are after\n\ndifference in mean weight is not in the posterior - must calculate a contrast\nbut the mean weight of each category does exist in the posterior\n\nfirst plot is just mean weight for each sex\ndistributions of weights is the posterior predicted, second figure\ncontrast is usually what we are after, third figure\n\n\n# posterior mean W\npost &lt;- extract.samples(m_SW)\ndensity_f &lt;- density(post$a[, 1])\ndensity_m &lt;- density(post$a[, 2])\nplot(density_f, col=2, xlim = c(min(density_f$x,density_m$x), max(density_f$x,density_m$x)), main = \"Posterior Mean Weight (kg)\") + \nlines(density_m, col=4)\n\n\n\n\ninteger(0)\n\n# posterior W predictions\nW1 &lt;- rnorm(1000, post$a[,1], post$sigma)\nW2 &lt;- rnorm(1000, post$a[,2], post$sigma)\npredict_f &lt;- density(W1)\npredict_m &lt;- density(W2)\nplot(predict_f, col=2, xlim = c(min(predict_f$x,predict_m$x), max(predict_f$x,predict_m$x)), main = \"Posterior Predicted Weight (kg)\") + \nlines(predict_m, col=4)\n\n\n\n\ninteger(0)\n\n\n\ncontrasting\n\nneed to compute the difference between the categories\nit is not legitimate to compare overlap in distributions\nwe must compute contrast distribution\noverlap in distributions does not indicate that they are the same (or different)\n\naverage difference between men and women in this sample:\n\n\nmu_contrast &lt;- post$a[,2] - post$a[,1]\ndens(mu_contrast)\n\n\n\n\n\nweight contrasting:\n\n\n# contrast\nW_contrast &lt;- W2 - W1\ndens(W_contrast)\n\n\n\n# proportion above zero\nsum(W_contrast &gt; 0)/1000\n\n[1] 0.813\n\nsum(W_contrast &lt; 0)/1000\n\n[1] 0.187"
  },
  {
    "objectID": "notes/notes-04.html#direct-causal-effect-of-sex-on-weight",
    "href": "notes/notes-04.html#direct-causal-effect-of-sex-on-weight",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Direct Causal Effect of Sex on Weight",
    "text": "Direct Causal Effect of Sex on Weight\n\n“controlling” for the indirect effect of sex through height\nwant to “block” association through H\n\n\nS &lt;- rbern(100)+1\n# slopes are the same so there is no effect of height on weight through slope but men are on average 10 kg heavier (intercept 10)\nset.seed(12)\ndat &lt;- sim_HW(S, b = c(0.5, 0.5), a = c(0, 10))\n\n\n\\(W_{i} \\sim Normal(\\mu _{i}, \\sigma)\\)\n\\(\\mu _{i} = \\alpha _{S[i]} + \\beta _{S[i]}(H_{i} - \\bar H)\\)\n\nThis equation centers the height \\((H_{i} - \\bar H)\\)\nCentering H means that alpha represents the average weight of a person with average height\nCentering also makes priors easier for alpha\n\\(\\alpha = [\\alpha _{1}, \\alpha _{2}]\\) , \\(\\beta = [\\beta _{1}, \\beta _{2}]\\)\n\nanalyze the sample\n\n\nd &lt;- Howell1\nd &lt;- d[d$age &gt;= 18, ]\ndat &lt;- list(W = d$weight, H = d$height, Hbar = mean(d$height), S = d$male + 1)\n\nm_SHW &lt;- quap(alist(\n  W ~ dnorm(mu, sigma),\n  mu &lt;- a[S] + b[S]*(H-Hbar),\n  a[S] ~ dnorm(60, 10),\n  b[S] ~ dunif(0, 1),\n  sigma ~ dunif(0, 10)\n), data = dat)\n\n\nwe need to compute the difference of expected weight at each height to get the actual estimate that we are looking for (for the direct effect of sex on weight)\ncompute posterior predictive for each group, calculate contrast, plot\n\n\nxseq &lt;- seq(from=130, to=190, len=50)\n\nmuF &lt;- link(m_SHW, data = list(S=rep(1,50), H=xseq, Hbar=mean(d$height)))\n\nmuM &lt;- link(m_SHW, data = list(S=rep(2,50), H=xseq, Hbar = mean(d$height)))\n\nmu_contrast &lt;- muF - muM\n\nplot(NULL, xlim=range(xseq), ylim = range(-6, 8), xlab = \"height (cm)\", ylab = \"weight contrast (F-M)\") +\nlines(xseq, apply(muF, 2, mean)) + \nlines(xseq, apply(muM, 2, mean)) \n\n\n\n\ninteger(0)\n\n#for (p in c(0.5, 0.6, 0.7, 0.8, 0.9, 0.99)) {\n#  shade(apply(mu_contrast, 2, PI, prob = p), xseq)\n#  abline(h=0)\n#  }\n\n\nwomen tend to be heavier at high heights and vice versa for men\nbut most of the effect is centered around zero, therefore:\nnearly all of the causal effects of S acts through H\n\nwhen we block H, we see very little effect of sex on weight"
  },
  {
    "objectID": "notes/notes-04.html#categorical-variables",
    "href": "notes/notes-04.html#categorical-variables",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Categorical Variables",
    "text": "Categorical Variables\n\ncommon, easy to use with index coding\nuse samples to compute relevant contrasts\nalways summarize (mean, interval) as the last step\nwe want mean difference and not difference of means"
  },
  {
    "objectID": "notes/notes-04.html#curves-from-lines",
    "href": "notes/notes-04.html#curves-from-lines",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Curves from Lines",
    "text": "Curves from Lines\n\nmany non linear relationships, which can be fit my linear models easily (but not mechanistic, like a geocentric model)\nlinear models can easily fit curves: 2 strategies\n\npolynomials (bad)\nsplines and GAMs (less bad + useful)"
  },
  {
    "objectID": "notes/notes-04.html#polynomial-models",
    "href": "notes/notes-04.html#polynomial-models",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Polynomial Models",
    "text": "Polynomial Models\n\nstill linear because its an additive function of the parameters\ncreate strange symmetries and explosive uncertainty\nno local smoothing, only global smoothing\nany data point at any part of the x-axis can significantly change the curve even at arbitrarily far distances\ncan’t predict anything outside of the data with any certainty\ndo not use"
  },
  {
    "objectID": "notes/notes-04.html#splines-gams",
    "href": "notes/notes-04.html#splines-gams",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Splines + GAMs",
    "text": "Splines + GAMs\n\ngreat for locally inferred function\nadd together a bunch of locally trained terms\ncan add as many locally trained terms as you want\neach term has a weight and slope and only affects its own region"
  },
  {
    "objectID": "notes/notes-04.html#full-luxury-bayes",
    "href": "notes/notes-04.html#full-luxury-bayes",
    "title": "Lecture 04 - Categories & Curves",
    "section": "Full Luxury Bayes",
    "text": "Full Luxury Bayes\n\ninstead of two models for two estimands, use one model for full causal model\ncan simulate interventions with this approach\nrequires more simulations\n\n\nm_SHW_full &lt;- quap(alist(\n  \n  # weight\n  W ~ dnorm(mu, sigma),\n  mu &lt;- a[S] + b[S]*(H-Hbar),\n  a[S] ~ dnorm(60, 10),\n  b[S] ~ dunif(0, 1),\n  sigma ~ dunif(0, 10),\n  \n  # height\n  H ~ dnorm(nu, tau),\n  nu &lt;- h[S],\n  h[S] ~ dnorm(160, 10),\n  tau ~ dunif(0, 10)\n  \n), data = dat)\n\n\npost &lt;- extract.samples(m_SHW_full)\nHbar &lt;- dat$Hbar\nn &lt;- 1e4\n\n#with(post, {\n#  \n#  H_S1 &lt;- rnorm(n, h[,1], tau)\n#  W_S1 &lt;- rnorm(n, a[,2] + b[,1]*(H_S2-Hbar), sigma)\n#  \n#  W_do_S &lt;&lt;- W_S2 - W_S1\n#  \n#})\n#\n## automate\n#HWsim &lt;- sim(m_SHW_full, data = list(S=c(1,2)), vars = c(\"H\", \"W\"))\n#W_do_S_auto &lt;- HWsim$W[,2] - HWsim$W[,1]\n\n\nyou can either do one statistical model for each estimand OR one simulation for each estimand (full luxury Bayes)"
  },
  {
    "objectID": "notes/notes-04.html#todo",
    "href": "notes/notes-04.html#todo",
    "title": "Lecture 04 - Categories & Curves",
    "section": "TODO:",
    "text": "TODO:"
  },
  {
    "objectID": "notes/notes-02.html",
    "href": "notes/notes-02.html",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "",
    "text": "Rose: understanding the predictive posterior this time\nThorn: what if you don’t know your misclassification rate"
  },
  {
    "objectID": "notes/notes-02.html#rose-thorn",
    "href": "notes/notes-02.html#rose-thorn",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "",
    "text": "Rose: understanding the predictive posterior this time\nThorn: what if you don’t know your misclassification rate"
  },
  {
    "objectID": "notes/notes-02.html#globe-example",
    "href": "notes/notes-02.html#globe-example",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Globe Example",
    "text": "Globe Example\nestimand: proportion of the globe covered in water - do people know what an estimand is?\n\na research/scientific question\n\nestimator: statistical way of producing an estimate\n\ngenerative model tests your estimator"
  },
  {
    "objectID": "notes/notes-02.html#generative-model-globe",
    "href": "notes/notes-02.html#generative-model-globe",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Generative Model (globe)",
    "text": "Generative Model (globe)\n\np = proportion of water\nW = water observations\nN = number of tosses\nL = land observations\nN influences W and L because higher tosses means higher numbers\nstart with how the variables influence each other, i.e., causal model\n\nstart conceptually, with science\nintervention on N is also an intervention on W and L\n\n\n\nlibrary(dagitty)\nlibrary(rethinking)\n\nLoading required package: cmdstanr\n\n\nThis is cmdstanr version 0.7.1\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/icrichmond/.cmdstan/cmdstan-2.34.1\n\n\n- CmdStan version: 2.34.1\n\n\nLoading required package: posterior\n\n\nThis is posterior version 1.4.1\n\n\n\nAttaching package: 'posterior'\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nThe following objects are masked from 'package:base':\n\n    %in%, match\n\n\nLoading required package: parallel\n\n\nrethinking (Version 2.40)\n\n\n\nAttaching package: 'rethinking'\n\n\nThe following object is masked from 'package:stats':\n\n    rstudent\n\nd &lt;- dagitty(\"dag {\n                p -&gt; W\n                p -&gt; L\n                N -&gt; W \n                N -&gt; L }\")\n\ndrawdag(d)\n\n\n\n\n\\[\nW,L = f(p,N)\n\\]\n\nW and L are functions of p and N\nDAGs are not generative, but they make causal models which allow us to make generative models\n\nthey represent functional relationships"
  },
  {
    "objectID": "notes/notes-02.html#bayesian-data-analysis",
    "href": "notes/notes-02.html#bayesian-data-analysis",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Bayesian Data Analysis",
    "text": "Bayesian Data Analysis\nFor each possible explanation of the sample,\n\ncount all the ways the sample could happen (given a particular explanation)\nexplanations with more ways to produce the sample are more plausible"
  },
  {
    "objectID": "notes/notes-02.html#garden-of-forking-data",
    "href": "notes/notes-02.html#garden-of-forking-data",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Garden of Forking Data",
    "text": "Garden of Forking Data\n\nrelies on samples being independent\nrelative differences between probabilities are dependent on sample size (differences will be smaller with smaller sample sizes because there is less evidence)\nnormalizing to probability allows for interpretability and easier math\ncollection of probabilities is a posterior distribution\n\n\nsample &lt;- c(\"W\", \"L\", \"W\", \"W\", \"W\", \"L\", \"W\", \"L\", \"W\")\n\nW &lt;- sum(sample==\"W\")\nL &lt;- sum(sample==\"L\")\np &lt;- c(0, 0.25, 0.5, 0.75, 1)\nways &lt;- sapply(p, function(q) (q*4)^W * ((1-q)*4)^L)\nprob &lt;- ways/sum(ways)\ncbind(p, ways, prob)\n\n        p ways       prob\n[1,] 0.00    0 0.00000000\n[2,] 0.25   27 0.02129338\n[3,] 0.50  512 0.40378549\n[4,] 0.75  729 0.57492114\n[5,] 1.00    0 0.00000000\n\nsim_globe &lt;- function(p = 0.7, N = 9){\n  sample(c(\"W\", \"L\"), size = N, prob = c(p, 1-p), replace = T)\n}\n\nsim_globe()\n\n[1] \"L\" \"L\" \"W\" \"W\" \"W\" \"W\" \"L\" \"L\" \"W\""
  },
  {
    "objectID": "notes/notes-02.html#testing",
    "href": "notes/notes-02.html#testing",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Testing",
    "text": "Testing\n\nhave to test\ntest using extreme values where you intuitively know the right answer\nexplore different sampling design\n\n\nsim_globe &lt;- function(p = 0.7, N = 9){\n  \n  sample(c(\"W\", \"L\"), size = N, prob=c(p, 1-p), replace = T)\n}\n\nsim_globe()\n\n[1] \"L\" \"W\" \"L\" \"W\" \"W\" \"L\" \"L\" \"W\" \"W\"\n\nsim_globe(p=1, N=11) \n\n [1] \"W\" \"W\" \"W\" \"W\" \"W\" \"W\" \"W\" \"W\" \"W\" \"W\" \"W\"\n\nsum(sim_globe(p=0.5, N=1e4) == \"W\")/1e4\n\n[1] 0.4936\n\n\nFunction:\n\nlibrary(crayon)\n\nmake_bar &lt;- function(q,size=20) {\n    n &lt;- round(q*size)\n    s1 &lt;- concat( rep(\"#\",n) )\n    s2 &lt;- concat( rep(\" \",size-n) )\n    concat(s1,s2)\n}\n\ncompute_posterior &lt;- function(the_sample, poss = c(0,0.25,0.5,0.75,1)){\n  W &lt;- sum(the_sample==\"W\")\n  L &lt;- sum(the_sample==\"L\")\n  ways &lt;- sapply(poss, function(q) (q*4)^W * ((1-q)*4)^L)\n  post &lt;- ways/sum(ways)\n  bars &lt;- sapply(post, function(q) make_bar(q))\n  data.frame(poss, ways, post = round(post,3), bars)\n}\n\ncompute_posterior(sim_globe())\n\n  poss ways  post                 bars\n1 0.00    0 0.000                     \n2 0.25    9 0.003                     \n3 0.50  512 0.189 ####                \n4 0.75 2187 0.808 ################    \n5 1.00    0 0.000"
  },
  {
    "objectID": "notes/notes-02.html#real-number-sampling",
    "href": "notes/notes-02.html#real-number-sampling",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Real Number Sampling",
    "text": "Real Number Sampling\n\nmore possibilities = less probability in each option/outcome\n\nprobability is spread out across many options\n\nnormalizing to probability allows our equation to calculate infinite number of “sides”/outcomes\n\n\\[\np^W(1-p)^L\n\\]\np = probability\ndensity = probability when we are assessing infinite number of possibilities\n\nshape of the posterior embodies sample size\n\nno min sample size -&gt; just more uncertain posterior\nposterior distribution embodies sample size\n\nno point estimates! estimate is entire posterior distribution\n\ncan use summary points from post dist for communication purposes\n\nintervals are merely indicators of the shape of the posterior distribution\n\nno “true interval” i.e., 95% CI doesn’t exist\ninterval is just distribution lower/upper bounds"
  },
  {
    "objectID": "notes/notes-02.html#analyze-sample-summarize",
    "href": "notes/notes-02.html#analyze-sample-summarize",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Analyze Sample + Summarize",
    "text": "Analyze Sample + Summarize\n\npost_samples &lt;- rbeta(1e3, 6+1, 3+1)\n\ndens(post_samples, lwd = 4, col = 2, xlab = \"prop water\", adj = 0.1)\n\ncurve(dbeta(x, 6+1, 3+1), add = T, lty = 2, lwd = 3)\n\n\n\n\n\nposterior prediction = “what would we bet?”\n\nhow many W’s do we expect to see in the next 10 tosses\n\nfor each sample of post dist, we can create a predictive distribution, then posterior predictive\n\nincorporates uncertainty from posterior distribution\n\n\n\npost_samples &lt;- rbeta(1e4, 6+1, 3+1)\n\npred_post &lt;- sapply(post_samples, function(p) \nsum(sim_globe(p, 10)==\"W\"))\n\ntab_post &lt;- table(pred_post)\n\n#for (i in 0:10) lines(c(i,i),c(0,tab_post[i+1]), lwd = 4, col = 4)"
  },
  {
    "objectID": "notes/notes-02.html#misclassification-bonus-round",
    "href": "notes/notes-02.html#misclassification-bonus-round",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "Misclassification (Bonus Round)",
    "text": "Misclassification (Bonus Round)\n\nW* is misclassified due to sampling error and measurement process\n\ntrue W is unknown\n\n\n\nlibrary(dagitty)\nlibrary(rethinking)\n\nd &lt;- dagitty(\"dag {\n                p -&gt; W\n                N -&gt; W\n                W -&gt; Wm\n                M -&gt; Wm\n             }\")\n\ndrawdag(d)\n\n\n\n\n\nincorporate measurement error with x (error rate of 10%)\n\n\nsim_globe2 &lt;- function(p = 0.7, N = 9, x = 0.1){\n  \n  true_sample &lt;- sample(c(\"W\", \"L\"), size = N, prob = c(p, 1-p), replace = T)\n  \n  obs_sample &lt;- ifelse(runif(N) &lt; x,\n                       ifelse(true_sample == \"W\", \"L\", \"W\"),\n                       true_sample)\n  \n  return(obs_sample)\n  \n}\n\n\nhow do you know the error rate?\ndon’t understand mechanism behind incorporating x but understand why x needs to be incorporated + consequences of not"
  },
  {
    "objectID": "notes/notes-02.html#todo",
    "href": "notes/notes-02.html#todo",
    "title": "Lecture 02 - The Garden of Forking Data",
    "section": "TODO",
    "text": "TODO"
  },
  {
    "objectID": "notes/notes-10.html",
    "href": "notes/notes-10.html",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "",
    "text": "Rose: qualitative data!!\nThorn:"
  },
  {
    "objectID": "notes/notes-10.html#rose-thorn",
    "href": "notes/notes-10.html#rose-thorn",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "",
    "text": "Rose: qualitative data!!\nThorn:"
  },
  {
    "objectID": "notes/notes-10.html#generalized-linear-models",
    "href": "notes/notes-10.html#generalized-linear-models",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Generalized Linear Models",
    "text": "Generalized Linear Models\n\nExpected value is some function (link function) of an additive combination of parameters\ninterpretation that changes, not computation - no longer simply an additive combination of parameters\n\nuniform changes in predictor not uniform changes in prediction\n\nall predictor variables interact and moderate one another\ninlfuences predictions and uncertainty of predictions"
  },
  {
    "objectID": "notes/notes-10.html#confounded-admissions",
    "href": "notes/notes-10.html#confounded-admissions",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Confounded Admissions",
    "text": "Confounded Admissions\n\nability is the most easy to imagine confound for admissions\n\n\n\n\n\ninclude confound in the model (u):\n\nBernoulli variable 0, 1 - 1 is extremely high achieving individuals that are 10% of the population, everyone else is average\n\ngender 1 individuals anticipate gender discrimination in department 2, so if they are average they will avoid it but if they are exceptional they will still apply\n\n\n# continuing from UCBadmit example\n# what happens when there is a confound?\n\nset.seed(17)\nN &lt;- 2000 # number of applicants\n# even gender distribution\nG &lt;- sample( 1:2 , size=N , replace=TRUE )\n# sample ability, high (1) to average (0)\n# unobserved common cause \nu &lt;- rbern(N,0.1)\n# gender 1 tends to apply to department 1, 2 to 2\n# and G=1 with greater ability tend to apply to 2 as well\nD &lt;- rbern( N , ifelse( G==1 , u*0.5 , 0.8 ) ) + 1\n# matrix of acceptance rates [dept,gender]\naccept_rate_u0 &lt;- matrix( c(0.1,0.1,0.1,0.3) , nrow=2 )\naccept_rate_u1 &lt;- matrix( c(0.2,0.3,0.2,0.5) , nrow=2 )\n# simulate acceptance\np &lt;- sapply( 1:N , function(i) \n    ifelse( u[i]==0 , accept_rate_u0[D[i],G[i]] , accept_rate_u1[D[i],G[i]] ) )\nA &lt;- rbern( N , p )\n\ntable(G,D)\ntable(G,A)\n\ndat_sim &lt;- list( A=A , D=D , G=G )\n\n# total effect gender\nm1 &lt;- ulam(\n    alist(\n        A ~ bernoulli(p),\n        logit(p) &lt;- a[G],\n        a[G] ~ normal(0,1)\n    ), data=dat_sim , chains=4 , cores=4 )\n\npost1 &lt;- extract.samples(m1)\npost1$fm_contrast &lt;- post1$a[,1] - post1$a[,2]\nprecis(post1)\n\n# direct effects - now confounded!\nm2 &lt;- ulam(\n    alist(\n        A ~ bernoulli(p),\n        logit(p) &lt;- a[G,D],\n        matrix[G,D]:a ~ normal(0,1)\n    ), data=dat_sim , chains=4 , cores=4 )\n\nprecis(m2,3)\n\n\nsecond model stratifies through department is now confounded because we’ve added a common cause, ability\n\n\n# contrast\npost2 &lt;- extract.samples(m2)\npost2$fm_contrast_D1 &lt;- post2$a[,1,1] - post2$a[,2,1]\npost2$fm_contrast_D2 &lt;- post2$a[,1,2] - post2$a[,2,2]\nprecis(post2)\n\ndens( post2$fm_contrast_D1 , lwd=4 , col=4 , xlab=\"F-M contrast in each department\" )\ndens( post2$fm_contrast_D2 , lwd=4 , col=2 , add=TRUE )\nabline(v=0,lty=3)\n\ndens( post2$a[,1,1] , lwd=4 , col=2 , xlim=c(-3,1) )\ndens( post2$a[,2,1] , lwd=4 , col=4 , add=TRUE )\ndens( post2$fm_contrast_D1 , lwd=4 , add=TRUE )\n\ndens( post2$a[,1,2] , lwd=4 , col=2 , add=TRUE , lty=4 )\ndens( post2$a[,2,2] , lwd=4 , col=4 , add=TRUE , lty=4)\ndens( post2$fm_contrast_D2 , lwd=4 , add=TRUE , lty=4)\n\n\nprobability distribution of probabilities because we’re modelling probability\nconfound happens because exceptional individuals don’t apply to department 1, they apply to department 2 and so it looks like department 1 is discriminating when its not because its getting lower quality applicants\n\ndepartment 2 appears to have no discrimination but it does have it, for the opposite reason. they are only admitting higher ability applicants of a certain gender\n\nmasking effect - sorting can mask a lot of things"
  },
  {
    "objectID": "notes/notes-10.html#collider-bias",
    "href": "notes/notes-10.html#collider-bias",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Collider Bias",
    "text": "Collider Bias\n\nWe can estimate total causal effect of G but it isn’t what we want (not useful for policy)\nWe cannot estimate direct effect of department or gender"
  },
  {
    "objectID": "notes/notes-10.html#citation-vs-membership",
    "href": "notes/notes-10.html#citation-vs-membership",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Citation vs Membership",
    "text": "Citation vs Membership\n\n\n\n\n\n\n\n\n\npaper one concludes that gender results in lower citation rates for women\npaper two concludes that women get elected more controlling for citations"
  },
  {
    "objectID": "notes/notes-10.html#citation-networks",
    "href": "notes/notes-10.html#citation-networks",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Citation Networks",
    "text": "Citation Networks\n\nvery plausible that there is quality differences among members of the academy but they are often hidden\ncitations is a post-treatment variable (and stratifying by post-treatment variable is dangerous because it can activate collider bias)\n\nif women are less likely to get citations because of discrimination, it is probably that women elected to the NAS with less citations have a higher quality\n\n\n\n\n\n\n\n\nin the absence of strong causal assumptions, we can’t conclude anything\nproxies for quality are often poor proxies (e.g., citations)\nif you want causal inference, you must make causal assumptions"
  },
  {
    "objectID": "notes/notes-10.html#sensitivity-analysis",
    "href": "notes/notes-10.html#sensitivity-analysis",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Sensitivity Analysis",
    "text": "Sensitivity Analysis\n\nwhat are the implications of what we don’t know?\nassume confound exists, model its consequences for different strengths/kinds of influence\nhow strong must the confound be to change conclusions?\ninclude quality as an unobserved variable\n\nchange parameter size/strength to test the effect of unobserved confound\n\n\\[\nA_i \\sim Bernoulli(p_i)\n\\\\\nlogit(p_i) = \\alpha[G_i, D_i] +\\beta_{G[i]}u_i\n\\]\n\nfirst model models total effect of gender on admissions with an unknown confound (quality)\n\n\\[\n(D_i = 2) \\sim Bernoulli(q_i)\n\\\\\nlogit(q_i) = \\delta[G_i] + \\gamma_{G[i]}u_i\n\\]\n\nsecond model investigates the effect of how people apply to departments\n\n\\(u_j \\sim Normal(0, 1)\\)\n\\(u_i\\) = ability\n\n\n# sensitivity\n\ndat_sim$D2 &lt;- ifelse( D==2 , 1 , 0 )\ndat_sim$b &lt;- c(1,1)\ndat_sim$g &lt;- c(1,0)\ndat_sim$N &lt;- length(dat_sim$D2)\n\nm3s &lt;- ulam(\n    alist( \n        # A model\n        A ~ bernoulli(p),\n        logit(p) &lt;- a[G,D] + b[G]*u[i],\n        matrix[G,D]:a ~ normal(0,1),\n\n        # D model\n        D2 ~ bernoulli(q),\n        logit(q) &lt;- delta[G] + g[G]*u[i],\n        delta[G] ~ normal(0,1),\n\n        # declare unobserved u\n        vector[N]:u ~ normal(0,1)\n    ), data=dat_sim , chains=4 , cores=4 )\n\nprecis(m3s,3,pars=c(\"a\",\"delta\"))\n\npost3s &lt;- extract.samples(m3s)\npost3s$fm_contrast_D1 &lt;- post3s$a[,1,1] - post3s$a[,2,1]\npost3s$fm_contrast_D2 &lt;- post3s$a[,1,2] - post3s$a[,2,2]\n\ndens( post2$fm_contrast_D1 , lwd=1 , col=4 , xlab=\"F-M contrast in each department\" , xlim=c(-2,1) )\ndens( post2$fm_contrast_D2 , lwd=1 , col=2 , add=TRUE )\nabline(v=0,lty=3)\ndens( post3s$fm_contrast_D1 , lwd=4 , col=4 , add=TRUE )\ndens( post3s$fm_contrast_D2 , lwd=4 , col=2 , add=TRUE )\n\nplot( jitter(u) , apply(post3s$u,2,mean) , col=ifelse(G==1,2,4) , lwd=3 )\n\n\nyou can say the strength of the confound needed to undo the results you found\n\nimportant thing to report - don’t pretend confounds don’t exist\ncan’t eliminate possibility of confounding\n\na lot of the most important science cannot be done experimentally so we need to be able to do these things"
  },
  {
    "objectID": "notes/notes-10.html#poisson-counts",
    "href": "notes/notes-10.html#poisson-counts",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Poisson Counts",
    "text": "Poisson Counts\n\n\n\n\n\n\ntotal count is not binomial: no maximum\n\nPoisson distribution: very high maximum and very low probability of each success\n\nPoisson distribution uses the log link - must be positive\n\nexponential scaling can be surprising\nlarge priors makes extremely long tails with very large values\nwant higher mean, lower variance\n\n\\[\nY_i \\sim Poisson(\\lambda_i)\n\\\\\nlog(\\lambda_i) = \\alpha + \\beta x_i\n\\\\\n\\lambda_i = exp(\\alpha + \\beta x_i)\n\\]\nTo add contact as an interaction term where C is contact:\n\n\\[\nY_i \\sim Poisson(\\lambda_i)\n\\\\\nlog(\\lambda_i) = \\alpha_{C[i]} + \\beta_{C[i]} log(P_i)\n\\\\\n\\alpha_j \\sim Normal(3, 0.5)\n\\\\\n\\beta_j \\sim Normal(0, 0.2)\n\\]\n\n\n\n# model\n\nlibrary(rethinking)\ndata(Kline)\nd &lt;- Kline\nd$P &lt;- scale( log(d$population) )\nd$contact_id &lt;- ifelse( d$contact==\"high\" , 2 , 1 )\n\ndat &lt;- list(\n    T = d$total_tools ,\n    P = d$P ,\n    C = d$contact_id )\n\n# intercept only\nm11.9 &lt;- ulam(\n    alist(\n        T ~ dpois( lambda ),\n        log(lambda) &lt;- a,\n        a ~ dnorm( 3 , 0.5 )\n    ), data=dat , chains=4 , log_lik=TRUE )\n\n# interaction model\nm11.10 &lt;- ulam(\n    alist(\n        T ~ dpois( lambda ),\n        log(lambda) &lt;- a[C] + b[C]*P,\n        a[C] ~ dnorm( 3 , 0.5 ),\n        b[C] ~ dnorm( 0 , 0.2 )\n    ), data=dat , chains=4 , log_lik=TRUE )\n\ncompare( m11.9 , m11.10 , func=PSIS )\n\nk &lt;- PSIS( m11.10 , pointwise=TRUE )$k\nplot( dat$P , dat$T , xlab=\"log population (std)\" , ylab=\"total tools\" ,\n    col=ifelse( dat$C==1 , 4 , 2 ) , lwd=4+4*normalize(k) ,\n    ylim=c(0,75) , cex=1+normalize(k) )\n# set up the horizontal axis values to compute predictions at\nP_seq &lt;- seq( from=-1.4 , to=3 , len=100 )\n\n# predictions for C=1 (low contact)\nlambda &lt;- link( m11.10 , data=data.frame( P=P_seq , C=1 ) )\nlmu &lt;- apply( lambda , 2 , mean )\nlci &lt;- apply( lambda , 2 , PI )\nlines( P_seq , lmu , lty=2 , lwd=1.5 )\nshade( lci , P_seq , xpd=TRUE , col=col.alpha(4,0.3) )\n\n# predictions for C=2 (high contact)\nlambda &lt;- link( m11.10 , data=data.frame( P=P_seq , C=2 ) )\nlmu &lt;- apply( lambda , 2 , mean )\nlci &lt;- apply( lambda , 2 , PI )\nlines( P_seq , lmu , lty=1 , lwd=1.5 )\nshade( lci , P_seq , xpd=TRUE , col=col.alpha(2,0.3))\n\nidentify( dat$P , dat$T , d$culture )\n\n# natural scale now\n\nplot( d$population , d$total_tools , xlab=\"population\" , ylab=\"total tools\" ,\n    col=ifelse( dat$C==1 , 4 , 2 ) , lwd=4+4*normalize(k) ,\n    ylim=c(0,75) , cex=1+normalize(k) )\nP_seq &lt;- seq( from=-5 , to=3 , length.out=100 )\n# 1.53 is sd of log(population)\n# 9 is mean of log(population)\npop_seq &lt;- exp( P_seq*1.53 + 9 )\nlambda &lt;- link( m11.10 , data=data.frame( P=P_seq , C=1 ) )\nlmu &lt;- apply( lambda , 2 , mean )\nlci &lt;- apply( lambda , 2 , PI )\nlines( pop_seq , lmu , lty=2 , lwd=1.5 )\nshade( lci , pop_seq , xpd=TRUE , col=col.alpha(4,0.3))\n\nlambda &lt;- link( m11.10 , data=data.frame( P=P_seq , C=2 ) )\nlmu &lt;- apply( lambda , 2 , mean )\nlci &lt;- apply( lambda , 2 , PI )\nlines( pop_seq , lmu , lty=1 , lwd=1.5 )\nshade( lci , pop_seq , xpd=TRUE , col=col.alpha(2,0.3) )\n\nidentify( d$population , d$total_tools , d$culture )\n\n\nnumber of effective parameters penalty shows how well the model performs after you drop individual data points\n\ntherefore models with more parameters often have lower effective parameters\n\ngamma-Poisson is the appropriate analog to a student t-test - wider tails and more robust\nimprove scientific model\n\npeople produce innovations so population and contact both innovate but there is also loss\n\\[\n\\Delta T = \\alpha_C P^{\\beta_C} - \\gamma T\n\\]\n\\(\\Delta T\\) = change in tools\n\\(\\alpha\\) = innovation rate\n\\(\\beta\\) = diminishing returns\n\\(\\gamma\\) = loss\nT = number of tools\nC = contact\n\nset equation to 0 and solve for T then insert into your model\n\n\\[\n\\hat{T} = \\frac {\\alpha_C P^{\\beta_C}} {\\gamma}\n\\\\\nT_i \\sim Poisson (\\lambda_i)\n\\\\\n\\lambda_i = \\hat{T}\n\\]\nmust constrain all parameters to be positive\n\n\n\n# innovation/loss model\n\ndat2 &lt;- list( T=d$total_tools, P=d$population, C=d$contact_id )\nm11.11 &lt;- ulam(\n    alist(\n        T ~ dpois( lambda ),\n        lambda &lt;- exp(a[C])*P^b[C]/g,\n        a[C] ~ dnorm(1,1),\n        b[C] ~ dexp(1),\n        g ~ dexp(1)\n    ), data=dat2 , chains=4 , cores=4 , log_lik=TRUE )\n\nprecis(m11.11,2)\n\nplot( d$population , d$total_tools , xlab=\"population\" , ylab=\"total tools\" ,\n    col=ifelse( dat$C==1 , 4 , 2 ) , lwd=4+4*normalize(k) ,\n    ylim=c(0,75) , cex=1+normalize(k) )\nP_seq &lt;- seq( from=-5 , to=3 , length.out=100 )\n\n\nstill need to deal with location as confound"
  },
  {
    "objectID": "notes/notes-10.html#count-glms",
    "href": "notes/notes-10.html#count-glms",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Count GLMs",
    "text": "Count GLMs\n\ndistributions from constraints\nmaximum entropy priors: binomial, Poisson, and extensions\nrobust regressions: beta-binomial, gamma-Poisson"
  },
  {
    "objectID": "notes/notes-10.html#simpsons-paradox",
    "href": "notes/notes-10.html#simpsons-paradox",
    "title": "Lecture 10 - Counts & Hidden Confounds",
    "section": "Simpson’s Paradox",
    "text": "Simpson’s Paradox\n\nreversal of an association when groups are combined or separated within the dataset\nthe reversal is purely statistical - no way to understand it without causal assumptions\nnon-linear haunting\n\nthere’s a positive effect in both groups but it cannot be estimated from this sample\njust because your distribution overlaps zero, doesn’t mean the effect is null"
  },
  {
    "objectID": "notes/notes-13.html",
    "href": "notes/notes-13.html",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-13.html#rose-thorn",
    "href": "notes/notes-13.html#rose-thorn",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-13.html#multilevel-adventures",
    "href": "notes/notes-13.html#multilevel-adventures",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "Multilevel Adventures",
    "text": "Multilevel Adventures\n\ncluster: kinds of groups in the data\nfeatures: aspets of the model (parameters) that vary by cluster\ncluster (tanks) -&gt; features (survival)\nadd clusters = more index (categorical) variables, more population priors\nadd features = more parameters, more dimensions in each population prior"
  },
  {
    "objectID": "notes/notes-13.html#varying-effects",
    "href": "notes/notes-13.html#varying-effects",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "Varying Effects",
    "text": "Varying Effects\n\na way for us to try and estimate unmeasured confounds\nvarying effect strategy: unmeasured features of clusters leave an imprint on the data that can be measured by 1) repeat observations of each cluster and 2) partial pooling among clusters\npredictive perspective: important source of cluster-level variation, regularize\ncausal perspective: competing causes or unobserved confounds\ninterested in varying effects from a predictive and a causal perspective\nfixed effects: varying effects with variance fixed at infinity, no pooling"
  },
  {
    "objectID": "notes/notes-13.html#practical-difficulties",
    "href": "notes/notes-13.html#practical-difficulties",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "Practical Difficulties",
    "text": "Practical Difficulties\n\nvarying effects are a good default but come with difficulties\n\nhow to use more than one cluster type at the same time?\nhow to calculate predictions\nhow to sample chains efficiently\ngroup-level confounding"
  },
  {
    "objectID": "notes/notes-13.html#varying-districts",
    "href": "notes/notes-13.html#varying-districts",
    "title": "Lecture 13 - Multilevel Adventures",
    "section": "Varying Districts",
    "text": "Varying Districts\n\ncluster by district\nestimand: C in each district, partially pooled\nvarying intercept on each district\n\\(C_i \\sim Bernoulli(p_i)\\)\n\\(logit(p_i) = \\alpha_{D[i]}\\)\n\\(\\alpha_j \\sim Normal(\\bar{\\alpha}, \\sigma)\\)\n\\(\\bar{\\alpha} \\sim Normal(0,1)\\)\n\\(\\sigma \\sim Exponential(1)\\)\n\n\n# simple varying intercepts model\nlibrary(rethinking)\ndata(bangladesh)\nd &lt;- bangladesh\n\ndat &lt;- list(\n    C = d$use.contraception,\n    D = as.integer(d$district) )\n\nmCD &lt;- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) &lt;- a[D],\n        vector[61]:a ~ normal(abar,sigma),\n        abar ~ normal(0,1),\n        sigma ~ exponential(1)\n    ) , data=dat , chains=4 , cores=4 )\n\n\n# plot estimates\np &lt;- link( mCD , data=list(D=1:61) )\n# blank2(w=2)\nplot( NULL , xlab=\"district\" , lwd=3 , col=2 , xlim=c(1,61), ylim=c(0,1) , ylab=\"prob use contraception\" )\n\npoints( 1:61 , apply(p,2,mean) , xlab=\"district\" , lwd=3 , col=2 , ylim=c(0,1) , ylab=\"prob use contraception\" )\n\n for ( i in 1:61 ) lines( c(i,i) , PI(p[,i]) , lwd=8 , col=col.alpha(2,0.5) )\n\n# show raw proportions - have to skip 54\nn &lt;- table(dat$D)\nCn &lt;- xtabs(dat$C ~ dat$D)\npC &lt;- as.numeric( Cn/n )\npC &lt;- c( pC[1:53] , NA , pC[54:60] )\npoints( pC , lwd=2 )\n\n# only some labels via locator\nn &lt;- table(dat$D)\nn &lt;- as.numeric(n)\nn &lt;- c( n[1:53] , 0 , n[54:60] )\nidentify( 1:61 , pC , labels=n , cex=1 )\n\n\npartial pooling shrinks districts with low sampling towards mean\n\nbetter predictions\n\nwhat is the effect of urban living? District features are potential group-level confounds\neach district\n\\(C_i \\sim Bernoulli(p_i)\\)\n\\(logit(p_i) = \\alpha_{D[i]} + \\beta_{D[i]}U_i\\)\n\\(\\alpha_j \\sim Normal(\\bar{\\alpha}, \\sigma)\\) = regularizing prior for rural\n\\(\\beta_j \\sim Normal(\\bar{\\beta}, \\tau)\\) = regularizing prior for urban effect\n\\(\\bar{\\alpha}, \\bar{\\beta} \\sim Normal(0,1)\\) = averages\n\\(\\sigma, \\tau \\sim Exponential(1)\\) = standard deviations\n\n\ndat &lt;- list(\n    C = d$use.contraception,\n    D = as.integer(d$district),\n    U = ifelse(d$urban==1,1,0) )\n\n# total U\nmCDU &lt;- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) &lt;- a[D] + b[D]*U,\n        vector[61]:a ~ normal(abar,sigma),\n        vector[61]:b ~ normal(bbar,tau),\n        c(abar,bbar) ~ normal(0,1),\n        c(sigma,tau) ~ exponential(1)\n    ) , data=dat , chains=4 , cores=4 )\n\ntraceplot(mCDU,pars=\"tau\",lwd=2,n_cols=1)\ntrankplot(mCDU,pars=\"tau\",lwd=3,n_cols=1)\n\n# non-centered version\nmCDUnc &lt;- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) &lt;- a[D] + b[D]*U,\n        # define effects using other parameters\n        save&gt; vector[61]:a &lt;&lt;- abar + za*sigma,\n        save&gt; vector[61]:b &lt;&lt;- bbar + zb*tau,\n        # z-scored effects\n        vector[61]:za ~ normal(0,1),\n        vector[61]:zb ~ normal(0,1),\n        # ye olde hyper-priors\n        c(abar,bbar) ~ normal(0,1),\n        c(sigma,tau) ~ exponential(1)\n    ) , data=dat , chains=4 , cores=4 )\n\n# plot estimates\n\nUval &lt;- 0\nxcol &lt;- ifelse(Uval==0,2,4)\np &lt;- link( mCDUnc , data=list(D=1:61,U=rep(Uval,61)) )\n# blank2(w=2,h=0.8)\nplot( NULL , xlab=\"district\" , lwd=3 , col=2 , xlim=c(1,61), ylim=c(0,1) , ylab=\"prob use contraception\" )\nabline(h=0.5,lty=2,lwd=0.5)\n\npoints( 1:61 , apply(p,2,mean) , xlab=\"district\" , lwd=3 , col=xcol , ylim=c(0,1) , ylab=\"prob use contraception\" )\n\n for ( i in 1:61 ) lines( c(i,i) , PI(p[,i]) , lwd=8 , col=col.alpha(xcol,0.5) )\n\n# show raw proportions - have to skip 54\nn &lt;- table(dat$D,dat$U)\nCn &lt;- xtabs(dat$C ~ dat$D + dat$U)\npC &lt;- as.numeric( Cn[,Uval+1]/n[,Uval+1] )\npC &lt;- c( pC[1:53] , NA , pC[54:60] )\npoints( pC , lwd=2 )\n\n# only some labels via locator\nnn &lt;- as.numeric(n[,Uval+1])\nnn &lt;- c( nn[1:53] , 0 , nn[54:60] )\nidentify( 1:61 , pC , labels=nn , cex=1 )\n\n# show standard deviations\npost &lt;- extract.samples(mCDUnc)\ndens(post$sigma,xlab=\"posterior standard deviation\",lwd=3,col=2,xlim=c(0,1.2))\ndens(post$tau,lwd=3,col=4,add=TRUE,adj=0.2)\ncurve(dexp(x,1),from=0,to=1.3,add=TRUE,lwd=2,lty=2)\n\n\npriors inside of priors is good for models but can create ill-fitting models\nthe more you cut up the data because of different varying effects, the sample sizes will inevitably get smaller -&gt; partial pooling helps"
  },
  {
    "objectID": "notes/notes-01.html",
    "href": "notes/notes-01.html",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "",
    "text": "Rose: I LOVE DAGS. Really interesting to think about the non-uniqueness of null models in ecology.\nThorn: the difference between regression/intervention – have i always just done regression?"
  },
  {
    "objectID": "notes/notes-01.html#rose-thorn",
    "href": "notes/notes-01.html#rose-thorn",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "",
    "text": "Rose: I LOVE DAGS. Really interesting to think about the non-uniqueness of null models in ecology.\nThorn: the difference between regression/intervention – have i always just done regression?"
  },
  {
    "objectID": "notes/notes-01.html#third-edition",
    "href": "notes/notes-01.html#third-edition",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "Third Edition",
    "text": "Third Edition\n\npeach boxes instead of blue boxes"
  },
  {
    "objectID": "notes/notes-01.html#causal-inference",
    "href": "notes/notes-01.html#causal-inference",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "Causal Inference",
    "text": "Causal Inference\n\nstatistical models require scientific (causal) models\ncorrelation is a very limited measure of association\n\nassociation can occur without correlation\n\ncausation requires intervention - it is not just the behaviour without intervention\ncausal prediction = prediction of the consequences of an intervention (implications of changing one variable on another variable)\n\nknowing the cause of an action allows you to create predictions\nwhat happens if I do this?\n\ncausal imputation = knowing the cause of an action allows you to reconstruct possible outcomes (i.e., what if I had done something else?)\nEven for description, causal models are required"
  },
  {
    "objectID": "notes/notes-01.html#dags",
    "href": "notes/notes-01.html#dags",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "DAGs",
    "text": "DAGs\n\nabstract causal models: includes names of variables and their causal relationships\ntells you the consequences of an intervention\ntells you what you can decide/ask without additional assumptions\nfacilitates you asking scientific questions\neach causal query requires a different model"
  },
  {
    "objectID": "notes/notes-01.html#golems",
    "href": "notes/notes-01.html#golems",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "Golems",
    "text": "Golems\n\nstatistical models = golems\noften not possible to design and outline a null hypothesis that is meaningful to reject in observational science\n\nwhat is a null ecological community?\n\nthink of good example/explanation for no null ecology/previous two slides\n\ntakeaway is that null hypothesis does not give you cause/process behind outcome\n\nwhat is your null? is it unique?"
  },
  {
    "objectID": "notes/notes-01.html#todo",
    "href": "notes/notes-01.html#todo",
    "title": "Lecture 01 - The Golem of Prague",
    "section": "TODO",
    "text": "TODO"
  },
  {
    "objectID": "notes/notes-18.html",
    "href": "notes/notes-18.html",
    "title": "Lecture 18 - Missing Data",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-18.html#rose-thorn",
    "href": "notes/notes-18.html#rose-thorn",
    "title": "Lecture 18 - Missing Data",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-18.html#missing-data",
    "href": "notes/notes-18.html#missing-data",
    "title": "Lecture 18 - Missing Data",
    "section": "Missing Data",
    "text": "Missing Data\n\nobserved data is a special case - we trick ourselves into believing there is no error\nmissing data = some cases unobserved\nnot totally missing - they have constraints and relationships to other variables"
  },
  {
    "objectID": "notes/notes-18.html#workflow",
    "href": "notes/notes-18.html#workflow",
    "title": "Lecture 18 - Missing Data",
    "section": "Workflow",
    "text": "Workflow\n\ndropping cases with missing values is sometimes justifiable\nright thing to do depends upon causal assumptions\nimputation is often beneficial/necessary\nBayesian imputation: compute posterior probability distribution of missing values\nMarginalizing unknowns: averaging over distribution of missing values"
  },
  {
    "objectID": "notes/notes-18.html#bayesian-imputation",
    "href": "notes/notes-18.html#bayesian-imputation",
    "title": "Lecture 18 - Missing Data",
    "section": "Bayesian Imputation",
    "text": "Bayesian Imputation\n\ncausal model of all variables implies strategy for imputation\nsometimes imputation is unnecessary, e.g., discrete parameters\nsometimes imputation is easier, e.g., censored observations"
  },
  {
    "objectID": "notes/notes-18.html#imputing-primates",
    "href": "notes/notes-18.html#imputing-primates",
    "title": "Lecture 18 - Missing Data",
    "section": "Imputing Primates",
    "text": "Imputing Primates\n\nmissing values already have probability distributions\nexpress causal model for each partially-observed variable\nreplace each missing value with a parameter\nnot the same as non-Bayesian imputation\n\nthat generates datasets and runs the model multiple times\nthis estimates probability distributions using other parameters and relationships\n\nimputation without relationships among predictors is risky"
  },
  {
    "objectID": "notes/notes-08.html",
    "href": "notes/notes-08.html",
    "title": "Lecture 08 - Markov chain Monte Carlo",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-08.html#rose-thorn",
    "href": "notes/notes-08.html#rose-thorn",
    "title": "Lecture 08 - Markov chain Monte Carlo",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-08.html#modelling-approaches",
    "href": "notes/notes-08.html#modelling-approaches",
    "title": "Lecture 08 - Markov chain Monte Carlo",
    "section": "Modelling Approaches",
    "text": "Modelling Approaches\n\nquadratic approximation makes strong assumptions about what the model looks like - approximately Gaussian\nMCMC is intensive but with less assumptions and more flexible"
  },
  {
    "objectID": "notes/notes-08.html#markov-chain-monte-carlo",
    "href": "notes/notes-08.html#markov-chain-monte-carlo",
    "title": "Lecture 08 - Markov chain Monte Carlo",
    "section": "Markov chain Monte Carlo",
    "text": "Markov chain Monte Carlo\n\nchain: sequence of draws from distribution\nMarkov chain: history doesn’t matter, just where you are now\nMonte Carlo: random simulation"
  },
  {
    "objectID": "notes/notes-08.html#hamiltonian-monte-carlo",
    "href": "notes/notes-08.html#hamiltonian-monte-carlo",
    "title": "Lecture 08 - Markov chain Monte Carlo",
    "section": "Hamiltonian Monte Carlo",
    "text": "Hamiltonian Monte Carlo\n\nprobability space is essentially a skate park\n\nuses random pathways that follow the distribution of the variables\n\n\ndag &lt;- dagify(\n  S ~ Q + J + X,\n  Q ~ X,\n  J ~ Z,\n  outcome = 'S',\n  latent = 'Q',\n    coords = list(x = c(Q = 0, X = 0, S = 1, J = 1, Z = 2),\n                y = c(X = 0, J = 0, Z = 0, Q = 1, S = 1))\n)\n\nggdag(dag) + theme_dag()\n\n\n\n\n\nEstimand: association between wine quality and wine origin. Stratify by judge for efficiency.\n\n\ndata(Wines2012)\nd &lt;- Wines2012\n\ndat &lt;- list(\n  S = standardize(d$score),\n  J = as.numeric(d$judge), \n  W = as.numeric(d$wine),\n  X = ifelse(d$wine.amer == 1,1,2),\n  Z = ifelse(d$judge.amer == 1,1,2)\n)\n\nmQ &lt;- ulam(alist(\n  S ~ dnorm(mu, sigma), \n  mu &lt;- Q[W],\n  Q[W] ~ dnorm(0, 1), \n  sigma ~ dexp(1)),\n  data = dat, chains = 4, cores = 4)\n\nprecis(mQ, 2)\n\n\ntrace plots: visualization of the Markov chain\nwant more than one chain in order to check convergence\n\nconvergence: each chain explores the right distribution and the same distribution\n\nR-hat is chain convergence diagnostic\n\nvariance ratio\nif chains do converge, beginning of the chain and end of chain should be exploring the same place and therefore the chain is stationary\nas total variance (among chains) approaches average variance within chains, R-hat approaches 1\nif chains were exploring different regions, the total variance would be bigger and Rhat is larger than 1\ndoes not guarantee convergence but gives an idea that the chains are working when ~ 1\n\nn_eff = effective samples\n\napproximation of how long the chain would be if each sample was completely independent of the one before it (perfectly uncorrelated, truly random)\nwhen samples are autocorrelated, you have fewer effective samples\ntypically n_eff is smaller than number of samples you actually took\n\nbecause perfect chain will need fewer samples/be shorter\n\n\n\n\nmQO &lt;- ulam(alist(\n  S ~ dnorm(mu, sigma), \n  mu &lt;- Q[W] + O[X],\n  Q[W] ~ dnorm(0, 1),\n  O[X] ~ dnorm(0, 1),\n  sigma ~ dexp(1)),\n  data = dat, chains = 4, cores = 4)\n\nplot(precis(mQO, 2))\n\nmQOJ &lt;- ulam(alist(\n  S ~ dnorm(mu, sigma), \n  mu &lt;- (Q[W] + O[X] - H[J])*D[J],\n  Q[W] ~ dnorm(0, 1),\n  O[X] ~ dnorm(0, 1),\n  H[J] ~ dnorm(0, 1),\n  D[J] ~ dexp(1),\n  sigma ~ dexp(1)),\n  data = dat, chains = 4, cores = 4)\n\nplot(precis(mQOJ, 2))\n\n\nadding judges adds information to the model and allows for better estimates\noften if there is an issue, it is with your model\n\nloop back to basic scientific questions and assumptions\ndivergent transitions are one of the signs of this - “rejected proposal”"
  },
  {
    "objectID": "notes/notes-03.html",
    "href": "notes/notes-03.html",
    "title": "Lecture 03 - Geocentric Models",
    "section": "",
    "text": "Rose: Non-independent variables in a summary table\nThorn: Stupid resolution to my plot coding issue"
  },
  {
    "objectID": "notes/notes-03.html#rose-thorn",
    "href": "notes/notes-03.html#rose-thorn",
    "title": "Lecture 03 - Geocentric Models",
    "section": "",
    "text": "Rose: Non-independent variables in a summary table\nThorn: Stupid resolution to my plot coding issue"
  },
  {
    "objectID": "notes/notes-03.html#linear-regressions",
    "href": "notes/notes-03.html#linear-regressions",
    "title": "Lecture 03 - Geocentric Models",
    "section": "Linear Regressions",
    "text": "Linear Regressions\n\nessentially a geocentric model - overly simplified\nseparate from a causal model\nassociations are from the causal model, not the statistical model"
  },
  {
    "objectID": "notes/notes-03.html#gaussian-distributions",
    "href": "notes/notes-03.html#gaussian-distributions",
    "title": "Lecture 03 - Geocentric Models",
    "section": "Gaussian Distributions",
    "text": "Gaussian Distributions\n\nthere are many more ways to end up in the center than to end up on the periphery\nwhy the Gaussian distribution spontaneously occurs in natural systems\ngenerative: if we add fluctuations, we tend towards normal distribution (lots of summed fluctuations in nature)\ninferential: estimating mean and variance, normal distribution is best one to use because it is least informative (no other information present)\nnormal distribution is just a tool for estimating mean/variance because it has widest distribution\n\ndata doesn’t have to be normal to be able to leverage the tool to estimate mean/variance"
  },
  {
    "objectID": "notes/notes-03.html#workflow",
    "href": "notes/notes-03.html#workflow",
    "title": "Lecture 03 - Geocentric Models",
    "section": "Workflow",
    "text": "Workflow\n\nState a clear question\nSketch causal assumptions\nDefine generative model from sketch\nUse generative model to build estimator\nProfit\n\n\nlibrary(rethinking)\nlibrary(dagitty)\ndata(Howell1)"
  },
  {
    "objectID": "notes/notes-03.html#describing-models",
    "href": "notes/notes-03.html#describing-models",
    "title": "Lecture 03 - Geocentric Models",
    "section": "Describing Models",
    "text": "Describing Models\n= is deterministic\n\n~ is distributional"
  },
  {
    "objectID": "notes/notes-03.html#howell-example",
    "href": "notes/notes-03.html#howell-example",
    "title": "Lecture 03 - Geocentric Models",
    "section": "Howell Example",
    "text": "Howell Example\n\nQuestion/Estimand: Describe association between adult weight and height\n\n\nd2 &lt;- Howell1[Howell1$age&gt;=18,]\n\n\nScientific model: weight is some function of height and unobserved influences\n\n\nd &lt;- dagitty(\"dag {\n                H -&gt; W\n                U -&gt; W\n             }\")\n\ndrawdag(d)\n\n\n\n\n\\[\nW = f(H, U)\n\\]\n\nGenerative/Statistical model\n\n\nTwo options: dynamic (complex and ongoing) and static\n\nStatic model allows us to imagine changes at specific times and still use a Gaussian distribution\n\nFor adults, weight is a proportion of height plus the influence of unobserved causes\n\n\\[\nW = \\beta H+U\n\\]\n\nsim_weight &lt;- function(H, b, sd){\n  U &lt;- rnorm(length(H), 0, sd)\n  W &lt;- b*H + U\n  return(W)\n}\n\nH &lt;- runif(200, min = 130, max = 170)\nW &lt;- sim_weight(H, b = 0.5, sd = 5)\nplot(W ~ H, col = 2, lwd = 3)\n\n\n\n\n\ncan adjust to produce biologically unrealistic relationships by adjusting b to be large or small\n\n\\[ W_i = \\beta H_i + U_i \\\\ U_i \\sim Normal(0, \\sigma) \\\\ H_i \\sim Uniform(130, 170) \\]\n\n~ indicates distribution\n= is deterministic\nwe want to estimate how the average weight changes with height\n\\[\nE(W_{i}|H_{i}) = \\alpha + \\beta H_{i}\n\\]\n\\(E(W_{i}|H_{i})\\) = average weight conditional on height\n\\(\\alpha\\) = intercept (when height is 0, what is weight? Scientifically should be zero but putting it in model to make sure our model is scientifically sound)\n\\(\\beta\\) = slope\nPosterior distribution:\n\n\\[\nPr(\\alpha,\\beta,\\sigma| H_{i}, W_{i}) = \\frac{Pr(W_{i}|H_{i}, \\alpha,\\beta,\\sigma)Pr(\\alpha,\\beta,\\sigma)}{Z}\n\\]\nalpha, beta, sigma are our three unknowns: alpha and beta define the line and sigma defines the error around it\nunknowns are conditional (|) on the data Hi and Wi\nalpha, sigma, beta are unknown so we need a posterior distribution for them (and they are dependent on the data)\n\\(Pr(\\alpha,\\beta,\\sigma| H_{i}, W_{i})\\) = posterior probability of specific line\n\\(Pr(W_{i}|H_{i}, \\alpha,\\beta,\\sigma)\\) = probability of each weight dependent on height value, alpha, beta, sigma (garden of forking data)\n\\(Pr(\\alpha,\\beta,\\sigma)\\) = prior\nZ = normalizing constant\n\\(W_{i} \\sim Normal(\\mu _{i}), \\sigma)\\): linear model\n\\(\\mu _{i} = \\alpha + \\beta H_{i}\\)\n\nQuadratic approximation (continuous version of grid approximation)\n\napproximate posterior distribution as a multivariate Gaussian distrubution\nposteriors are often Gaussian\n\\(W_{i} \\sim Normal(\\mu _{i}), \\sigma)\\)\n\\(\\mu _{i} = \\alpha + \\beta H_{i}\\)\n\\(\\alpha \\sim Normal(0,10)\\)\n\\(\\beta \\sim Uniform(0,1)\\)\n\\(\\sigma \\sim Uniform(0, 10)\\)\n\n\n\nH &lt;- runif(10, 130, 170)\nW &lt;- sim_weight(H, b = 0.5, sd = 5)\n\nm3.1 &lt;- quap(alist(\n  W ~ dnorm(mu, sigma),\n  mu &lt;- a + b*H,\n  a ~ dnorm(0, 10),\n  b ~ dunif(0, 1),\n  sigma ~ dunif(0, 10)\n), data = list(W=W, H=H))\n\n\nPriors\n\nwe want to constrain to scientifically plausible values\njustify with information outside the data - like the rest of model\npriors have no essential differences from posteriors except for data – we can use them as generative models and ensure that our assumptions are reasonable\n\n\n\nn &lt;- 1e3\na &lt;- rnorm(n, 0, 10)\nb &lt;- runif(n, 0, 1)\nplot(NULL, xlim = c(130, 170), ylim = c(50, 90)) + \nfor (j in 1:50) abline(a=a[j], b=b[j], col = 'red') \n\n\n\n\ninteger(0)\n\n\n\nValidate model\n\n\ntest statistical model with simulated observations from scientific model - need to test if your model is working\nuse many values and make sure your model responds appropriately\n\n\n# model summary\nprecis(m3.1)\n\n           mean         sd       5.5%      94.5%\na     4.0511353 9.13423476 -10.547136 18.6494067\nb     0.4779494 0.06084271   0.380711  0.5751878\nsigma 4.4312133 1.00487274   2.825233  6.0371940\n\n\n\nAnalyze data\n\n\ndat &lt;- list(W = d2$weight, H = d2$height)\nm3.2 &lt;- quap(alist(\n  W ~ dnorm(mu, sigma),\n  mu &lt;- a + b*H,\n  a ~ dnorm(0, 10), \n  b ~ dunif(0, 1),\n  sigma ~ dunif(0, 10)\n), data = dat)\n\nprecis(m3.2)\n\n             mean         sd        5.5%       94.5%\na     -43.3648194 4.16934139 -50.0282322 -36.7014066\nb       0.5716653 0.02694158   0.5286074   0.6147231\nsigma   4.2507500 0.16155195   3.9925588   4.5089412\n\n\n\nparameters are not independent of one another, they cannot be independently interpreted\n\nuse posterior predictions and describe/interpret those by sampling the posterior distribution\n\nPosterior Predictive Distribution\n\n\npost &lt;- extract.samples(m3.2)\nplot(d2$height, d2$weight) + \nfor (j in 1:20) abline(a=post$a[j], b=post$b[j])\n\n\n\n\ninteger(0)\n\nheight_seq &lt;- seq(130, 190, len = 20)\nW_postpred &lt;- sim(m3.2, data = list(H=height_seq))\nW_PI &lt;- apply(W_postpred, 2, PI)\n\nplot(d2$height, d2$weight) + \nfor (j in 1:20) abline(a=post$a[j], b=post$b[j]) +\nlines(height_seq, W_PI[1,], lty = 2) +\nlines(height_seq, W_PI[2,], lty = 2)\n\n\n\n\ninteger(0)"
  },
  {
    "objectID": "notes/notes-03.html#todo",
    "href": "notes/notes-03.html#todo",
    "title": "Lecture 03 - Geocentric Models",
    "section": "TODO:",
    "text": "TODO:"
  },
  {
    "objectID": "notes/notes-06.html",
    "href": "notes/notes-06.html",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "",
    "text": "Rose: identifying and working through bad controls, table 2 fallacy\nThorn:"
  },
  {
    "objectID": "notes/notes-06.html#rose-thorn",
    "href": "notes/notes-06.html#rose-thorn",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "",
    "text": "Rose: identifying and working through bad controls, table 2 fallacy\nThorn:"
  },
  {
    "objectID": "notes/notes-06.html#randomization",
    "href": "notes/notes-06.html#randomization",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Randomization",
    "text": "Randomization\n\nrandomizing the treatment can remove the confound (only available for experiments)\neffectively removes all the other arrows in X"
  },
  {
    "objectID": "notes/notes-06.html#causal-thinking",
    "href": "notes/notes-06.html#causal-thinking",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Causal Thinking",
    "text": "Causal Thinking\n\nin an experiment, we cut causes of the treatment -&gt; we randomize\nsimulating intervention mimics randomization\ndo(X) means intervene on X\nexample: simple confound\n\n\ndag &lt;- dagify(\n\n    X ~ U,\n\n    Y ~ U + X\n\n)\n\nggdag(dag) +\n\n    theme_dag()\n\n\n\n\n\nstratifying by U removes causal relationship and allows to test effect of X -&gt; Y\nmarginalize or average over control variables\n\nthe coefficient is not usually satisfactory, need to marginalize\nthe causal effect of X on Y is the distribution of Y when we change X, averaged over the distributions of the control variables\n\n\n\ndag &lt;- dagify(\n\n    Baboons ~ Cheetahs,\n\n    Gazelle ~ Baboons + Cheetahs\n\n)\n\nggdag(dag) +\n\n    theme_dag()\n\n\n\n\n\npopulations of each of these species influences the other\n\nwhen cheetahs are present, baboons are scared and do not influence gazelle population\nwhen cheetahs are absent, baboons eat and regulate gazelle population\nto assess causal effect of baboons, need to average over cheetah population"
  },
  {
    "objectID": "notes/notes-06.html#do-calculus",
    "href": "notes/notes-06.html#do-calculus",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Do-Calculus",
    "text": "Do-Calculus\n\nallows us to determine if it is possible to answer our question using a DAG\ndo-calculus tells us if we need to make additional functional assumptions\nbackdoor criterion\n\nshortcut to apply do-calculus to use your eyes\nrule to find a set of variables to stratify by to yield estimate of our estimand\n\n\nidentify all paths connecting treatment (X) to outcome (Y)\npaths with arrows entering X are backdoor paths (non-causal paths)\nfind adjustment set that closes/blocks all backdoor paths\n\n\n\n\n\n# simulate confounded Y\nN &lt;- 200\nb_XY &lt;- 0\nb_UY &lt;- -1\nb_UZ &lt;- -1\nb_ZX &lt;- 1\n\nset.seed(10)\nU &lt;- rbern(N)\nZ &lt;- rnorm(N, b_UZ*U)\nX &lt;- rnorm(N, b_ZX*Z)\nY &lt;- rnorm(N, b_XY*X + b_UY*U)\nd &lt;- list(Y=Y, X=X, Z=Z)\n\n# ignore U,Z \nm_YX &lt;- quap(alist(\n  Y ~ dnorm(mu, sigma),\n  mu &lt;- a + b_XY*X,\n  a ~ dnorm(0,1),\n  b_XY ~ dnorm(0, 1),\n  sigma ~ dexp(1)\n), data = d)\n\n# stratify by Z \nm_YXZ &lt;- quap(alist(\n    Y ~ dnorm(mu, sigma),\n  mu &lt;- a + b_XY*X + b_Z*Z,\n  a ~ dnorm(0,1),\n  c(b_XY, b_Z) ~ dnorm(0, 1),\n  sigma ~ dexp(1)\n), data = d)\n\npost &lt;- extract.samples(m_YX)\npost2 &lt;- extract.samples(m_YXZ)\n\ndensity_1 &lt;- density(post$b_XY)\ndensity_2 &lt;- density(post2$b_XY)\nplot(density_1, col=2, xlim = c(min(density_1$x,density_2$x), max(density_1$x,density_2$x)), xlab = \"posterior b_XY\", main = \"red = confounded, blue = stratified\") + \nlines(density_2, col=4)\n\n\n\n\ninteger(0)\n\n\n\nany variable you add to a model as part of the adjustment set (ie to control for), its coefficients are usually not interpretable\nminimum adjustment set is not always the best set\n\ndoesn’t consider statistical efficiency\nsometimes want to stratify by things that are not in the minimum adjustment set to make your model more efficient\n\n\n\ndag &lt;- dagify(\n\n    P ~ G + U,\n    C ~ P + G + U\n\n)\n\nggdag(dag) +\n\n    theme_dag()\n\n\n\n\n\nP is a mediator and collider, so we can’t get the direct effect of G on C because we don’t have U\n\ncan estimate of total effect of G on C"
  },
  {
    "objectID": "notes/notes-06.html#good-bad-controls",
    "href": "notes/notes-06.html#good-bad-controls",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Good & Bad Controls",
    "text": "Good & Bad Controls\n\ncontrol variable: variable introduced to an analysis so that a causal estimate is possible\n\ngood and bad controls\n\nvariables not being collinear is not a good reason for including/excluding variables\n\ncollinearity can arise from many causal processes\n\npost-treatment variables are often risky controls\nif there is no backdoor path to variable of interest, you don’t need to control for it\n\n\n# sim confounding by post-treatment variable\n\nf &lt;- function(n=100,bXZ=1,bZY=1) {\n    X &lt;- rnorm(n)\n    u &lt;- rnorm(n)\n    Z &lt;- rnorm(n, bXZ*X + u)\n    Y &lt;- rnorm(n, bZY*Z + u )\n    bX &lt;- coef( lm(Y ~ X) )['X']\n    bXZ &lt;- coef( lm(Y ~ X + Z) )['X']\n    return( c(bX,bXZ) )\n}\n\nsim &lt;- mcreplicate( 1e4 , f(), mc.cores = 1)\n\n[ 1000 / 10000 ]\n[ 2000 / 10000 ]\n[ 3000 / 10000 ]\n[ 4000 / 10000 ]\n[ 5000 / 10000 ]\n[ 6000 / 10000 ]\n[ 7000 / 10000 ]\n[ 8000 / 10000 ]\n[ 9000 / 10000 ]\n[ 10000 / 10000 ]\n\ndensity_1 &lt;- density(sim[1,])\ndensity_2 &lt;- density(sim[2,])\nplot(density_1,  xlim=c(-1,0.8) , ylim=c(0,2.7), xlab = \"posterior mean\", main = \"red = confounded, black = correct\") + \nlines(density_2, col=2)\n\n\n\n\ninteger(0)\n\n\n\ncase control bias (selection on outcome)\n\nvery bad to add descendents of your outcome to your model\nweakly stratifying by the outcome (e.g., stratifying by Z)\n\n\n\ndag &lt;- dagify(\n    Y ~ X,\n    Z ~ Y\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nf &lt;- function(n=100,bXY=1,bYZ=1) {\n    X &lt;- rnorm(n)\n    Y &lt;- rnorm(n, bXY*X )\n    Z &lt;- rnorm(n, bYZ*Y )\n    bX &lt;- coef( lm(Y ~ X) )['X']\n    bXZ &lt;- coef( lm(Y ~ X + Z) )['X']\n    return( c(bX,bXZ) )\n}\n\nsim &lt;- mcreplicate( 1e4 , f(), mc.cores = 1 )\n\n[ 1000 / 10000 ]\n[ 2000 / 10000 ]\n[ 3000 / 10000 ]\n[ 4000 / 10000 ]\n[ 5000 / 10000 ]\n[ 6000 / 10000 ]\n[ 7000 / 10000 ]\n[ 8000 / 10000 ]\n[ 9000 / 10000 ]\n[ 10000 / 10000 ]\n\ndensity_1 &lt;- density(sim[1,])\ndensity_2 &lt;- density(sim[2,])\nplot(density_1,  xlim=c(-1,0.8) , ylim=c(0,2.7), xlab = \"posterior mean\", main = \"red = confounded, black = correct\") + \nlines(density_2, col=2)\n\n\n\n\ninteger(0)\n\n\n\nprecision parasite\n\nno backdoors because Z is not connected to Y except through X\nnot good to stratify Z because you are explaining part of the effect of X with Z\n\n\n\ndag &lt;- dagify(\n    Y ~ X,\n    X ~ Z\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nf &lt;- function(n=100,bZX=1,bXY=1) {\n    Z &lt;- rnorm(n)\n    X &lt;- rnorm(n, bZX*Z )\n    Y &lt;- rnorm(n, bXY*X )\n    bX &lt;- coef( lm(Y ~ X) )['X']\n    bXZ &lt;- coef( lm(Y ~ X + Z) )['X']\n    return( c(bX,bXZ) )\n}\n\nsim &lt;- mcreplicate( 1e4 , f(n=50), mc.cores = 1 )\n\n[ 1000 / 10000 ]\n[ 2000 / 10000 ]\n[ 3000 / 10000 ]\n[ 4000 / 10000 ]\n[ 5000 / 10000 ]\n[ 6000 / 10000 ]\n[ 7000 / 10000 ]\n[ 8000 / 10000 ]\n[ 9000 / 10000 ]\n[ 10000 / 10000 ]\n\ndensity_1 &lt;- density(sim[1,])\ndensity_2 &lt;- density(sim[2,])\nplot(density_1,  xlim=c(-1,0.8) , ylim=c(0,2.7), xlab = \"posterior mean\", main = \"red = confounded, black = correct\") + \nlines(density_2, col=2)\n\n\n\n\ninteger(0)\n\n\n\nbias amplification\n\nX and Y confounded by u\nadding Z biases your answer because it “double” activates the confound\n\n\n\ndag &lt;- dagify(\n    Y ~ X + u,\n    X ~ Z + u\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nf &lt;- function(n=100,bZX=1,bXY=1) {\n    Z &lt;- rnorm(n)\n    u &lt;- rnorm(n)\n    X &lt;- rnorm(n, bZX*Z + u )\n    Y &lt;- rnorm(n, bXY*X + u )\n    bX &lt;- coef( lm(Y ~ X) )['X']\n    bXZ &lt;- coef( lm(Y ~ X + Z) )['X']\n    return( c(bX,bXZ) )\n}\n\n# true value zero\nsim &lt;- mcreplicate( 1e4 , f(bXY=0), mc.cores = 1)\n\n[ 1000 / 10000 ]\n[ 2000 / 10000 ]\n[ 3000 / 10000 ]\n[ 4000 / 10000 ]\n[ 5000 / 10000 ]\n[ 6000 / 10000 ]\n[ 7000 / 10000 ]\n[ 8000 / 10000 ]\n[ 9000 / 10000 ]\n[ 10000 / 10000 ]\n\ndensity_1 &lt;- density(sim[1,])\ndensity_2 &lt;- density(sim[2,])\nplot(density_1,  xlim=c(0,1) , ylim=c(0,6), xlab = \"posterior mean\", main = \"red = more biased, black = biased\") + \nlines(density_2, col=2)\n\n\n\n\ninteger(0)\n\n\n\ncovariation in X & Y requires variation in their causes\nwithin each level of Z, less variation in X\nadditionally, the confound u becomes relatively more important within each level of Z\ndouble biasing\n\n\nabline_w &lt;- function(...,col=1,lwd=1,dlwd=2) {\n    abline(...,col=\"white\",lwd=lwd+dlwd)\n    abline(...,col=col,lwd=lwd)\n}\n\nn &lt;- 1000\nZ &lt;- rbern(n)\nu &lt;- rnorm(n)\nX &lt;- rnorm(n, 7*Z + u )\nY &lt;- rnorm(n, 0*X + u )\n\ncols &lt;- c( col.alpha(2,0.5) , col.alpha(4,0.5) )\nplot( X , Y  , col=cols[Z+1] , lwd=2 ) + \n  abline_w( lm(Y~X) , lwd=3 ) + \n  abline_w( lm(Y[Z==1]~X[Z==1]) , lwd=3 , col=4 ) + \n  abline_w( lm(Y[Z==0]~X[Z==0]) , lwd=3 , col=2 )\n\n\n\n\ninteger(0)\n\n\n\nthe damage increases once stratified by Z (red and blue lines)"
  },
  {
    "objectID": "notes/notes-06.html#summary",
    "href": "notes/notes-06.html#summary",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Summary",
    "text": "Summary\n\nadding control variables can be worse than omitting\nthere are good controls - backdoor criterion\nmake assumptions explicit"
  },
  {
    "objectID": "notes/notes-06.html#bonus---table-2-fallacy",
    "href": "notes/notes-06.html#bonus---table-2-fallacy",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "Bonus - Table 2 Fallacy",
    "text": "Bonus - Table 2 Fallacy\n\nnot all coefficients are causal effects\nstatistical model designed to identify X -&gt; Y will not also identify effects of control variables\n\\(Y_i \\sim Normal(\\mu_i, \\sigma)\\)\n\\(\\mu_i = \\alpha + \\beta_xX_i + \\beta_SS_i + \\beta_AA_i\\)\nthink through DAG for each control variable to see what the coefficient actually means\nno interpretation without causal representation"
  },
  {
    "objectID": "notes/notes-06.html#todo",
    "href": "notes/notes-06.html#todo",
    "title": "Lecture 06 - Good & Bad Controls",
    "section": "TODO",
    "text": "TODO\n\nread Table 2 Fallacy paper\nwhat are other types of causal inference that are not multiple regression?"
  },
  {
    "objectID": "notes/notes-07.html",
    "href": "notes/notes-07.html",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "",
    "text": "Rose: prediction is different from causal inference\nThorn: could be clearer that this is all about prediction/have an example for prediction"
  },
  {
    "objectID": "notes/notes-07.html#rose-thorn",
    "href": "notes/notes-07.html#rose-thorn",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "",
    "text": "Rose: prediction is different from causal inference\nThorn: could be clearer that this is all about prediction/have an example for prediction"
  },
  {
    "objectID": "notes/notes-07.html#problems-of-prediction",
    "href": "notes/notes-07.html#problems-of-prediction",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Problems of Prediction",
    "text": "Problems of Prediction\n\nwhat function describes the data (fitting, compression)\nwhat functions explains these points (causal inference)\nwhat would happen if we changed the data (intervention)\nwhat is the next observation from the same process (prediction)\n\nprediction is the absence of intervention\nprediction does not require causal inference\n\nLeave-one-out cross-validation\n\n\n\ndrop one point\nfit line to remaining\npredict dropped point\nrepeat (1) with next point\nscore is error on dropped\n\n\ntask you use to assess the expected predictive accuracy of a statistical procedure\nscore in: fit to the sample / score out: fit to prediction\nLPPD (log posterior probability of observation) used for cross-validation because it includes the entire posterior\nmore flexible patterns generally perform better in sample and worse out of sample (at least for simple models)"
  },
  {
    "objectID": "notes/notes-07.html#cross-validation",
    "href": "notes/notes-07.html#cross-validation",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Cross-Validation",
    "text": "Cross-Validation\n\nfor simple models (no hyperparameters), more parameters improves fit to sample BUT may reduce accuracy of predictions out of sample\naccurate models trade off flexibility with overfitting\nthere’s usually an optimal flexibility"
  },
  {
    "objectID": "notes/notes-07.html#regularization",
    "href": "notes/notes-07.html#regularization",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Regularization",
    "text": "Regularization\n\nregular means learning the important/regular features of the sample - not getting too excited by every datapoint\nregularization improves models, where loo just compares models (can both be bad)\noverfitting depends upon the priors\ndon’t be too excited about every point in the sample, because not every point in the sample is regular (not all points are representative)\nskeptical priors regularize models/inference - have tighter variance that reduces flexibility\n\ndownweights improbable values\n\nskeptical priors improve model prediction - regularize so that models learn regular features and ignore irregular features\n\nthere is such a thing as too tight priors for model prediction (unless you have a small sample size)\n\nIn sample gets worse with tighter priors, out of sample gets better with tighter priors\nRegularizing priors -&gt; for pure prediction uses, you can tune the prior using cross-validation\n\ncausal inference uses science to choose priors"
  },
  {
    "objectID": "notes/notes-07.html#prediction-penalty",
    "href": "notes/notes-07.html#prediction-penalty",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Prediction Penalty",
    "text": "Prediction Penalty\n\nFor N points, cross-validation requires fitting N models\n\nfeasible for few data points but for many data points gets unwieldy\n\nImportance sampling (PSIS) and information criteria (WAIC) allow you to assess prediction penalty from one model posterior distribution (for predictive models)\nWAIC, PSIS, cross-validation (CV) measure overfitting\n\nregularization manages overfitting\n\nCausal inference is not addressed by measuring or addressing overfitting\n\nthese tools are addressing the performance of a predictive model, not a causal model\nshould not select causal models based on these values because they are not associated with causality\n\nthese are all predictive metrics"
  },
  {
    "objectID": "notes/notes-07.html#model-mis-selection",
    "href": "notes/notes-07.html#model-mis-selection",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Model Mis-selection",
    "text": "Model Mis-selection\n\nDo not use predictive criteria (WAIC, PSIS, CV) to choose a causal estimate\nPredictive criteria prefer confounds and colliders\n\nimprove predictive accuracy"
  },
  {
    "objectID": "notes/notes-07.html#outliers-robust-regression",
    "href": "notes/notes-07.html#outliers-robust-regression",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Outliers & Robust Regression",
    "text": "Outliers & Robust Regression\n\nsome points are more influential than others - ‘outliers’\noutliers are information - don’t necessarily want to remove them\n\nbut they often have high leverage/weight because they are “surprising”\ndropping outliers ignores the problem - predictions will still be bad\nmodel is wrong, not the data\n\ncan quantify the influence of each point on the posterior distribution using cross-validation\ncan also use a mixture model/robust regression to address outliers\ndivorce rate example\n\nMaine and Idaho are outliers in divorce/age relationship\nquantify influence of outliers using PSIS k statistic or WAIC penalty term\nunmodelled sources of variation cause outliers -&gt; error distributions are not constant across the sample\n\nassuming that the dataset has multiple error distributions, with the same mean but different variations indicates that you are using a student t-test\nGaussian distribution has extremely thin tails - very skeptical\nstudent t distribution is much less skeptical, wider tails, much less influenced by outliers + more robust\n\n\n\n\ndata(WaffleDivorce)\nd &lt;- WaffleDivorce\n\n# model\ndat &lt;- list(\n    D = standardize(d$Divorce),\n    M = standardize(d$Marriage),\n    A = standardize(d$MedianAgeMarriage)\n)\n\nm5.3 &lt;- quap(alist(\n  D ~ dnorm(mu, sigma), \n  mu &lt;- a + bM*M + bA*A,\n  a ~ dnorm(0, 0.2),\n  bM ~ dnorm(0, 0.5), \n  bA ~ dnorm(0, 0.5),\n  sigma ~ dexp(1)\n), data = dat)\n\nm5.3t &lt;- quap(alist(\n  D ~ dstudent(2, mu, sigma), \n  mu &lt;- a + bM*M + bA*A,\n  a ~ dnorm(0, 0.2),\n  bM ~ dnorm(0, 0.5), \n  bA ~ dnorm(0, 0.5),\n  sigma ~ dexp(1)\n), data = dat)"
  },
  {
    "objectID": "notes/notes-07.html#robust-regressions",
    "href": "notes/notes-07.html#robust-regressions",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Robust Regressions",
    "text": "Robust Regressions\n\nunobserved heterogeneity in sample -&gt; mixture of Gaussian errors\n\nthicker tails means model is less surprised/more robust\n\nhard to choose distribution of student t-test because extreme values are rare - can test multiple values and select based on that, reporting all after\nstudent-t regression can be a good default for undertheorized domains\n\nbecause Gaussian distribution is so skeptical"
  },
  {
    "objectID": "notes/notes-07.html#prediction",
    "href": "notes/notes-07.html#prediction",
    "title": "Lecture 07 - Fitting Over & Under",
    "section": "Prediction",
    "text": "Prediction\n\nwhat is the next observation from the same process? = prediction\npossible to make very good predictions without knowing causes\noptimizing prediction does not reliably reveal causes"
  },
  {
    "objectID": "notes/notes-09.html",
    "href": "notes/notes-09.html",
    "title": "Lecture 09 - Modeling Events",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-09.html#rose-thorn",
    "href": "notes/notes-09.html#rose-thorn",
    "title": "Lecture 09 - Modeling Events",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-09.html#modeling-events",
    "href": "notes/notes-09.html#modeling-events",
    "title": "Lecture 09 - Modeling Events",
    "section": "Modeling Events",
    "text": "Modeling Events\nNOTE: read causal foundations of bias, fairness, and …\n\nobservations are counts\nunknowns are possibilities, odds\neverything is interacting\n“log-odds” scale\n\nEstimand: what is the effect of gender on university admissions?\n\n\n\n\n\n\nperception of gender by admissions officer is what truly matters here\ntotal effect of discrimination is what people experience\ndirect discrimination: status-based (referees are biased for or against certain gender)\nindirect discrimination: structural (gender influences what discipline you are interested in and that discipline is underfunded)\nquite often, the thing we are able to estimate is not what we want (total effects are easier to estimate but subpaths are interesting and important to understanding equity)\nmany unobserved confounds in this setup\n\nGenerative Model:\n\nN &lt;- 1000 # number of applicants\nG &lt;- sample(1:2, size = N, replace = T) # gender distribution\nD &lt;- rbern(N, ifelse(G==1, 0.3, 0.8)) + 1 #gener 1 tends to apply to appartment 1, 2 to 2\naccept_rate &lt;- matrix(c(0.1, 0.3, 0.1, 0.3), nrow = 2) # matrix of acceptance rates [dept, gender]\nA &lt;- rbern(N, accept_rate[D,G]) # simulate acceptance"
  },
  {
    "objectID": "notes/notes-09.html#modeling-events-1",
    "href": "notes/notes-09.html#modeling-events-1",
    "title": "Lecture 09 - Modeling Events",
    "section": "Modeling Events",
    "text": "Modeling Events\n\nwe observe: count of events\nwe estimate: probability (or log-odds) of events\n\nlike the globe tossing model, but need “proportion of water” stratified by other variables"
  },
  {
    "objectID": "notes/notes-09.html#generalized-linear-models",
    "href": "notes/notes-09.html#generalized-linear-models",
    "title": "Lecture 09 - Modeling Events",
    "section": "Generalized Linear Models",
    "text": "Generalized Linear Models\n\nlinear models: expected value is additive “linear” combination of parameters\ngeneralized linear models: expected value is some function of an additive combination of parameters\n\nworks because normal distribution is unbounded on both sides\nwhen you have probabilities, which are bounded by 0 and 1, you make the expected value a function of the additive model\nchoosing the function so that it works well is the art of linear models\n\n\n\\[\nY_i \\sim Bernoulli (p_i)\n\\\\\nf(p_i) = \\alpha + \\beta_XX_i + \\beta_Z Z_i\n\\\\\np_i = f^{-1}(\\alpha + \\beta_XX_i + \\beta_Z Z_i )\n\\]\n\np = probability of the event\n\n\n\nf is the link function - links parameters of distribution to linear model\nf-1 is the inverse link function\n\nthe probability = inverse link function\n\ndistributions: relative number of ways to observe data, given assumptions about rates, probabilities, slopes, etc.\ndistributions are matched to constraints on observed variables\nlink functions are matched to distributions, essentially automatically matched to distributions\nexponential distribution - the time to an event that has a constant rate. Values you sample from exponential distribution are latencies/rates (continuous data above one)\n\nprocess that produces events and then you count those events = binomial distribution\ndon’t know maximum number of counts = poisson (special case of binomial)\nsum exponential processes = gamma\nlarge means of gamma distribution = normal distribution\n\ndistribution you want is governed by the constraints you assume about your variable\n\nyou cannot test if your data are normal\nneed to think about constraints and match to distributions"
  },
  {
    "objectID": "notes/notes-09.html#logit-link",
    "href": "notes/notes-09.html#logit-link",
    "title": "Lecture 09 - Modeling Events",
    "section": "Logit Link",
    "text": "Logit Link\n\nlog-odds = logit link\n\\[\nlogit(p_i) = log \\frac{p_i}{1-p_i}\n\\]\nBernoulli/binomial models most often use the logit link\n\\[\nY_i \\sim Bernoulli (p_i)\n\\\\\nlogit(p_i) = \\alpha + \\beta_XX_i + \\beta_Z Z_i\n\\\\\np_i = logit^{-1}(\\alpha + \\beta_XX_i + \\beta_Z Z_i )\n\\]\nlinear model output is on the “log-odds scale”\n\nharsh scale (S-shaped curve)\nby the time you reach -4 on the scale it means hardly ever, and -6 is never (opposite on the other side)"
  },
  {
    "objectID": "notes/notes-09.html#logistic-priors",
    "href": "notes/notes-09.html#logistic-priors",
    "title": "Lecture 09 - Modeling Events",
    "section": "Logistic Priors",
    "text": "Logistic Priors\n\nlogit link compresses parameter distributions\non log-odds scale, above +4 = almost always, below -4 = almost never\n\ntherefore, tighter priors are better\n\n\nStatistical Model:\n\n\\(A_i \\sim Bernoulli(p_i)\\)\n\\(logit(p_i) = \\alpha [G_i, D_i]\\)\n\nthis creates a matrix\n\n\\(\\alpha_{j,k} \\sim Normal(0,1)\\)\n\n\n# generative model, basic mediator scenario\n\nN &lt;- 1000 # number of applicants\n# even gender distribution\nG &lt;- sample( 1:2 , size=N , replace=TRUE )\n# gender 1 tends to apply to department 1, 2 to 2\nD &lt;- rbern( N , ifelse( G==1 , 0.3 , 0.8 ) ) + 1\n# matrix of acceptance rates [dept,gender]\naccept_rate &lt;- matrix( c(0.1,0.3,0.1,0.3) , nrow=2 )\naccept_rate &lt;- matrix( c(0.05,0.2,0.1,0.3) , nrow=2 )\n# simulate acceptance\np &lt;- sapply( 1:N , function(i) accept_rate[D[i],G[i]] )\nA &lt;- rbern( N , p )\n\n# total effect gender\ndat_sim &lt;- list( A=A , D=D , G=G )\n\nm1 &lt;- ulam(\n    alist(\n        A ~ bernoulli(p),\n        logit(p) &lt;- a[G],\n        a[G] ~ normal(0,1)\n    ), data=dat_sim , chains=4 , cores=4 )\n\nprecis(m1,depth=2)\n\n# direct effects\nm2 &lt;- ulam(\n    alist(\n        A ~ bernoulli(p),\n        logit(p) &lt;- a[G,D],\n        matrix[G,D]:a ~ normal(0,1)\n    ), data=dat_sim , chains=4 , cores=4 )\n\nprecis(m2,depth=3)\n\n# aggregate the dat_sim for binomial instead of Bernoulli\n\nx &lt;- as.data.frame(cbind( A=dat_sim$A , G=dat_sim$G , D=dat_sim$D  ))\nhead(x,20)\n\ndat_sim2 &lt;- aggregate( A ~ G + D , dat_sim , sum )\ndat_sim2$N &lt;- aggregate( A ~ G + D , dat_sim , length )$A\n\nm2_bin &lt;- ulam(\n    alist(\n        A ~ binomial(N,p),\n        logit(p) &lt;- a[G,D],\n        matrix[G,D]:a ~ normal(0,1)\n    ), data=dat_sim2 , chains=4 , cores=4 )\n\nprecis(m2_bin,3)"
  },
  {
    "objectID": "notes/notes-09.html#logistic-binomial-regression-with-data",
    "href": "notes/notes-09.html#logistic-binomial-regression-with-data",
    "title": "Lecture 09 - Modeling Events",
    "section": "Logistic & Binomial Regression with Data",
    "text": "Logistic & Binomial Regression with Data\n\nlogistic is Bernoulli - binary 0, 1\nbinomial is count 0, N\nboth have logit link and are equivalent for inference\n\n\n\ndata(UCBadmit)\nd &lt;- UCBadmit\n\ndat &lt;- list( \n    A = d$admit,\n    N = d$applications,\n    G = ifelse(d$applicant.gender==\"female\",1,2),\n    D = as.integer(d$dept)\n)\n\n# total effect gender\nmG &lt;- ulam(\n    alist(\n        A ~ binomial(N,p),\n        logit(p) &lt;- a[G],\n        a[G] ~ normal(0,1)\n    ), data=dat , chains=4 , cores=4 )\n\nprecis(mG,2)\n\n# direct effects\nmGD &lt;- ulam(\n    alist(\n        A ~ binomial(N,p),\n        logit(p) &lt;- a[G,D],\n        matrix[G,D]:a ~ normal(0,1)\n    ), data=dat , chains=4 , cores=4 )\n\nprecis(mGD,3)\n\n# check chains\n\ntraceplot(mGD)\ntrankplot(mGD)\n\n# contrasts\n# on probability scale\n\npost1 &lt;- extract.samples(mG)\nPrA_G1 &lt;- inv_logit( post1$a[,1] )\nPrA_G2 &lt;- inv_logit( post1$a[,2] )\ndiff_prob &lt;- PrA_G1 - PrA_G2\ndens(diff_prob,lwd=4,col=2,xlab=\"Gender contrast (probability)\")\n\npost2 &lt;- extract.samples(mGD)\nPrA &lt;- inv_logit( post2$a ) \ndiff_prob_D_ &lt;- sapply( 1:6 , function(i) PrA[,1,i] - PrA[,2,i] )\nplot(NULL,xlim=c(-0.2,0.3),ylim=c(0,25),xlab=\"Gender contrast (probability)\",ylab=\"Density\")\nfor ( i in 1:6 ) dens( diff_prob_D_[,i] , lwd=4 , col=1+i , add=TRUE )\nabline(v=0,lty=3)\n\n\n# marginal effect of gender perception (direct effect)\n\n# compute department weights via simulation\n# we can just compute predictions as if all applications had been perceived as men\n# and then again as if all had been perceived as women\n# difference is marginal effect of perception, beause does not change department assignments (G -&gt; A only, no G -&gt; D)\n\n# OLD WRONG CODE!\n#p_G1 &lt;- link( mGD , data=list(N=dat$N,D=dat$D,G=rep(1,12)) )\n#p_G2 &lt;- link( mGD , data=list(N=dat$N,D=dat$D,G=rep(2,12)) )\n\n# NEW CORRECT CODE\n\n# number of applicatons to simulate\ntotal_apps &lt;- sum(dat$N)\n\n# number of applications per department\napps_per_dept &lt;- sapply( 1:6 , function(i) sum(dat$N[dat$D==i]) )\n\n# simulate as if all apps from women\np_G1 &lt;- link(mGD,data=list(\n    D=rep(1:6,times=apps_per_dept),\n    N=rep(1,total_apps),\n    G=rep(1,total_apps)))\n\n# simulate as if all apps from men\np_G2 &lt;- link(mGD,data=list(\n    D=rep(1:6,times=apps_per_dept),\n    N=rep(1,total_apps),\n    G=rep(2,total_apps)))\n\n# summarize\ndens( p_G1 - p_G2 , lwd=4 , col=2 , xlab=\"effect of gender perception\" )\nabline(v=0,lty=3)\n\n# show each dept density with weight as in population\nw &lt;- xtabs( dat$N ~ dat$D ) / sum(dat$N)\nw &lt;- w/max(w)\nplot(NULL,xlim=c(-0.2,0.3),ylim=c(0,25),xlab=\"Gender contrast (probability)\",ylab=\"Density\")\nfor ( i in 1:6 ) dens( diff_prob_D_[,i] , lwd=2+8*w[i]^3 , col=1+i , add=TRUE )\nabline(v=0,lty=3)"
  },
  {
    "objectID": "notes/notes-09.html#post-stratification",
    "href": "notes/notes-09.html#post-stratification",
    "title": "Lecture 09 - Modeling Events",
    "section": "Post-Stratification",
    "text": "Post-Stratification\n\ndescription, prediction, and causal inference often require post-stratification\nway to predict what the intervention will do to a specific population\npost-stratification = re-weighting estimates for target population\nfor university example, we would reweight the application numbers to each department"
  },
  {
    "objectID": "notes/notes-09.html#discrimination",
    "href": "notes/notes-09.html#discrimination",
    "title": "Lecture 09 - Modeling Events",
    "section": "Discrimination",
    "text": "Discrimination\n\nthere are large structural effects\ndistribution of applications can also be a consequence of discrimination but data cannot respond to this question\nconfounds here are likely"
  },
  {
    "objectID": "notes/notes-09.html#survival-analysis",
    "href": "notes/notes-09.html#survival-analysis",
    "title": "Lecture 09 - Modeling Events",
    "section": "Survival Analysis",
    "text": "Survival Analysis\n\nanother way of modelling events but we care about the time it took for an event to happen instead of number of times it happened\ncannot ignore censored cases (left-censored = don’t know when time started, right-censored = observation ended before event)\n\nignoring leads to inferential error\n\nexponential or gamma distribution\n\nexponential for single part failure\ngamma for multiple part failure\n\ninverse rate is average waiting time in this example\n\\[\nD_i \\sim Exponential(\\lambda_i)\n\\\\\np(D_i|\\lambda_i) = \\lambda_iexp(-\\lambda_iD_i)\n\\]\nIf the event happened we use the cumulative distribution (CDF) from the exponential - probability event before-or-at time x\nif the event didn’t happen yet (censored) use complementary cumulative distribution (CCDF) - probability not-event before-or-at time x\n\nfor any time on the x axis, how many cats have not yet been adopted\n\n\\[\nD_i |A_i = 1\\sim Exponential(\\lambda_i)\n\\\\\nD_i|A_i = 0 \\sim Exponential-CCDF(\\lambda_i)\n\\\\\n\\lambda_i = 1/\\mu_i\n\\\\\nlog\\ \\mu_i = \\alpha_{CID[i]}\n\\]\nFirst line is observed adoptions, second line is not-yet adoptions\nCID = colour id\n\\(1/\\mu_i\\) is to get average waiting time for each cat\nD = days at shelter, A = day at adoption"
  },
  {
    "objectID": "notes/notes-17.html",
    "href": "notes/notes-17.html",
    "title": "Lecture 17 - Measurement & Misclassification",
    "section": "",
    "text": "Rose: feels extremely relevant\nThorn: weird log functions"
  },
  {
    "objectID": "notes/notes-17.html#rose-thorn",
    "href": "notes/notes-17.html#rose-thorn",
    "title": "Lecture 17 - Measurement & Misclassification",
    "section": "",
    "text": "Rose: feels extremely relevant\nThorn: weird log functions"
  },
  {
    "objectID": "notes/notes-17.html#measurement-error",
    "href": "notes/notes-17.html#measurement-error",
    "title": "Lecture 17 - Measurement & Misclassification",
    "section": "Measurement Error",
    "text": "Measurement Error\n\nmany variables are proxies of the cause of interest\ndon’t consider how things are measured\nmeasurement error can have many effects on estimates"
  },
  {
    "objectID": "notes/notes-17.html#modeling-measurement",
    "href": "notes/notes-17.html#modeling-measurement",
    "title": "Lecture 17 - Measurement & Misclassification",
    "section": "Modeling Measurement",
    "text": "Modeling Measurement\n\ndivorce, marriage, and age statistics are measured with error and the amount of error varies by state\n\nimbalance in evidence quality\npotential confounding through measurement error\n\nstates with larger populations have less uncertainty/higher quality data\nconfounding because measurement is influenced by population size but then effects such as divorce rate can also be influenced by population size"
  },
  {
    "objectID": "notes/notes-17.html#misclassification",
    "href": "notes/notes-17.html#misclassification",
    "title": "Lecture 17 - Measurement & Misclassification",
    "section": "Misclassification",
    "text": "Misclassification\n\ncategorical version of measurement error\nrelated models: hurdle models and occupancy models"
  },
  {
    "objectID": "notes/notes-05.html",
    "href": "notes/notes-05.html",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "",
    "text": "Rose: completely changed my approach to science\nThorn: why set M and not A in intervention?"
  },
  {
    "objectID": "notes/notes-05.html#rose-thorn",
    "href": "notes/notes-05.html#rose-thorn",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "",
    "text": "Rose: completely changed my approach to science\nThorn: why set M and not A in intervention?"
  },
  {
    "objectID": "notes/notes-05.html#correlation",
    "href": "notes/notes-05.html#correlation",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "Correlation",
    "text": "Correlation\n\ncorrelation is common in nature, causation is sparse\ncorrelation over time series especially common\nscientific question/estimand -&gt; recipe/estimator -&gt; result/estimate"
  },
  {
    "objectID": "notes/notes-05.html#association-causation",
    "href": "notes/notes-05.html#association-causation",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "Association & Causation",
    "text": "Association & Causation\n\nwe must defend against confounding in our stats\nconfounds mislead us - feature of the sample + how we use it\nfour elemental confounds\n\ncauses of confounds can be extremely diverse but they are all at their core made up of relationships between 3 variables"
  },
  {
    "objectID": "notes/notes-05.html#the-fork",
    "href": "notes/notes-05.html#the-fork",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "The Fork",
    "text": "The Fork\n\nX and Y are associated \\(Y \\not\\!\\perp\\!\\!\\!\\perp X\\) (not independent)\nShare a common cause Z\nOnce stratified by Z, no association \\(Y \\perp\\!\\!\\!\\perp X | Z\\)\n\n\ndag &lt;- dagify(\n    X ~ Z,\n    Y ~ Z\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nsimulation:\n\n\nn &lt;- 1000\nZ &lt;- rbern(n, 0.5)\nX &lt;- rbern(n, (1-Z)*0.01 + Z*0.9)\nY &lt;- rbern(n, (1-Z)*0.01 + Z*0.9)\n\n# correlated\ncor(X, Y)\n\n[1] 0.7716271\n\n# no longer correlated when we pull out Z\ncor(X[Z==0], Y[Z==0])\n\n[1] -0.007855966\n\ncor(X[Z==1], Y[Z==1])\n\n[1] 0.0004186768\n\n\n\ncols &lt;- c(4,2)\nn &lt;- 300\nZ &lt;- rbern(n, 0.5)\nX &lt;- rnorm(n, (1-Z)*0.01 + Z*0.9)\nY &lt;- rnorm(n, (1-Z)*0.01 + Z*0.9)\n\nplot(X, Y, col=cols[Z+1]) + \n  abline(lm(Y[Z==1] ~ X[Z==1]), col = 2) + \n  abline(lm(Y[Z==0] ~X[Z==0]), col = 4) + \n  abline(lm(Y~ X))\n\n\n\n\ninteger(0)\n\n\n\nexample:\n\nwhy do regions of the USA with higher rates of marriage also have higher rates of divorce?\nestimand: causal effect of marriage rate on divorce rate\n\n\n\ndag &lt;- dagify(\n    D ~ A,\n    M ~ A,\n    D ~ M\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\ncauses are not in the data\nis effect of marriage rates on divorce rates just a symptom of common cause age?\nneed to break the fork to test direct effect – stratify by A\ncontinuous variable stratification means that we are adding to that variable essentially to the intercept\n\nstratifying means for every level of the stratified value, what is the association between the other two variables?\nwhat does this mean for continuous variables?\nevery value of A produces a different relationship between D and M\n\\[\n\\mu_i = (\\alpha + \\beta_A*A) + B_D*D\n\\]\n\nstandardizing variables is almost always helpful in linear regression\n\ntransform measurement scales to the scale we want, as long as we remember how we changed them\nmake the mean zero and divide by sd\nalpha prior is the value of average divorce rate (when standardized = 0)\nbeta is within 1 and -1 for standardized variables because outside of those values the variable would be explaining all of the variation\n\nto stratify by A, include as a term in the linear model:\n\n\\(D _i \\sim Normal(\\mu _i, \\sigma)\\)\n\\(\\mu _i = \\alpha + \\beta_MM_i + \\beta_AA_i\\)\n\\(\\alpha \\sim Normal(0, 0.2)\\)\n\\(\\beta_M \\sim Normal(0,0.5)\\)\n\\(\\beta_A \\sim Normal(0, 0.5)\\)\n\\(\\sigma \\sim Exponential(1)\\)\n\n\n\nlibrary(rethinking)\ndata(WaffleDivorce)\nd &lt;- WaffleDivorce\n\n# model\ndat &lt;- list(\n    D = standardize(d$Divorce),\n    M = standardize(d$Marriage),\n    A = standardize(d$MedianAgeMarriage)\n)\n\nm_DMA &lt;- quap(\n    alist(\n        D ~ dnorm(mu,sigma),\n        mu &lt;- a + bM*M + bA*A,\n        a ~ dnorm(0,0.2),\n        bM ~ dnorm(0,0.5),\n        bA ~ dnorm(0,0.5),\n        sigma ~ dexp(1)\n    ) , data=dat )\n\nplot(precis(m_DMA))\n\n\n\n\n\na causal effect is a manipulation of the generative model, an intervention\ndistribution of D when we intervene (“do”) M \\(p(D|do(M))\\)\n\nimplies deleting all arrows into M and simulating D\nset values of M while holding A constant\n\n\n\npost &lt;- extract.samples(m_DMA)\n\n# sample A from data\nn &lt;- 1e3\nAs &lt;- sample(dat$A, size = n, replace = T)\n\n# simulate D for M=0 (sample mean)\nDM0 &lt;- with(post, rnorm(n, a + bM*0 + bA*As, sigma))\n\n# simulate D for M = 1 (+1 standard deviation)\n# use the same A values \nDM1 &lt;- with(post, rnorm(n, a + bM*1 + bA*As, sigma))\n\n# contrast\nM10_contrast &lt;- DM1 - DM0\ndens(M10_contrast, lwd=4, col=2, xlab=\"effect of increase in M\")"
  },
  {
    "objectID": "notes/notes-05.html#the-pipe",
    "href": "notes/notes-05.html#the-pipe",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "The Pipe",
    "text": "The Pipe\n\nX and Y are associated \\(Y \\not\\!\\perp\\!\\!\\!\\perp X\\)\nInfluence of X on Y transmitted through Z\nOnce stratified by Z, no association \\(Y \\perp\\!\\!\\!\\perp X | Z\\)\n\n\ndag &lt;- dagify(\n    Y ~ Z,\n    Z ~ X\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nn &lt;- 1000\nX &lt;- rbern(n, 0.5)\nZ &lt;- rbern(n, (1-X)*0.01 + X*0.9)\nY &lt;- rbern(n, (1-Z)*0.01 + Z*0.9)\ncor(X,Y)\n\n[1] 0.8046954\n\n\n\neverything that Y knows about X, is already known by Z\n\nonce you learn Z, there is nothing more to learn about the association\n\n\n\ncols &lt;- c(4,2)\nn &lt;- 300\nX &lt;- rbern(n)\nZ &lt;- rbern(n, inv_logit(X))\nY &lt;- rbern(n, (2*Z-1))\n\nWarning in rbinom(n, size = 1, prob = prob): NAs produced\n\n# plot\n\n\nincluding the mediator at the wrong time can lead to incorrect inference\n\n\ndag &lt;- dagify(\n   H1 ~ H0 + Treat,\n   H1 ~ Fungus,\n   Fungus ~ Treat\n   \n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nwhat is the total causal effect of treatment?\nTreat -&gt; Fungus -&gt; H1 is a pipe, should not stratify by F\npost-treatment bias\n\nif you stratify by a consquence of the treatment, it can induce post-treatment bias - gives you a misleading estimate of what you’re after\nconsequences of treatment should not usually be included in the estimator"
  },
  {
    "objectID": "notes/notes-05.html#the-collider",
    "href": "notes/notes-05.html#the-collider",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "The Collider",
    "text": "The Collider\n\nX and Y are not associated (share no causes) \\(Y \\perp\\!\\!\\!\\perp X\\)\nX and Y both influence Z\nOnce stratified by Z, X and Y are associated \\(Y \\not\\!\\perp\\!\\!\\!\\perp X | Z\\)\n\n\ndag &lt;- dagify(\n    Z ~ X + Y\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nn &lt;- 1000\nX &lt;- rbern(n, 0.5)\nY &lt;- rbern(n, 0.5)\nZ &lt;- rbern(n, ifelse(X+Y&gt;0, 0.9, 0.2))\n\n\nstrong correlations caused by the collider could be read as correlation but causes are not in the data\n\n\ncols &lt;- c(4,2)\nN &lt;- 300\nX &lt;- rnorm(N)\nY &lt;- rnorm(N)\nZ &lt;- rbern(N, inv_logit(2*X+2*Y-2))\n\nplot(X,Y, cols = cols[Z+1]) + \n  abline(lm(Y[Z==1] ~ X[Z==1]), col = 2) + \n  abline(lm(Y[Z==0] ~X[Z==0]), col = 4) + \n  abline(lm(Y~ X))\n\nWarning in plot.window(...): \"cols\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"cols\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"cols\" is not a\ngraphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"cols\" is not a\ngraphical parameter\n\n\nWarning in box(...): \"cols\" is not a graphical parameter\n\n\nWarning in title(...): \"cols\" is not a graphical parameter\n\n\n\n\n\ninteger(0)\n\n\n\nsometimes samples come already stratified by collider\nassociations among the things you have measured post-selection is dangerous because the selection is often collider bias\nendogenous colliders\n\nif you include a collider in your estimator you can induce a spurious correlation\nhappens within your analysis\n\nexample: age and happiness\n\nestimand: influence of age on happiness\npossible confound: marital status\nsuppose age has zero influence on happiness, but that both age and happiness influence marital status\n\n\n\ndag &lt;- dagify(\n   M ~ A + H\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nstratified by marital status, negative association between age and happiness even though they are not related -&gt; age/happiness are unrelated"
  },
  {
    "objectID": "notes/notes-05.html#the-descendant",
    "href": "notes/notes-05.html#the-descendant",
    "title": "Lecture 05 - Elemental Confounds",
    "section": "The Descendant",
    "text": "The Descendant\n\nhow it behaves depends on what it is attached to\nA is the descendant, contains information of its “parent”\nX and Y are causally associated through Z \\(Y \\not\\!\\perp\\!\\!\\!\\perp X\\)\nA holds information about Z\nOnce stratified by A, X and Y less associated (if strong enough) \\(Y \\perp\\!\\!\\!\\perp X | A\\)\n\n\ndag &lt;- dagify(\n   Z ~ X,\n   Y ~ Z,\n   A ~ Z\n)\n\nggdag(dag) +\n    theme_dag()\n\n\n\n\n\nn &lt;- 1000\nx &lt;- rbern(n, 0.5)\nz &lt;- rbern(n, (1-x)*0.1 + x*0.9)\ny &lt;- rbern(n, (1-z)*0.1 + z*0.9)\na &lt;- rbern(n, (1-z)*0.1 + z*0.9)\n\n\ndescendants are everywhere - proxies"
  },
  {
    "objectID": "notes/notes-12.html",
    "href": "notes/notes-12.html",
    "title": "Lecture 12 - Multilevel Models",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-12.html#rose-thorn",
    "href": "notes/notes-12.html#rose-thorn",
    "title": "Lecture 12 - Multilevel Models",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-12.html#repeat-observations",
    "href": "notes/notes-12.html#repeat-observations",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Repeat Observations",
    "text": "Repeat Observations\n\nfor any given estimand, there are multiple estimators we can use (but some are better than others)\ncan include categorical responses such as individuals as seen before\n\nbut the model is not learning"
  },
  {
    "objectID": "notes/notes-12.html#multilevel-models",
    "href": "notes/notes-12.html#multilevel-models",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Multilevel Models",
    "text": "Multilevel Models\n\nmodels within models\n\n\nmodel observed groups/individuals\nmodel of population of groups/individuals\n\n\nthe population model creates a kind of memory\nmultilevel models with memory learn faster, better AND models with memory resist overfitting\nmultilevel models use every observation to inform predictions about other cafes and the population of cafes\nprior for next individual is the posterior of the previous one"
  },
  {
    "objectID": "notes/notes-12.html#regularization",
    "href": "notes/notes-12.html#regularization",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Regularization",
    "text": "Regularization\n\nmultilevel models adaptively regularize\ncomplete pooling: treat all clusters as identical -&gt; underfitting\nno pooling: treat all clusters as unrelated -&gt; overfitting\npartial pooling: adaptive compromise that achieves regularization"
  },
  {
    "objectID": "notes/notes-12.html#reedfrogs",
    "href": "notes/notes-12.html#reedfrogs",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Reedfrogs",
    "text": "Reedfrogs\n\ntreatments: density, size, predation\noutcome: survival\n48 groups (“tanks”) of tadpoles\n\n\n\n\n\n\n\n\\(S_i \\sim Binomial(D_i, p_i)\\)\n\\(logit(p_i) = \\alpha_{T[i]}\\)\n\\(\\alpha_j \\sim Normal(\\overline{\\alpha}, \\sigma)\\)\n\\(\\overline{\\alpha} \\sim Normal(0, 1.5)\\)\nparameters are just unobserved variables\n\ndata is an observed parameter\n\nif we want to learn about differences in between groups, we can set the prior for the mean tank as we normally would and then leave the prior for the variation of the groups as an unobserved parameter to be learned\nfind optimal value of sigma through cross-validation\n\nalthough we are using the model to choose a prior, we are not basing it off of model fit of the sample, we are evaluating it on cross-validation (out-of-sample). So we we are just assessing whether the model is overfit - not seeing how well it fits the data/causal relationships"
  },
  {
    "objectID": "notes/notes-12.html#automatic-regularization",
    "href": "notes/notes-12.html#automatic-regularization",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Automatic Regularization",
    "text": "Automatic Regularization\n\ncan use automatic regularization instead of cross-validation to remove the need to run so many models\n\n\\(S_i \\sim Binomial(D_i, p_i)\\)\n\\(logit(p_i) = \\alpha_{T[i]}\\)\n\\(\\alpha_j \\sim Normal(\\overline{\\alpha}, \\sigma)\\)\n\\(\\overline{\\alpha} \\sim Normal(0, 1.5)\\)\n\\(\\sigma \\sim Exponential(1)\\)\n\n\n\nlibrary(rethinking) \ndata(reedfrogs)\nd &lt;- reedfrogs \nd$tank &lt;- 1:nrow(d)\ndat &lt;- list(\n    S = d$surv,\n    D = d$density,\n    T = d$tank )\n\nmST &lt;- ulam( \n    alist(\n        S ~ dbinom( D , p ) ,\n        logit(p) &lt;- a[T] ,\n        a[T] ~ dnorm( a_bar , sigma ) , \n        a_bar ~ dnorm( 0 , 1.5 ) ,\n        sigma ~ dexp( 1 )\n    ), data=dat , chains=4 , log_lik=TRUE )\n\nmSTnomem &lt;- ulam( \n    alist(\n        S ~ dbinom( D , p ) ,\n        logit(p) &lt;- a[T] ,\n        a[T] ~ dnorm( a_bar , 1 ) , \n        a_bar ~ dnorm( 0 , 1.5 )\n    ), data=dat , chains=4 , log_lik=TRUE )\n\ncompare( mST , mSTnomem , func=WAIC )\n\n\nmultilevel models regularize “for free” - model mST is a multilevel model and having sigma as a prior means that it is regularized around the relevant values\nmSTnomem is not a multilevel model (sigma is not a prior - it is a fixed value)\nwhen you are working with multilevel models, when you add treatment variables, the variation among means is going to shrink because you are accounting for the variation with the different treatments\nmultilevel models often have lower neff than non-multilevel counterparts with more parameters because the parameters are hierarchically imbedded and operate more efficiently – it is the structure that matters not the absolute number of parameters\n\nadding parameters to a mlm doesn’t necessarily result in overfitting because of this fact, they are resistant to overfitting\n\nmore evidence results in more accurate modelling - however individuals furthest from the mean have results that have the most discrepancy because the model is skeptical of extreme events\nstratify mean by predators:\n\n\\(S_i \\sim Binomial(D_i, p_i)\\)\n\\(logit(p_i) = \\alpha_{T[i]} + \\beta_PP_i\\)\n\\(\\beta_P \\sim Normal(0, 0.5)\\)\n\\(\\alpha_j \\sim Normal(\\overline{\\alpha}, \\sigma)\\)\n\\(\\overline{\\alpha_j} \\sim Normal(0, 1.5)\\)\n\\(\\sigma \\sim Exponential(1)\\)\n\n\n\n# pred model\n\ndat$P &lt;- ifelse(d$pred==\"pred\",1,0)\nmSTP &lt;- ulam( \n    alist(\n        S ~ dbinom( D , p ) ,\n        logit(p) &lt;- a[T] + bP*P ,\n        bP ~ dnorm( 0 , 0.5 ),\n        a[T] ~ dnorm( a_bar , sigma ) , \n        a_bar ~ dnorm( 0 , 1.5 ) ,\n        sigma ~ dexp( 1 )\n    ), data=dat , chains=4 , log_lik=TRUE )\n\npost &lt;- extract.samples(mSTP)\ndens( post$bP , lwd=4 , col=2 , xlab=\"bP (effect of predators)\" )\n\n\nextremely similar predictions between model with predators and model without\n\nbecause alphas can learn the behaviours of each tank without an explanation (ie predators)\n\nBUT the variation that the model learns between tanks is very different between models\n\npredator model has much lower variation in sigma\nits not variation among the tanks, its the variation among parameters, net all the other effects in the model"
  },
  {
    "objectID": "notes/notes-12.html#multilevel-tadpoles",
    "href": "notes/notes-12.html#multilevel-tadpoles",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Multilevel Tadpoles",
    "text": "Multilevel Tadpoles\n\nmodel of unobserved population helps learn about observed units\nuse data efficiently, reduce overfitting\nvarying effects: unit-specific partially pooled estimates (also called random effects depending on discipline)"
  },
  {
    "objectID": "notes/notes-12.html#varying-effects-superstitions",
    "href": "notes/notes-12.html#varying-effects-superstitions",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Varying Effects Superstitions",
    "text": "Varying Effects Superstitions\n\nunits must be sampled at random (false - unrelated) - justification for partial pooling is that you learn faster\nnumber of units must be large (false - unrelated)\nassumes Gaussian variation (false) - misunderstanding of probability theory. Distributions in statistical models are not claims of frequency distributions of the variables in the real world, they are just priors. Posterior distribution does not have to be Gaussian. A Gaussian prior does not impose a Gaussian posterior distribution.\n\nprior is just a prior\nbut you can use non-random distributions in multilevel models"
  },
  {
    "objectID": "notes/notes-12.html#practical-difficulties",
    "href": "notes/notes-12.html#practical-difficulties",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Practical Difficulties",
    "text": "Practical Difficulties\n\nhow to use more than one cluster at the same time?\nhow to sample efficiently?\nwhat about slopes? confounds?"
  },
  {
    "objectID": "notes/notes-12.html#bonus-random-confounds",
    "href": "notes/notes-12.html#bonus-random-confounds",
    "title": "Lecture 12 - Multilevel Models",
    "section": "Bonus: Random Confounds",
    "text": "Bonus: Random Confounds\n\nwhen unobserved group features influence individually-varying causes\n\ngroup level variables have direct and indirect influences\n\nvery confusing literature\n\n\n\n\n\n\n\nG (tank traits) have direct influences on Si (survival)\nZ (group trait) have direct influences on Si (survival)\nXi (individual trait) have direct influences on Si\nPROBLEM: G (tank traits) also indirectly influence Si through Xi\nmultilevel models that account for these confounds = Mundlak Machines\n\n\nset.seed(8672)\n\nN_groups &lt;- 30\nN_id &lt;- 200\na0 &lt;- (-2)\nbZY &lt;- (-0.5)\ng &lt;- sample(1:N_groups,size=N_id,replace=TRUE) # sample into groups\nUg &lt;- rnorm(N_groups,1.5) # group confounds\nX &lt;- rnorm(N_id, Ug[g] ) # individual varying trait\nZ &lt;- rnorm(N_groups) # group varying trait (observed)\nY &lt;- rbern(N_id, p=inv_logit( a0 + X + Ug[g] + bZY*Z[g] ) )\n\ntable(g)\n\n\ncan use a fixed effects model (estimate a different average rate for each group, without pooling) which soaks up the confounding - but its inefficient and it cannot identify any group-level effects\n\n\n# fixed effects\n# X deconfounded, but Z unidentified now!\nprecis(glm(Y~X+Z[g]+as.factor(g),family=binomial),pars=c(\"X\",\"Z\"),2)\n\ndat &lt;- list(Y=Y,X=X,g=g,Ng=N_groups,Z=Z)\n\n# fixed effects\nmf &lt;- ulam(\n    alist(\n        Y ~ bernoulli(p),\n        logit(p) &lt;- a[g] + bxy*X + bzy*Z[g],\n        a[g] ~ dnorm(0,10),\n        c(bxy,bzy) ~ dnorm(0,1)\n    ) , data=dat , chains=4 , cores=4 )\n\n# random effects\nmr &lt;- ulam(\n    alist(\n        Y ~ bernoulli(p),\n        logit(p) &lt;- a[g] + bxy*X + bzy*Z[g],\n        transpars&gt; vector[Ng]:a &lt;&lt;- abar + z*tau,\n        z[g] ~ dnorm(0,1),\n        c(bxy,bzy) ~ dnorm(0,1),\n        abar ~ dnorm(0,1),\n        tau ~ dexp(1)\n    ) , data=dat , chains=4 , cores=4 , sample=TRUE )\n\n\nshould expect your model to have posterior high density regions over the true value\nfixed effects model cannot estimate the group level effects\nmultilevel model pulls intercepts towards each other and thus compromises on identifying the confound so that it can get better estimates for each group\n\nbetter estimates for G, worse estimate for X but you can include Z\n\nMundlak Machine\n\ncalculate group average X which is a descendant of the confound (G) SO if we condition on \\(\\overline{X}_G\\) and treat it like a group level variable, it will partly deconfound our model\nestimate a different average rate for each group via partial pooling via including group average X\nbetter X but improper respect for uncertainty in X-bar (ignoring quality of Xbar across groups)\n\n\n\n# The Mundlak Machine\nxbar &lt;- sapply( 1:N_groups , function(j) mean(X[g==j]) )\ndat$Xbar &lt;- xbar\nmrx &lt;- ulam(\n    alist(\n        Y ~ bernoulli(p),\n        logit(p) &lt;- a[g] + bxy*X + bzy*Z[g] + buy*Xbar[g],\n        transpars&gt; vector[Ng]:a &lt;&lt;- abar + z*tau,\n        z[g] ~ dnorm(0,1),\n        c(bxy,buy,bzy) ~ dnorm(0,1),\n        abar ~ dnorm(0,1),\n        tau ~ dexp(1)\n    ) , data=dat , chains=4 , cores=4 , sample=TRUE )\n\n\ncan fix the problem of not respecting the uncertainty in X-bar\n\ntreat G as unknown and use Xi to estimate\nrespects uncertainty in G\nrun two simultaneous regressions\n\n\n\n# The Latent Mundlak Machine\nmru &lt;- ulam(\n    alist(\n        # Y model\n        Y ~ bernoulli(p),\n        logit(p) &lt;- a[g] + bxy*X + bzy*Z[g] + buy*u[g],\n        transpars&gt; vector[Ng]:a &lt;&lt;- abar + z*tau,\n        # X model\n        X ~ normal(mu,sigma),\n        mu &lt;- aX + bux*u[g],\n        vector[Ng]:u ~ normal(0,1),\n        # priors\n        z[g] ~ dnorm(0,1),\n        c(aX,bxy,buy,bzy) ~ dnorm(0,1),\n        bux ~ dexp(1),\n        abar ~ dnorm(0,1),\n        tau ~ dexp(1),\n        sigma ~ dexp(1)\n    ) , data=dat , chains=4 , cores=4 , sample=TRUE )\n\n\ncan use fixed effects if you are not interested in group-level predictors or prediction\ncan include average X but it is better to use the latent model\nconfounds vary a lot - there is no one answer"
  },
  {
    "objectID": "notes/notes-14.html",
    "href": "notes/notes-14.html",
    "title": "Lecture 14 - Correlated Features",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-14.html#rose-thorn",
    "href": "notes/notes-14.html#rose-thorn",
    "title": "Lecture 14 - Correlated Features",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-14.html#add-correlated-features",
    "href": "notes/notes-14.html#add-correlated-features",
    "title": "Lecture 14 - Correlated Features",
    "section": "Add Correlated Features",
    "text": "Add Correlated Features\n\nwhen you build models that can identify correlation between features you can use partial pooling between those correlated features\none prior distribution for each cluster\n\none feature: one dimensional distribution (varying intercepts)\ntwo features: two-D distribution (often use multivariate normal distribution - have mean and variation but also correlation between the parameters)\nN features: N-dimensional distribution\n\nhard part: learning associations\n\n\n###########\n# non-centered varying slopes with and without covariance\n\ndat &lt;- list(\n    C = d$use.contraception,\n    D = as.integer(d$district),\n    U = d$urban,\n    A = standardize(d$age.centered),\n    K = d$living.children )\n\n# no covariance\nmCDUnc &lt;- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) &lt;- a[D] + b[D]*U,\n        # define effects using other parameters\n        save&gt; vector[61]:a &lt;&lt;- abar + za*sigma,\n        save&gt; vector[61]:b &lt;&lt;- bbar + zb*tau,\n        # z-scored effects\n        vector[61]:za ~ normal(0,1),\n        vector[61]:zb ~ normal(0,1),\n        # ye olde hyper-priors\n        c(abar,bbar) ~ normal(0,1),\n        c(sigma,tau) ~ exponential(1)\n    ) , data=dat , chains=4 , cores=4 )\n\n\nit is hard to learn the correlation from any finite sample\nLKJ correlation matrix priors - prior for correlation matrices\n\ntends to have shapes\ncan be skeptical of extreme correlations\n\n\n\n# covariance - centered\nmCDUcov &lt;- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) &lt;- a[D] + b[D]*U,\n        # define effects using other parameters\n        transpars&gt; vector[61]:a &lt;&lt;- v[,1],\n        transpars&gt; vector[61]:b &lt;&lt;- v[,2],\n        # priors - centered correlated varying effects\n        matrix[61,2]:v ~ multi_normal(abar,Rho,sigma),\n        vector[2]:abar ~ normal(0,1),\n        corr_matrix[2]:Rho ~ lkj_corr(4),\n        vector[2]:sigma ~ exponential(1)\n    ) , data=dat , chains=4 , cores=4 )\n\n\ncentering vs non-centering to increase efficiency of models\n\ncentered = priors of priors (parameters inside the priors)\nnon-centered = changing model to not have hyper-priors (but be mathematically equivalent) to have increased efficiencies\n\n\n\n# covariance - non-centered\nmCDUcov_nc &lt;- ulam(\n    alist(\n        C ~ bernoulli(p),\n        logit(p) &lt;- a[D] + b[D]*U,\n        # define effects using other parameters\n        # this is the non-centered Cholesky machine\n        transpars&gt; vector[61]:a &lt;&lt;- abar[1] + v[,1],\n        transpars&gt; vector[61]:b &lt;&lt;- abar[2] + v[,2],\n        transpars&gt; matrix[61,2]:v &lt;-\n            compose_noncentered( sigma , L_Rho , Z ),\n        # priors - note that none have parameters inside them\n        # that is what makes them non-centered\n        matrix[2,61]:Z ~ normal( 0 , 1 ),\n        vector[2]:abar ~ normal(0,1),\n        cholesky_factor_corr[2]:L_Rho ~ lkj_corr_cholesky( 4 ),\n        vector[2]:sigma ~ exponential(1),\n        # convert Cholesky to Corr matrix\n        gq&gt; matrix[2,2]:Rho &lt;&lt;- Chol_to_Corr(L_Rho)\n    ) , data=dat , chains=4 , cores=4 )\n\n\nnice to compare prior to posterior distribution to make sure the model learned something\ncorrelated varying effects models are easier to fit in Bayesian framework\npriors learn correlation structure\nvarying effects can be correlated even if the prior doesn’t learn the correlations"
  },
  {
    "objectID": "notes/notes-14.html#inconvenient-posteriors",
    "href": "notes/notes-14.html#inconvenient-posteriors",
    "title": "Lecture 14 - Correlated Features",
    "section": "Inconvenient Posteriors",
    "text": "Inconvenient Posteriors\n\ntransforming priors can help with divergent transitions because it changes the shape of the model\nbrms uses non-centered priors as default in multilevel models\n\nnot always better\n\ncentered and non-centered priors are better in different contexts\n\ncentered: lots of data in each cluster (data probability dominant)\nnon-centered: many clusters, sparse evidence (prior dominant)"
  },
  {
    "objectID": "notes/notes-11.html",
    "href": "notes/notes-11.html",
    "title": "Lecture 11 - Ordered Categories",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-11.html#rose-thorn",
    "href": "notes/notes-11.html#rose-thorn",
    "title": "Lecture 11 - Ordered Categories",
    "section": "",
    "text": "Rose:\nThorn:"
  },
  {
    "objectID": "notes/notes-11.html#trolley-problems",
    "href": "notes/notes-11.html#trolley-problems",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Trolley Problems",
    "text": "Trolley Problems\n\nthere is a runaway trolley, you are next to a switch\nif you do not pull the switch, it will kill 5 people. If you pull the switch, one person dies\nwhat is the ethics of pulling the switch\ncan assess people’s reactions to trolley problems to assess ethics (can’t actually do trolley problems)\nthree variables that people try to analyze: action, intention, contact\n\ntaking an action is less morally permissible than not\nintention seems more monstrous\nintended access are even worse if they involve contact\n\ntrolley data: answering 30 trolley problems asking how appropriate is the action from 1-7?\noutcome data is ordered categorical data\nestimand: how do action, intention, and contact influence response to a trolley story?\n\nhow are influences of A/I/C associated with other variables?"
  },
  {
    "objectID": "notes/notes-11.html#ordered-categories",
    "href": "notes/notes-11.html#ordered-categories",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Ordered Categories",
    "text": "Ordered Categories\n\ncategories of discrete types with ordered relationships\ndistances between the categories doesn’t have to be the same (e.g., going from 4-5 is probably easier than going from 6-7 because reaching the max means more than shifting in the middle )\nanchor points are common (defaults when we are not sure/feeling meh)\n\nnot everyone shares the same anchor points\n\nneed to think of outcomes as cumulative distribution -&gt; i.e., 5 is everything 5 and under added together\n\nthe probability of 5 is actually the probability of 5 or less\nbuild log-odds parameters that correspond to this (log(probability of thing / probability of thing not happening))\nlogit link models\ncumulative proportion -&gt; cumulative log-odds to model these data\nparameters are on cumulative log-odds scale = cutpoints\nnumber of cutpoints you need is n-1 of outcomes (because last one is Infinity because we added the cumulative proportion of everything together to get to 1)\nto predict the data, we have to recalculate cumulative proportion\n\nHow to make it a function of variables (GLM)?\n\nstratify cutpoints\noffset each cutpoint by value of linear model\nRi ~ OrderedLogit(\\(\\phi_i , \\alpha\\))\n\\(\\phi_i\\) = \\(\\beta x_i\\) (linear model)\n\\(\\alpha\\) = cutpoint\nthere is no intercept in phi because the intercept is already accounted for with cutpoints\nBigger phis give you smaller average responses and smaller phis give you larger average responses (if phi is subtracted - double check software)\n\navoid interpreting coefficients - double check you know what is happening\n\n\nExample:\n\n\\(R_i \\sim OrderedLogit(\\phi_i , \\alpha)\\)\n\\(\\phi_i = \\beta_A A_i + \\beta_C C_i + \\beta_I I_i\\)\n\\(\\beta \\sim Normal(0, 0.5)\\)\n\\(\\alpha_j \\sim Normal(0, 1)\\)\n\n\n\ndata(Trolley)\nd &lt;- Trolley\ndat &lt;- list(\n    R = d$response,\n    A = d$action,\n    I = d$intention,\n    C = d$contact\n)\n\nmRX &lt;- ulam(\n    alist(\n        R ~ dordlogit(phi,alpha),\n        phi &lt;- bA*A + bI*I + bC*C,\n        c(bA,bI,bC) ~ normal(0,0.5),\n        alpha ~ normal(0,1)\n    ) , data=dat , chains=4 , cores=4 )\n\nprecis(mRX,2)\n\n\nafter modelling, simulate different outcomes\n\n\n# plot predictive distributions for each treatment\n\nvals &lt;- c(0,1,1) # A,I,C\nRsim &lt;- mcreplicate( 100 , sim(mRX,data=list(A=vals[1],I=vals[2],C=vals[3])) , mc.cores=6 )\nsimplehist(as.vector(Rsim),lwd=8,col=2,xlab=\"Response\")\nmtext(concat(\"A=\",vals[1],\", I=\",vals[2],\", C=\",vals[3]))"
  },
  {
    "objectID": "notes/notes-11.html#competing-causes",
    "href": "notes/notes-11.html#competing-causes",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Competing Causes",
    "text": "Competing Causes\n\nwe can stratify by competing causes - just stratify the model by the variable of interest\n\n\n# total effect of gender\ndat$G &lt;- ifelse(d$male==1,2,1)\nmRXG &lt;- ulam(\n    alist(\n        R ~ dordlogit(phi,alpha),\n        phi &lt;- bA[G]*A + bI[G]*I + bC[G]*C,\n        bA[G] ~ normal(0,0.5),\n        bI[G] ~ normal(0,0.5),\n        bC[G] ~ normal(0,0.5),\n        alpha ~ normal(0,1)\n    ) , data=dat , chains=4 , cores=4 )\n\nprecis(mRXG,2)\n\nvals &lt;- c(0,1,1,2) # A,I,C,G\nRsim &lt;- mcreplicate( 100 , sim(mRXG,data=list(A=vals[1],I=vals[2],C=vals[3],G=vals[4])) , mc.cores=6 )\nsimplehist(as.vector(Rsim),lwd=8,col=2,xlab=\"Response\")\nmtext(concat(\"A=\",vals[1],\", I=\",vals[2],\", C=\",vals[3],\", G=\",vals[4]))\n\n\nis this the causal effect of gender?\n\nconfounded because this is a voluntary sample\neverything is causally associated with participation\nparticipation is implicitly conditioned on - it is a collider\nbecause all our covarying effects of interest are already stratified by the collider participation, it is impossible to get the total causal effect of gender BUT we can get direct effect of gender (if we stratify appropriately)\n\n\n\n\n\n\nhow do we put these metric predictors into the model?"
  },
  {
    "objectID": "notes/notes-11.html#ordered-monotonic-predictors",
    "href": "notes/notes-11.html#ordered-monotonic-predictors",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Ordered Monotonic Predictors",
    "text": "Ordered Monotonic Predictors\n\neducation is an ordered category that is a predictor\n\nunlikely that each level has the same effect\nwant a parameter for each level\ntake top level as “maximum effect” and each level gets their own beta and multiply each education level by maximum effect\nindividual delta parameters form a simplex (vector that sums to 1)\nprobability distribution that sums to 1 = Dirichlet\n\nDirichlet\n\ndistribution for distributions\nwhen you sample from a Dirichlet distribution, you get a probability distribution\nvector that sums to 1\nneed the same number of input numbers as levels\nbigger the numbers get, the less variation there is in the distributions\nhaving the same number doesn’t mean they are all the same, it means there is no prior expectation of which ones are bigger than the others\n\n\n\n# distributions of education and age\n\nedu_levels &lt;- c( 6 , 1 , 8 , 4 , 7 , 2 , 5 , 3 )\nedu_new &lt;- edu_levels[ d$edu ]\n\ndat$E &lt;- edu_new\ndat$a &lt;- rep(2,7) # dirichlet prior\n\nmRXE &lt;- ulam(\n    alist(\n        R ~ ordered_logistic( phi , alpha ),\n        phi &lt;- bE*sum( delta_j[1:E] ) + bA*A + bI*I + bC*C,\n        alpha ~ normal( 0 , 1 ),\n        c(bA,bI,bC,bE) ~ normal( 0 , 0.5 ),\n        vector[8]: delta_j &lt;&lt;- append_row( 0 , delta ),\n        simplex[7]: delta ~ dirichlet( a )\n    ), data=dat , chains=4 , cores=4 )\n\nprecis(mRXE,2)\n\n# version with transpars\nmRXE2 &lt;- ulam(\n    alist(\n        R ~ ordered_logistic( phi , alpha ),\n        phi &lt;- bE*sum( delta_j[1:E] ) + bA*A + bI*I + bC*C,\n        alpha ~ normal( 0 , 1 ),\n        c(bA,bI,bC,bE) ~ normal( 0 , 0.5 ),\n        transpars&gt; vector[8]: delta_j &lt;&lt;- append_row( 0 , delta ),\n        simplex[7]: delta ~ dirichlet( a )\n    ), data=dat , chains=4 , cores=4 )\n\nl &lt;- link(mRXE2)\n\n\ndeltas from output show the proportion of the effect that is attributed to each education level\n\n\n# BIG MODEL\n\ndat$Y &lt;- standardize(d$age)\n\n# single-threaded version\nmRXEYG &lt;- ulam(\n    alist(\n        R ~ ordered_logistic( phi , alpha ),\n        phi &lt;- bE[G]*sum( delta_j[1:E] ) + \n               bA[G]*A + bI[G]*I + bC[G]*C +\n               bY[G]*Y,\n        alpha ~ normal( 0 , 1 ),\n        bA[G] ~ normal( 0 , 0.5 ),\n        bI[G] ~ normal( 0 , 0.5 ),\n        bC[G] ~ normal( 0 , 0.5 ),\n        bE[G] ~ normal( 0 , 0.5 ),\n        bY[G] ~ normal( 0 , 0.5 ),\n        vector[8]: delta_j &lt;&lt;- append_row( 0 , delta ),\n        simplex[7]: delta ~ dirichlet( a )\n    ), data=dat , chains=4 , cores=4 )\n\n# multi-threaded version\nmRXEYGt &lt;- ulam(\n    alist(\n        R ~ ordered_logistic( phi , alpha ),\n        phi &lt;- bE[G]*sum( delta_j[1:E] ) + \n               bA[G]*A + bI[G]*I + bC[G]*C +\n               bY[G]*Y,\n        alpha ~ normal( 0 , 1 ),\n        bA[G] ~ normal( 0 , 0.5 ),\n        bI[G] ~ normal( 0 , 0.5 ),\n        bC[G] ~ normal( 0 , 0.5 ),\n        bE[G] ~ normal( 0 , 0.5 ),\n        bY[G] ~ normal( 0 , 0.5 ),\n        vector[8]: delta_j &lt;&lt;- append_row( 0 , delta ),\n        simplex[7]: delta ~ dirichlet( a )\n    ), data=dat , chains=4 , cores=4 , threads=2 )\n\nprecis(mRXEYGt,2)"
  },
  {
    "objectID": "notes/notes-11.html#complex-causal-effects",
    "href": "notes/notes-11.html#complex-causal-effects",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Complex Causal Effects",
    "text": "Complex Causal Effects\n\ncausal effects (predicted consequences of intervention) require marginalization aka post-stratification\ncausal effect of education requires distribution of age and gender to average over\nsimulate causal effects after thinking carefully over the range of the population you’d like to estimate over\nproblem 1: should not marginalize over this sample because of selection bias (participation)! Post-stratify to new target\nproblem 2: should not set all ages to the same education\n\nwhat does a real population look like?\n\ncausal effect of age requires effect of age on education, which we cannot estimate (because of participation!)\nno matter how complex, its still just a generative simulation using posterior samples\n\nneed generative model to plan estimation\nneed generative model to compute causal estimates"
  },
  {
    "objectID": "notes/notes-11.html#repeat-observations",
    "href": "notes/notes-11.html#repeat-observations",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Repeat Observations",
    "text": "Repeat Observations\n\nrepeating stories and individuals\n\nnot confounds because the treatment is randomized"
  },
  {
    "objectID": "notes/notes-11.html#bonus-post-stratification",
    "href": "notes/notes-11.html#bonus-post-stratification",
    "title": "Lecture 11 - Ordered Categories",
    "section": "Bonus: Post-Stratification",
    "text": "Bonus: Post-Stratification\n\nquality of data is more important than quantity\nbigger samples amplify biases\na non-representative sample can be better than a representative one\n\ndifferent aspects of data matter than representation\ncan correct for non-representativeness\n\nbasic problem: sample is not the target\n\npost-stratification is principled methods for extrapolating from sample to population\npost-stratification requires causal model of reasons sample differs from population\n\nselection nodes indicate why the sample is unrepresentative of the population\n\n[S] indicates what the sample is being selected by (e.g., age -&gt; different ages are less likely to respond to a survey)\nmany sources of data are already filtered by selection effects\nthe right thing to do depends upon causes of selection\n\nmany questions are really post-stratification questions\njustified descriptions require causal information and post stratification\ntime trends should account for changes in measurement/population\ncomparison is post-stratification from one population to another\nPAPER: a causal framework for cross-cultural generalizability\n4 step plan for honest digital scholarship\n\n\n\nwhat are we trying to describe?\nwhat is the ideal data for doing so?\nwhat data do we actually have?\nwhat causes the differences between (2) and (3)?\n[optional] is there a way to use (3) + (4) to do (1)?"
  }
]