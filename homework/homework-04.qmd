---
title: "Homework - Week 04"
author: "Isabella C. Richmond"
format: html
---

```{r, include = FALSE}
source('R/packages.R')
```

## Question 1: Revisit the marriage, age, and happiness collider bias example from Chapter 6. Run models m6.9 and m6.10 again (pages 178--179). Compare these two models using both PSIS and WAIC. Which model is expected to make better predictions, according to these criteria, and which model yields the correct causal inference?

```{r}
d <- sim_happiness(seed = 1977, N_years = 1000)
d2 <- d[d$age > 17, ]
d2$A <- (d2$age - 18) / (65 - 18)
d2$mid <- d2$married + 1

# model with marital status and age
tar_load(h04_q1a)
mMA <- h04_q1a

mMA %>% 
  gather_draws(b_Intercept, b_mid, b_A, sigma) %>% 
  median_qi() %>%
  ggplot(aes(y = .variable, x = .value, xmin = .lower, xmax = .upper)) + 
  geom_pointinterval() + 
  theme_classic() +
  labs(y = "", x = "mean value +/- 95% CIs")

# model with age
tar_load(h04_q1b)
mA <- h04_q1b

mA %>% 
  gather_draws(b_Intercept, b_A, sigma) %>% 
  median_qi() %>%
  ggplot(aes(y = .variable, x = .value, xmin = .lower, xmax = .upper)) + 
  geom_pointinterval() + 
  theme_classic() +
  labs(y = "", x = "mean value +/- 95% CIs")

# compare with PSIS & WAIC
cMA <- add_criterion(mMA, c("loo", "waic"))
cA <- add_criterion(mA, c("loo", "waic"))
loo_compare(cMA, cA, criterion = "loo")
loo_compare(cMA, cA, criterion = "waic")
```

The correct predictive model includes both marriage status and age. However, marriage status is a collider and the correct causal model includes only age. Thus, the correct causal model and the best predictive model are different in this case (because predictive models favour colliders).

## Question 2: Reconsider the urban fox analysis from last week's homework. On the basis of PSIS and WAIC scores, which combination of variables best predicts body weight (W, weight)? What causal interpretation can you assign each coefficient (parameter) from the best scoring model?

```{r}
# get data
data(foxes)
d <- foxes %>% 
    select(c(weight, avgfood, area, groupsize)) %>%
    mutate(avgfood = standardize(avgfood), 
           area = standardize(area),
           weight = standardize(weight),
           groupsize = standardize(groupsize))

# load models
tar_load(h03_q2)
tar_load(h03_q3)
tar_load(h04_q2)
m_food <- h03_q2
m_foodgroupsize <- h03_q3
m_areafoodgroupsize <- h04_q2

crit_food <- add_criterion(m_food, c("loo", "waic"))
crit_foodgroupsize <- add_criterion(m_foodgroupsize, c("loo", "waic"))
crit_areafoodgroupsize <- add_criterion(m_areafoodgroupsize, c("loo", "waic"))

loo_compare(crit_food, crit_foodgroupsize, crit_areafoodgroupsize, criterion = "loo")
```

The model with area, average food, and group size is the best predictive model. In this model, we are assessing the direct effect of group size on weight. So the coefficient for G can be read as the direct effect. The coefficients for F and A do not have causal meaning **(discuss with group)**. If we hadn't stratified by group size, we would be assessing the direct effect of area on weight but stratifying by both average food *and* group size means that we opened a backdoor path.

## Question 3: Build a predictive model of the relationship show on the cover of the book, the relationship between the timing of cherry blossoms and March temperature in the same year. The data are found in data(cherry_blossoms). Consider at least two different models (functional relationships) to predict doy with temp. You could for example compare a linear model with a quadratic model. Compare them with PSIS or WAIC.

```{r}
# data
data("cherry_blossoms")

cherry <- cherry_blossoms %>% 
  select(temp, doy) %>%
  drop_na() %>%
  mutate(temp_s = standardize(temp),
         doy_s = standardize(doy))

# models
tar_load(h04_q3a)
tar_load(h04_q3b)
tar_load(h04_q3c)
m_priors <- h04_q3a
m_linear <- h04_q3b
m_gam <- h04_q3c

# compare
crit_priors <- add_criterion(m_priors, c("loo"))
crit_linear <- add_criterion(m_linear, c("loo"))
crit_gam <- add_criterion(m_gam, c("loo"))

loo_compare(crit_priors, crit_linear, crit_gam, criterion = "loo")

```

The linear model performed best, but the GAM and linear model performed much more similarly than the prior only model (which makes sense).

## Suppose March temperatures reach 9 degrees by the year 2050. What does your best model predict for the predictive distribution of the day-in-year that the cherry trees will blossom?

```{r}
# posterior summary
posterior_summary(m_linear)

# create dataset that simulates 9 degree days in March (also need to standardize as that is how model is currently set up)
pred_val <- cherry %>%
  summarize(temp_s = (9-mean(temp))/sd(temp))

# simulate from model for when March is 9 degrees
post_pred <- predicted_draws(m_linear, pred_val) 
post_pred <- post_pred %>%
  # convert back to real values from standardized ones
  mutate(doy = .prediction*sd(cherry$doy) + mean(cherry$doy))

# plot  
ggplot() + 
  geom_density(aes(x = doy), col = "red", data = post_pred) + 
  geom_density(aes(x = doy), data = cherry) + 
  xlab("day of year in 1st bloom") + 
  theme_classic()

```

Average first day in bloom seems to be much earlier when warming occurs (red line) according to our predictive model.

## Question 4: The data in data(Dinosaurs) are body mass estimates at different estimated ages for six different dinosaur species. See ?Dinosaurs for more details. Choose one or more of these species (at least one, but as many as you like) and model its growth. To be precise: Make a predictive model of body mass using age as a predictor. Consider two or more model types for the function relating age to body mass and score each using PSIS and WAIC.

## Which model do you think is best, on predictive grounds? On scientific grounds? If your answers to these questions differ, why?

## This is a challenging exercise, because the data are so scarce. But it is also a realistic example, because people publish Nature papers with even less data. So do your best, and I look forward to seeing your growth curves.
